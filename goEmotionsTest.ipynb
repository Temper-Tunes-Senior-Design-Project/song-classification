{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if needed, he'll use for arousal: neutral/suprise\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:\n",
    "\"uriyas model total emotions: happy, sad, disgust, fear, neutral, anger, surprise\"\n",
    "\"use for valence: happy/sad\"\n",
    "\"if needed, he'll use for arousal: neutral/suprise\"\n",
    "#THEN, for me:\n",
    "#map the emotions to (x,y) coordinates of valence and arousal, then multiply it by the probability of the emotion, then take the weighted average and get the reslting x,y coordinates\n",
    "#valence and arousal are the two dimensions of the circumplex model and the resulting scores should get put in one of the 9(nuetral plus 8 categories) categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions: Testing Input to the Model, Adding Softmax Layer, Conversion Function for getting segment Label, Getting final Label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model monologg/bert-base-cased-goemotions-original from huggingface\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model on a sentence\n",
    "sentence = \"I am so happy\"\n",
    "tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "tokens = tokens.cuda()\n",
    "result = model(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Playing around/testing model (skip)\n",
    "this is to figure out what will be needed making softmax, and determining the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "#determine the max size of the input the model can handle\n",
    "max_length = model.config.max_position_embeddings\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 0, 13]\n"
     ]
    }
   ],
   "source": [
    "#identify the top 3 emotion with the highest probability\n",
    "emotion = result.logits\n",
    "emotion = emotion.cpu().detach().numpy()\n",
    "emotion = emotion[0]\n",
    "emotion = emotion.argsort()[-3:][::-1]\n",
    "emotion = emotion.tolist()\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert model.config.id2label to a list of emotions, where the key is the index of the emotion\n",
    "emotion_dict = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "admiration\n",
      "excitement\n"
     ]
    }
   ],
   "source": [
    "#identify the label of top 3 emotions from emotion list\n",
    "for i in emotion:\n",
    "    print(emotion_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "#identify the emotion with the highest probability\n",
    "emotion = result.logits.argmax()\n",
    "print(emotion)\n",
    "#which emotion is that?\n",
    "print(model.config.id2label[emotion.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict.values()\n",
    "emotionGroups=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionSet = set(emotion_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "approvedMoods=['neutral']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoftmax(model, sentence, n,printRawScores=False, printTopN=True):\n",
    "    tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    tokens = tokens.cuda()\n",
    "    result = model(tokens)\n",
    "    emotion = result.logits\n",
    "    emotion = emotion.cpu().detach().numpy()\n",
    "    emotion = emotion[0]\n",
    "    softmax = tf.nn.softmax(emotion)\n",
    "    if printRawScores:\n",
    "        print(softmax)\n",
    "    \n",
    "    if printTopN:\n",
    "        emotion = emotion.argsort()[-n:][::-1]\n",
    "        emotion = emotion.tolist()\n",
    "        printTopEmotions(emotion,model, softmax)\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def printTopEmotions(emotion, model, softmax):\n",
    "    \n",
    "    #identify the label of top n emotions from emotion list\n",
    "    #softmax is in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    emotion_dict = model.config.id2label\n",
    "    for i in emotion:\n",
    "        print(emotion_dict[i])\n",
    "        print(softmax[emotion[id]].numpy()*100,\"%\")\n",
    "        id+=1\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences from songs to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear2 = \"'Cause you see people, people, people, people Don't really know you (They don't really know you) They don't really know you 'Cause you see people, people, people They don't really know you (Mmm) They don't really know—\"\n",
    "unclear = \"I've been drinking more alcohol for the past five days Did you check on me? Now, did you look for me? I walked in the room, eyes are red and I don't smoke banga Did you check on me? (Did you check on me?) Now, did you notice me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "braggingLyrics = \"She just hit my phone, she said, 'Tecca, you a winner' (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I’m a star I just wanna ball with my guys Drive off the Wock', he just caught a DUI He think he know the answers, nigga, like he Bill Nye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadMetaphoricLyrics = \"Hello darkness, my old friend, I've come to talk with you again, because a vision softly creeping, left its seeds while I was sleeping.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "goEasyOnMeSad = \"There ain't no gold in this river That I've been washin' my hands in forever I know there is hope in these waters But I can't bring myself to swim When I am drowning in this silence Baby, let me in. Go easy on me, baby I was still a child Didn't get the chance to Feel the world around me I had no time to choose what I chose to do So go easy on me\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curiosity\n",
      "99.90363121032715 %\n",
      "neutral\n",
      "0.034640790545381606 %\n",
      "confusion\n",
      "0.019302892906125635 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear=getSoftmax(model, unclear, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.9980092048645 %\n",
      "annoyance\n",
      "0.00058388282013766 %\n",
      "disappointment\n",
      "0.0003420888106120401 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear2=getSoftmax(model,unclear2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "75.65684914588928 %\n",
      "joy\n",
      "16.482388973236084 %\n",
      "excitement\n",
      "4.176769405603409 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestBraggingLyrics=getSoftmax(model,braggingLyrics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.99864101409912 %\n",
      "annoyance\n",
      "0.00020481845695030643 %\n",
      "caring\n",
      "0.00011883536217283108 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestsadMetaphoricLyrics=getSoftmax(model,sadMetaphoricLyrics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointment\n",
      "63.13481330871582 %\n",
      "realization\n",
      "14.627596735954285 %\n",
      "sadness\n",
      "14.258602261543274 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestgoEasyOnMeSad=getSoftmax(model,goEasyOnMeSad, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SoftMax Recap:\n",
    "\n",
    "1. There seems to be a dominance of neutral while the trailing classes seem to be more relevant. This does make sense considering the fact that not every lyric is emotionally charged.  \n",
    "\n",
    "- However, this does raise the question, \"How do we handle neutral?\"\n",
    "\n",
    "- similarly, \"Do we want neutral as a resulting category?\n",
    "\n",
    "2. Songs that are reliant on metaphores or to create emotion will not be captured via sentiment analysis\n",
    "\n",
    "- In these cases, we would want the linear model to give results\n",
    "- perhaps if this is specifially reated neutral we should rely on the linear classificiaton model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class Conversion Without Special Neutral Considerations\n",
    "\n",
    "Here we will:\n",
    "1. scale emotions to (valence, energy) based on the valence-arousal mood wheel\n",
    "2. multiply that value by the percent\n",
    "3. add up x values as well as y values\n",
    "4. place resulting values into the 8 main mood categories to get a class\n",
    "5. if close to 0, label it neutral instead\n",
    "    - If neutral, perhaps use as indicator to rely on 2nd model for classification\n",
    "\n",
    "NOTE: Some words did not have a perfect point plotted, but there were some synonyms\n",
    "- approval was mapped with satisfied\n",
    "- caring was with passionate\n",
    "- confused with a lessened amount of frustrated (1/2)\n",
    "- curious was mapped with interested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mood setup verification (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration\n",
      "amusement\n",
      "anger\n",
      "annoyance\n",
      "approval\n",
      "caring\n",
      "confusion\n",
      "curiosity\n",
      "desire\n",
      "disappointment\n",
      "disapproval\n",
      "disgust\n",
      "embarrassment\n",
      "excitement\n",
      "fear\n",
      "gratitude\n",
      "grief\n",
      "joy\n",
      "love\n",
      "nervousness\n",
      "optimism\n",
      "pride\n",
      "realization\n",
      "relief\n",
      "remorse\n",
      "sadness\n",
      "surprise\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "emotion_dict = model.config.id2label\n",
    "for key in range(len(emotion_dict)):\n",
    "    print(emotion_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary mapping all emotions to valence and arousal values\n",
    "# valence is the x axis, arousal is the y axis of the circumplex model\n",
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,-.3),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6, 0.4)\n",
      "(0.6, 0.2)\n",
      "(-0.8, 0.6)\n",
      "(-0.6, 0.6)\n",
      "(0.8, 0.6)\n",
      "(0.6, -0.2)\n",
      "(-0.2, 0.2)\n",
      "(0, 0.4)\n",
      "(0.6, 0.6)\n",
      "(-0.6, -0.6)\n",
      "(-0.8, 0.65)\n",
      "(-0.8, 0.2)\n",
      "(-0.6, 0.4)\n",
      "(0.6, 0.8)\n",
      "(-0.6, 0.8)\n",
      "(0.6, -0.6)\n",
      "(-0.6, -0.8)\n",
      "(0.8, 0.2)\n",
      "(0.8, 0.4)\n",
      "(-0.4, 0.6)\n",
      "(0.6, -0.3)\n",
      "(0.6, 0.1)\n",
      "(0.2, 0.2)\n",
      "(0.4, -0.4)\n",
      "(-0.6, -0.4)\n",
      "(-0.8, -0.2)\n",
      "(0.2, 0.6)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(emotion_dict)):\n",
    "    print(emotionsAsValenceArousal[emotion_dict[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'despair':(-.8,-.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'envy':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,.2),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n",
    "#moods=['energetic','excited','happy','relaxed','calm','depressed','sad','anxious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determineMoodLabel(valence,arousal):\n",
    "    #determine the diagonal of the circumplex model that the valence and arousal scores fall on\n",
    "    #MAKE 2 BOXES OF THE CIRCUMPLEX MODEL A MOOD \n",
    "\n",
    "    energetic =   -0.5<valence<0.5 and arousal>0.5\n",
    "    happy =       valence>0.5 and -.5<arousal<0.5\n",
    "    calm =       -0.5<valence<0.5 and arousal<-0.5\n",
    "    sad =         valence<-0.5 and -.5<arousal<0.5\n",
    "\n",
    "    excited =   not (happy or energetic) and valence>0 and arousal>0\n",
    "    relaxed =   not (calm or happy) and valence>0 and arousal<0\n",
    "    depressed = not (calm or sad) and valence<0 and arousal<0\n",
    "    anxious =   not (energetic or sad) and valence<0 and arousal>0\n",
    "\n",
    "\n",
    "    if energetic:\n",
    "        mood='energetic'\n",
    "    elif happy:\n",
    "        mood='happy'\n",
    "    elif calm:\n",
    "        mood='calm'\n",
    "    elif sad:\n",
    "        mood='sad'\n",
    "    elif excited:\n",
    "        mood='excited'\n",
    "    elif relaxed:\n",
    "        mood='relaxed'\n",
    "    elif depressed:\n",
    "        mood='depressed'\n",
    "    elif anxious:\n",
    "        mood='anxious'\n",
    "    else:\n",
    "        mood='neutral'\n",
    "    return mood     \n",
    "\n",
    "def convertScoresToLabels(softmaxScores, emotionsAsValenceArousal,emotion_dict,printValenceArousal=False):\n",
    "    #convert the softmax scores to a valence and arousal score\n",
    "    #softmax scores are in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    valence=0\n",
    "    arousal=0\n",
    "    for i in softmaxScores:\n",
    "        valence+=i*emotionsAsValenceArousal[emotion_dict[id]][0]\n",
    "        arousal+=i*emotionsAsValenceArousal[emotion_dict[id]][1]\n",
    "        id+=1\n",
    "    #convert valence and arousal from tensor to float\n",
    "    valence = valence.numpy()\n",
    "    arousal = arousal.numpy()\n",
    "    mood =determineMoodLabel(valence,arousal)\n",
    "    if printValenceArousal:\n",
    "        print(\"Valence: \",valence)\n",
    "        print(\"Arousal: \",arousal)\n",
    "    return mood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken function but cleaner code (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef determineMoodLabel(valence, arousal):\\n    conditions = {\\n        'energetic': (-0.5 < valence < 0.5) and (arousal > 0.5),\\n        'happy': (valence > 0.5) and (-0.5 < arousal < 0.5),\\n        'calm': (-0.5 < valence < 0.5) and (arousal < -0.5),\\n        'sad': (valence < -0.5) and (-0.5 < arousal < 0.5),\\n    }\\n    conditions['excited']= (valence > 0) and (arousal > 0) and not ((conditions.get('happy') == True) or (conditions.get('energetic') == True))\\n    conditions['relaxed'] =(valence > 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('happy') == True)),\\n    conditions['depressed']= (valence < 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('sad') == True)),\\n    conditions['anxious']= (valence < 0) and (arousal > 0) and not ((conditions.get('energetic') == True) or (conditions.get('sad') == True))\\n\\n    for mood, condition in conditions.items():\\n        #print(mood)\\n        if condition:\\n            if condition:\\n            #print(condition)\\n                return mood\\n    return 'neutral'\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def determineMoodLabel(valence, arousal):\n",
    "    conditions = {\n",
    "        'energetic': (-0.5 < valence < 0.5) and (arousal > 0.5),\n",
    "        'happy': (valence > 0.5) and (-0.5 < arousal < 0.5),\n",
    "        'calm': (-0.5 < valence < 0.5) and (arousal < -0.5),\n",
    "        'sad': (valence < -0.5) and (-0.5 < arousal < 0.5),\n",
    "    }\n",
    "    conditions['excited']= (valence > 0) and (arousal > 0) and not ((conditions.get('happy') == True) or (conditions.get('energetic') == True))\n",
    "    conditions['relaxed'] =(valence > 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('happy') == True)),\n",
    "    conditions['depressed']= (valence < 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('sad') == True)),\n",
    "    conditions['anxious']= (valence < 0) and (arousal > 0) and not ((conditions.get('energetic') == True) or (conditions.get('sad') == True))\n",
    "\n",
    "    for mood, condition in conditions.items():\n",
    "        #print(mood)\n",
    "        if condition:\n",
    "            if condition:\n",
    "            #print(condition)\n",
    "                return mood\n",
    "    return 'neutral'\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determineMoodLabel(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.00014550616\n",
      "Arousal:  0.39976904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear, emotionsAsValenceArousal,emotion_dict,printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -6.28967e-06\n",
      "Arousal:  4.1340345e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear2, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.17935042\n",
      "Arousal:  0.0792139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestBraggingLyrics, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -1.578913e-06\n",
      "Arousal:  2.6779267e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestsadMetaphoricLyrics, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.4687149\n",
      "Arousal:  -0.37509394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'depressed'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestgoEasyOnMeSad, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class Conversion Recap:\n",
    "\n",
    "- The code works but it tends to classify heavily towards the center of the coordinates\n",
    "- NOTE: This could be because it was just a few small samples, which may not reflect the overall distribution of the data\n",
    "- As an alternative, we could remove the neutral score and apply softmax to the remaining classes\n",
    "- OR, I could just exclude the inputs that result in overwhemingly neutral, and then continue to the next chunk of lyrics until I find all chunks that are not neutral and then get the average of those to get the final classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Class Conversion With Special Neutral Considerations\n",
    "\n",
    "First, in 6 and 7, we will try to get the average of the classes that are not overwhelmingly neutral to get final label.\n",
    "\n",
    "If that doesnt work, here we will drop the neutral score and apply softmax to the remaining classes\n",
    "\n",
    "- This would allow us to multiply the coordinates without shrinking the values due to the neutral score\n",
    "- Perhaps this would allow us to reach the classes that are further away from the center\n",
    "- If not, we could shift the boundaries of the classes closer to the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Breaking up Lyrics to fit into model\n",
    "\n",
    "In order to fit the lyrics into the model, we need to break up the lyrics. There are various ways to do this. We will try a few different methods and see which one works best.\n",
    "\n",
    "\n",
    "- (Best) We could break it up by headers. Below are the various headers that we could use to break up the lyrics\n",
    "https://genius.com/Genius-song-sections-and-headers-guide-annotated\n",
    "    - in general, the intro is least emotional, the chorus is most emotional, and the verses are in between\n",
    "    - This could mean we could skip the intro/outro and rely on the chorus and verses (maybe just the chorus when need fast results)\n",
    "\n",
    "Some other ideas:\n",
    "- We could break it up by sentences (some songs have no punctuation, so this may not work)\n",
    "- We could break it up by line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Samples used in testing (skip if not interested, but run cells)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song sample 1.\n",
    "\n",
    "This one is intentionally vague, but it is more relaxed or happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsLilTecca = \"\"\"\n",
    "[Intro]\n",
    "Nah, nah, nah\n",
    "Yeah, oh-oh\n",
    "Yeah, oh no\n",
    "We love you Tecca\n",
    "Yeah, yeah\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (That's Tec)\n",
    "I just took her home, then I turn her to a sinner, yeah\n",
    "Rambow\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they say that I’m a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he know the answers, nigga, like he Bill Nye\n",
    "[Verse]\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they sayin’ I'm a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he got the answers, nigga, like he Bill Nye\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song sample 2.\n",
    "\n",
    "This one is more sad, and it is Go easy on me by Adele\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsAdele =\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0.1. Determining split when tokenizing lyrics exceeds 512 (model input limit)\n",
    "\n",
    "The goal should be to split it as evenly as possible.\n",
    "\n",
    "If over limit but under 1024, we can split it into 2 chunks, either at the nerest line break or paragraph break to the middle of the chunk\n",
    "\n",
    "If it is bigger, we can divide by 512 to get n and then split it as smooth as possible into n+1 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(fullLyricsLilTecca)#, return_tensors=\"pt\")\n",
    "#tokens = tokens.cuda()\n",
    "max_length = model.config.max_position_embeddings #aka 512\n",
    "\n",
    "#if the token length over max length, get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "262\n",
      "262\n",
      "1678\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(fullLyricsLilTecca)#, return_tensors=\"pt\")\n",
    "#tokens = tokens.cuda()\n",
    "max_length = model.config.max_position_embeddings #aka 512\n",
    "\n",
    "\n",
    "if len(tokens) > max_length:\n",
    "    songSegmentCount = int(len(tokens)/max_length)+1\n",
    "    averageSegmentSize = int(len(tokens)/songSegmentCount)\n",
    "    print(songSegmentCount)\n",
    "    for i in range(1,songSegmentCount):\n",
    "        #determine the smooth segment and break up lyrics by those indeces, returning it in a list\n",
    "        print(averageSegmentSize)\n",
    "        print(len(fullLyricsLilTecca[:averageSegmentSize]))\n",
    "\n",
    "        \n",
    "        #compare it for now to the len of tokens\n",
    "\n",
    "\n",
    "        #need to think about how to go from encoded back to text. Maybe decode by the averageSegmentSize and then compare to original text to look for an end of line/new par!\n",
    "\n",
    "\n",
    "    #Need to verify that when trying to jump to fit to a paragraph or sentence it doesn't accidentally go over the limit again!\n",
    "    #possibly add a check to verify the new segments are not over the limit\n",
    "\n",
    "    #after splitting it up, either have the funtion return the list of token segments or list of strings to be tokenized\n",
    "\n",
    "\n",
    "\n",
    "print(songSegmentCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode both fullLyricsAdele and fullLyricsLilTecca\n",
    "tokens = tokenizer.encode([fullLyricsAdele,fullLyricsLilTecca], return_tensors=\"pt\")\n",
    "\n",
    "#keep track of the two songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakUpLyricsToFitModel(fullLyricsString):\n",
    "    songSegmentCount = 1\n",
    "    songSegments=[fullLyricsString]\n",
    "    tokenSegments = []\n",
    "\n",
    "    #convert the string to a list of lines in the string\n",
    "    lines = fullLyricsString.splitlines()[1:-1]#NOTE: THIS MIGHT NOT WORK WITH GENIUS LYRICS\n",
    "\n",
    "    tokens = tokenizer.encode(fullLyricsString)\n",
    "    max_length = model.config.max_position_embeddings #aka 512, could hard-code it to 512\n",
    "    if len(tokens) > max_length:\n",
    "        songSegments=[]\n",
    "        songSegmentCount = int(len(tokens)/max_length)+1\n",
    "        averageSegmentSize = int(len(tokens)/songSegmentCount)\n",
    "\n",
    "        #for the number of songSegmentCount, decode the tokens by the average segment size to get the string\n",
    "        for i in range(songSegmentCount):\n",
    "            #decode the tokens by the average segment size to get the string\n",
    "            startidx=averageSegmentSize*(i)\n",
    "            if i == 0:\n",
    "                startidx+=1\n",
    "            endidx=averageSegmentSize*(i+1)\n",
    "            if i == songSegmentCount-1:\n",
    "                endidx-=1\n",
    "\n",
    "            segment = tokenizer.decode(tokens[startidx:endidx])\n",
    "            #if the segment is not at the end of a line, then find the next line break and add it to the segment\n",
    "            if segment[-1] != ' ':\n",
    "\n",
    "\n",
    "            songSegments.append(tokenizer.decode(tokens[startidx:endidx]))\n",
    "\n",
    "    for segment in songSegments:\n",
    "\n",
    "        #if cuda is available,  add to tokenSegments\n",
    "        if torch.cuda.is_available():\n",
    "            tokenSegments.append(tokenizer.encode(segment, return_tensors=\"pt\").cuda())\n",
    "        else:\n",
    "            tokenSegments.append(tokenizer.encode(segment, return_tensors=\"pt\"))\n",
    "\n",
    "    #NOTE: I should add a check for the chunk size to make sure it is still not over the max length\n",
    "    return tokenSegments, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Intro ] Nah, nah, nah Yeah, oh - oh Yeah, oh no We love you Tecca Yeah, yeah She just hit my phone, she said, \" Tecca, you a winner \" ( That's Tec ) I just took her home, then I turn her to a sinner, yeah Rambow [ Chorus ] She just hit my phone, she said, \" Tecca, you a winner \" ( Yeah ) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I ’ m a star I just wanna ball with my guys Drive off the Wock ', he just caught a DUI He think he know the answers, nigga, like he Bill Nye [ Verse ] Bitch, I feel like A. I., nigga, never need to practice I got two clips'cause that chopper automatic And I started talkin ’ shit, I got tired of this rappin'But I been making'hits, most these niggas, they been nappin'And my lyrics hit her\n",
      "-1\n",
      "hard, like her nigga, he was stabbin'LSD hit his brain, yeah, that nigga, he been tabbin'I just got your shorty, yeah, my niggas, we been tappin'Walk to the bank, Chief Keef, I be laughin'Red, blue, yellow, nigga, you could pick your Power Ranger I could fuck, but I won ’ t date ya Getting bands, but I can ’ t save her Fast nigga, but I can't chase her 360, quick scope, FaZe him God - mode, aim - bot, laser Cut you off, I got that razor [ Chorus ] She just hit my phone, she said, \" Tecca, you a winner \" ( Yeah ) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they sayin ’ I'm a star I just wanna ball with my guys Drive off the Wock ', he just caught a DUI He think he got the answers, nigga, like he Bill Nye\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "x,lines = breakUpLyricsToFitModel(fullLyricsLilTecca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Intro]'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Breaking up by headers\n",
    "\n",
    "Now that we accounted for the limit, we can break up the lyrics by headers and split large chunks if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Final Function For Inferences based on Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-29-7f41d4dde591>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-7f41d4dde591>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    #return the most common label\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def getMoodLabelFromLyrics(model, lyrics, printRawScores=False, printTopN=False):\n",
    "    #probably first need to pass through to the functions the various dictionaries like emotion_dict and emotionsAsValenceArousal\n",
    "\n",
    "\n",
    "    #Deterime the lyrics breakdown (depending on how this is done, my for loop will either be chunks of tokens or lyrics)\n",
    "\n",
    "    #for lyricsChunk in LyricsChunks:\n",
    "        #convert the lyrics to tokens\n",
    "        #feed tokens to model and Get the softmax\n",
    "        #apply the softmax values to the valence and arousal values\n",
    "        #get the average valence and arousal values\n",
    "        #get the label of the appropriate range and keep track of it\n",
    "\n",
    "    #return the most common label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CudaTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2fa8f4dd4130559c9bb206ea5c1e5e62ed157dfd2663e7fcefd868ad60d1c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
