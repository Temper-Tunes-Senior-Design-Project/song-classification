{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if needed, he'll use for arousal: neutral/suprise\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:\n",
    "\"uriyas model total emotions: happy, sad, disgust, fear, neutral, anger, surprise\"\n",
    "\"use for valence: happy/sad\"\n",
    "\"if needed, he'll use for arousal: neutral/suprise\"\n",
    "#THEN, for me:\n",
    "#map the emotions to (x,y) coordinates of valence and arousal, then multiply it by the probability of the emotion, then take the weighted average and get the reslting x,y coordinates\n",
    "#valence and arousal are the two dimensions of the circumplex model and the resulting scores should get put in one of the 9(nuetral plus 8 categories) categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions: Testing Input to the Model, Adding Softmax Layer, Conversion Function for final Label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlar5\\anaconda3\\envs\\CudaTest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model monologg/bert-base-cased-goemotions-original from huggingface\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model on a sentence\n",
    "sentence = \"I am so happy\"\n",
    "tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "tokens = tokens.cuda()\n",
    "result = model(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Playing around/testing model (skip)\n",
    "this is to figure out what will be needed making softmax, and determining the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "#determine the max size of the input the model can handle\n",
    "max_length = model.config.max_position_embeddings\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 0, 13]\n"
     ]
    }
   ],
   "source": [
    "#identify the top 3 emotion with the highest probability\n",
    "emotion = result.logits\n",
    "emotion = emotion.cpu().detach().numpy()\n",
    "emotion = emotion[0]\n",
    "emotion = emotion.argsort()[-3:][::-1]\n",
    "emotion = emotion.tolist()\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert model.config.id2label to a list of emotions, where the key is the index of the emotion\n",
    "emotion_dict = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "admiration\n",
      "excitement\n"
     ]
    }
   ],
   "source": [
    "#identify the label of top 3 emotions from emotion list\n",
    "for i in emotion:\n",
    "    print(emotion_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "#identify the emotion with the highest probability\n",
    "emotion = result.logits.argmax()\n",
    "print(emotion)\n",
    "#which emotion is that?\n",
    "print(model.config.id2label[emotion.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['admiration', 'amusement', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'anger', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict.values()\n",
    "emotionGroups=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionSet = set(emotion_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "approvedMoods=['neutral']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoftmax(model, sentence, n,printRawScores=False, printTopN=True):\n",
    "    tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    tokens = tokens.cuda()\n",
    "    result = model(tokens)\n",
    "    emotion = result.logits\n",
    "    emotion = emotion.cpu().detach().numpy()\n",
    "    emotion = emotion[0]\n",
    "    softmax = tf.nn.softmax(emotion)\n",
    "    if printRawScores:\n",
    "        print(softmax)\n",
    "    \n",
    "    if printTopN:\n",
    "        emotion = emotion.argsort()[-n:][::-1]\n",
    "        emotion = emotion.tolist()\n",
    "        printTopEmotions(emotion,model, softmax)\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def printTopEmotions(emotion, model, softmax):\n",
    "    \n",
    "    #identify the label of top n emotions from emotion list\n",
    "    #softmax is in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    emotion_dict = model.config.id2label\n",
    "    for i in emotion:\n",
    "        print(emotion_dict[i])\n",
    "        print(softmax[emotion[id]].numpy()*100,\"%\")\n",
    "        id+=1\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences from songs to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear2 = \"'Cause you see people, people, people, people Don't really know you (They don't really know you) They don't really know you 'Cause you see people, people, people They don't really know you (Mmm) They don't really know—\"\n",
    "unclear = \"I've been drinking more alcohol for the past five days Did you check on me? Now, did you look for me? I walked in the room, eyes are red and I don't smoke banga Did you check on me? (Did you check on me?) Now, did you notice me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "braggingLyrics = \"She just hit my phone, she said, 'Tecca, you a winner' (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I’m a star I just wanna ball with my guys Drive off the Wock', he just caught a DUI He think he know the answers, nigga, like he Bill Nye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadMetaphoricLyrics = \"Hello darkness, my old friend, I've come to talk with you again, because a vision softly creeping, left its seeds while I was sleeping.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "goEasyOnMeSad = \"There ain't no gold in this river That I've been washin' my hands in forever I know there is hope in these waters But I can't bring myself to swim When I am drowning in this silence Baby, let me in. Go easy on me, baby I was still a child Didn't get the chance to Feel the world around me I had no time to choose what I chose to do So go easy on me\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curiosity\n",
      "99.90363121032715 %\n",
      "neutral\n",
      "0.034640790545381606 %\n",
      "confusion\n",
      "0.019302892906125635 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear=getSoftmax(model, unclear, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.9980092048645 %\n",
      "annoyance\n",
      "0.00058388282013766 %\n",
      "disappointment\n",
      "0.0003420888106120401 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear2=getSoftmax(model,unclear2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "75.65684914588928 %\n",
      "joy\n",
      "16.482388973236084 %\n",
      "excitement\n",
      "4.176769405603409 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestBraggingLyrics=getSoftmax(model,braggingLyrics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.99864101409912 %\n",
      "annoyance\n",
      "0.00020481845695030643 %\n",
      "caring\n",
      "0.00011883536217283108 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestsadMetaphoricLyrics=getSoftmax(model,sadMetaphoricLyrics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointment\n",
      "63.13481330871582 %\n",
      "realization\n",
      "14.627596735954285 %\n",
      "sadness\n",
      "14.258602261543274 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestgoEasyOnMeSad=getSoftmax(model,goEasyOnMeSad, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax Recap:\n",
    "\n",
    "1. There seems to be a dominance of neutral while the trailing classes seem to be more relevant. This does make sense considering the fact that not every lyric is emotionally charged.  \n",
    "\n",
    "- However, this does raise the question, \"How do we handle neutral?\"\n",
    "\n",
    "- similarly, \"Do we want neutral as a resulting category?\n",
    "\n",
    "2. Songs that are reliant on metaphores or to create emotion will not be captured via sentiment analysis\n",
    "\n",
    "- In these cases, we would want the linear model to give results\n",
    "- perhaps if this is specifially reated neutral we should rely on the linear classificiaton model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conversion Without Special Neutral Considerations\n",
    "\n",
    "Here we will:\n",
    "1. scale emotions to (valence, energy) based on the valence-arousal mood wheel\n",
    "2. multiply that value by the percent\n",
    "3. add up x values as well as y values\n",
    "4. place resulting values into the 8 main mood categories to get a class\n",
    "5. if close to 0, label it neutral instead\n",
    "    - If neutral, perhaps use as indicator to rely on 2nd model for classification\n",
    "\n",
    "NOTE: Some words did not have a perfect point plotted, but there were some synonyms\n",
    "- approval was mapped with satisfied\n",
    "- caring was with passionate\n",
    "- confused with a lessened amount of frustrated (1/2)\n",
    "- curious was mapped with interested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mood setup verification (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration\n",
      "amusement\n",
      "anger\n",
      "annoyance\n",
      "approval\n",
      "caring\n",
      "confusion\n",
      "curiosity\n",
      "desire\n",
      "disappointment\n",
      "disapproval\n",
      "disgust\n",
      "embarrassment\n",
      "excitement\n",
      "fear\n",
      "gratitude\n",
      "grief\n",
      "joy\n",
      "love\n",
      "nervousness\n",
      "optimism\n",
      "pride\n",
      "realization\n",
      "relief\n",
      "remorse\n",
      "sadness\n",
      "surprise\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "for key in range(len(emotion_dict)):\n",
    "    print(emotion_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary mapping all emotions to valence and arousal values\n",
    "# valence is the x axis, arousal is the y axis of the circumplex model\n",
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'despair':(-.8,-.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'envy':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,.2),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6, 0.4)\n",
      "(0.6, 0.2)\n",
      "(-0.8, 0.6)\n",
      "(-0.6, 0.6)\n",
      "(0.8, 0.6)\n",
      "(0.6, -0.2)\n",
      "(-0.2, 0.2)\n",
      "(0, 0.4)\n",
      "(0.6, 0.6)\n",
      "(-0.6, -0.6)\n",
      "(-0.8, 0.65)\n",
      "(-0.8, 0.2)\n",
      "(-0.6, 0.4)\n",
      "(0.6, 0.8)\n",
      "(-0.6, 0.8)\n",
      "(0.6, -0.6)\n",
      "(-0.6, -0.8)\n",
      "(0.8, 0.2)\n",
      "(0.8, 0.4)\n",
      "(-0.4, 0.6)\n",
      "(0.6, 0.2)\n",
      "(0.6, 0.1)\n",
      "(0.2, 0.2)\n",
      "(0.4, -0.4)\n",
      "(-0.6, -0.4)\n",
      "(-0.8, -0.2)\n",
      "(0.2, 0.6)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "emotion_dict = model.config.id2label\n",
    "for i in range(len(emotion_dict)):\n",
    "    print(emotionsAsValenceArousal[emotion_dict[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'despair':(-.8,-.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'envy':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,.2),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertScoresToLabels(softmaxScores, emotionsAsValenceArousal,emotion_dict):\n",
    "    #convert the softmax scores to a valence and arousal score\n",
    "    #softmax scores are in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    valence=0\n",
    "    arousal=0\n",
    "    for i in softmaxScores:\n",
    "        valence+=i*emotionsAsValenceArousal[emotion_dict[id]][0]\n",
    "        arousal+=i*emotionsAsValenceArousal[emotion_dict[id]][1]\n",
    "        id+=1\n",
    "    #convert valence and arousal from tensor to float\n",
    "    valence = valence.numpy()\n",
    "    arousal = arousal.numpy()\n",
    "    return valence,arousal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00014550616, 0.39976904)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear, emotionsAsValenceArousal,emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.28967e-06, 4.1340345e-06)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear2, emotionsAsValenceArousal,emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17935042, 0.0792139)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestBraggingLyrics, emotionsAsValenceArousal,emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.578913e-06, 2.6779267e-06)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestsadMetaphoricLyrics, emotionsAsValenceArousal,emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4687149, -0.37509394)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestgoEasyOnMeSad, emotionsAsValenceArousal,emotion_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conversion With Special Neutral Considerations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Breaking up Lyrics to fit into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "longLyricsTest = \"\"\"\n",
    "Nah, nah, nah\n",
    "Yeah, oh-oh\n",
    "Yeah, oh no\n",
    "We love you Tecca\n",
    "Yeah, yeah\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (That's Tec)\n",
    "I just took her home, then I turn her to a sinner, yeah\n",
    "Rambow\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they say that I’m a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he know the answers, nigga, like he Bill Nye\n",
    "[Verse]\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they sayin’ I'm a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he got the answers, nigga, like he Bill Nye but I try not to die\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(longLyricsTest, return_tensors=\"pt\")\n",
    "tokens = tokens.cuda()\n",
    "max_length = model.config.max_position_embeddings\n",
    "#if the tokens are too long, break them up and put them in a list\n",
    "if len(tokens[0]) > max_length:\n",
    "    print('??')\n",
    "    tokens = tokens.split(max_length)\n",
    "#len(tokens[0][0])\n",
    "\n",
    "#result = model(tokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Function For Inferences based on Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoodLabelFromLyrics(model, lyrics, printRawScores=False, printTopN=False):\n",
    "    #probably first need to pass through to the functions the various dictionaries like emotion_dict and emotionsAsValenceArousal\n",
    "\n",
    "\n",
    "    #Deterime the lyrics breakdown (depending on how this is done, my for loop will either be chunks of tokens or lyrics)\n",
    "\n",
    "    #for lyricsChunk in LyricsChunks:\n",
    "        #convert the lyrics to tokens\n",
    "        #feed tokens to model and Get the softmax\n",
    "        #apply the softmax values to the valence and arousal values\n",
    "        #get the average valence and arousal values\n",
    "        #get the label of the appropriate range and keep track of it\n",
    "\n",
    "    #return the most common label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CudaTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2fa8f4dd4130559c9bb206ea5c1e5e62ed157dfd2663e7fcefd868ad60d1c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
