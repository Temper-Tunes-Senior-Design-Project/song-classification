{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if needed, he'll use for arousal: neutral/suprise\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:\n",
    "\"uriyas model total emotions: happy, sad, disgust, fear, neutral, anger, surprise\"\n",
    "\"use for valence: happy/sad\"\n",
    "\"if needed, he'll use for arousal: neutral/suprise\"\n",
    "#THEN, for me:\n",
    "#map the emotions to (x,y) coordinates of valence and arousal, then multiply it by the probability of the emotion, then take the weighted average and get the reslting x,y coordinates\n",
    "#valence and arousal are the two dimensions of the circumplex model and the resulting scores should get put in one of the 9(nuetral plus 8 categories) categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions: Testing Input to the Model, Adding Softmax Layer, Conversion Function for final Label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlar5\\anaconda3\\envs\\CudaTest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model monologg/bert-base-cased-goemotions-original from huggingface\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model on a sentence\n",
    "sentence = \"I am so happy\"\n",
    "tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "tokens = tokens.cuda()\n",
    "result = model(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Playing around/testing model (skip)\n",
    "this is to figure out what will be needed making softmax, and determining the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "#determine the max size of the input the model can handle\n",
    "max_length = model.config.max_position_embeddings\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 0, 13]\n"
     ]
    }
   ],
   "source": [
    "#identify the top 3 emotion with the highest probability\n",
    "emotion = result.logits\n",
    "emotion = emotion.cpu().detach().numpy()\n",
    "emotion = emotion[0]\n",
    "emotion = emotion.argsort()[-3:][::-1]\n",
    "emotion = emotion.tolist()\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert model.config.id2label to a list of emotions, where the key is the index of the emotion\n",
    "emotion_dict = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "admiration\n",
      "excitement\n"
     ]
    }
   ],
   "source": [
    "#identify the label of top 3 emotions from emotion list\n",
    "for i in emotion:\n",
    "    print(emotion_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "#identify the emotion with the highest probability\n",
    "emotion = result.logits.argmax()\n",
    "print(emotion)\n",
    "#which emotion is that?\n",
    "print(model.config.id2label[emotion.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['admiration', 'amusement', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'anger', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_dict.values()\n",
    "emotionGroups=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionSet = set(emotion_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "approvedMoods=['neutral']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoftmax(model, sentence, n,printRawScores=False, printTopN=True):\n",
    "    tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    tokens = tokens.cuda()\n",
    "    result = model(tokens)\n",
    "    emotion = result.logits\n",
    "    emotion = emotion.cpu().detach().numpy()\n",
    "    emotion = emotion[0]\n",
    "    softmax = tf.nn.softmax(emotion)\n",
    "    if printRawScores:\n",
    "        print(softmax)\n",
    "    \n",
    "    if printTopN:\n",
    "        emotion = emotion.argsort()[-n:][::-1]\n",
    "        emotion = emotion.tolist()\n",
    "        printTopEmotions(emotion,model, softmax)\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def printTopEmotions(emotion, model, softmax):\n",
    "    \n",
    "    #identify the label of top n emotions from emotion list\n",
    "    #softmax is in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    emotion_dict = model.config.id2label\n",
    "    for i in emotion:\n",
    "        print(emotion_dict[i])\n",
    "        print(softmax[emotion[id]].numpy()*100,\"%\")\n",
    "        id+=1\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences from songs to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear2 = \"'Cause you see people, people, people, people Don't really know you (They don't really know you) They don't really know you 'Cause you see people, people, people They don't really know you (Mmm) They don't really know—\"\n",
    "unclear = \"I've been drinking more alcohol for the past five days Did you check on me? Now, did you look for me? I walked in the room, eyes are red and I don't smoke banga Did you check on me? (Did you check on me?) Now, did you notice me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "braggingLyrics = \"She just hit my phone, she said, 'Tecca, you a winner' (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I’m a star I just wanna ball with my guys Drive off the Wock', he just caught a DUI He think he know the answers, nigga, like he Bill Nye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadMetaphoricLyrics = \"Hello darkness, my old friend, I've come to talk with you again, because a vision softly creeping, left its seeds while I was sleeping.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "goEasyOnMeSad = \"There ain't no gold in this river That I've been washin' my hands in forever I know there is hope in these waters But I can't bring myself to swim When I am drowning in this silence Baby, let me in. Go easy on me, baby I was still a child Didn't get the chance to Feel the world around me I had no time to choose what I chose to do So go easy on me\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curiosity\n",
      "99.90363121032715 %\n",
      "neutral\n",
      "0.034640790545381606 %\n",
      "confusion\n",
      "0.019302892906125635 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear=getSoftmax(model, unclear, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.9980092048645 %\n",
      "annoyance\n",
      "0.00058388282013766 %\n",
      "disappointment\n",
      "0.0003420888106120401 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear2=getSoftmax(model,unclear2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "75.65684914588928 %\n",
      "joy\n",
      "16.482388973236084 %\n",
      "excitement\n",
      "4.176769405603409 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestBraggingLyrics=getSoftmax(model,braggingLyrics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.99864101409912 %\n",
      "annoyance\n",
      "0.00020481845695030643 %\n",
      "caring\n",
      "0.00011883536217283108 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestsadMetaphoricLyrics=getSoftmax(model,sadMetaphoricLyrics, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointment\n",
      "63.13481330871582 %\n",
      "realization\n",
      "14.627596735954285 %\n",
      "sadness\n",
      "14.258602261543274 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestgoEasyOnMeSad=getSoftmax(model,goEasyOnMeSad, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SoftMax Recap:\n",
    "\n",
    "1. There seems to be a dominance of neutral while the trailing classes seem to be more relevant. This does make sense considering the fact that not every lyric is emotionally charged.  \n",
    "\n",
    "- However, this does raise the question, \"How do we handle neutral?\"\n",
    "\n",
    "- similarly, \"Do we want neutral as a resulting category?\n",
    "\n",
    "2. Songs that are reliant on metaphores or to create emotion will not be captured via sentiment analysis\n",
    "\n",
    "- In these cases, we would want the linear model to give results\n",
    "- perhaps if this is specifially reated neutral we should rely on the linear classificiaton model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Conversion Without Special Neutral Considerations\n",
    "\n",
    "Here we will:\n",
    "1. scale emotions to (valence, energy) based on the valence-arousal mood wheel\n",
    "2. multiply that value by the percent\n",
    "3. add up x values as well as y values\n",
    "4. place resulting values into the 8 main mood categories to get a class\n",
    "5. if close to 0, label it neutral instead\n",
    "    - If neutral, perhaps use as indicator to rely on 2nd model for classification\n",
    "\n",
    "NOTE: Some words did not have a perfect point plotted, but there were some synonyms\n",
    "- approval was mapped with satisfied\n",
    "- caring was with passionate\n",
    "- confused with a lessened amount of frustrated (1/2)\n",
    "- curious was mapped with interested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mood setup verification (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration\n",
      "amusement\n",
      "anger\n",
      "annoyance\n",
      "approval\n",
      "caring\n",
      "confusion\n",
      "curiosity\n",
      "desire\n",
      "disappointment\n",
      "disapproval\n",
      "disgust\n",
      "embarrassment\n",
      "excitement\n",
      "fear\n",
      "gratitude\n",
      "grief\n",
      "joy\n",
      "love\n",
      "nervousness\n",
      "optimism\n",
      "pride\n",
      "realization\n",
      "relief\n",
      "remorse\n",
      "sadness\n",
      "surprise\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "for key in range(len(emotion_dict)):\n",
    "    print(emotion_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary mapping all emotions to valence and arousal values\n",
    "# valence is the x axis, arousal is the y axis of the circumplex model\n",
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,-.3),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6, 0.4)\n",
      "(0.6, 0.2)\n",
      "(-0.8, 0.6)\n",
      "(-0.6, 0.6)\n",
      "(0.8, 0.6)\n",
      "(0.6, -0.2)\n",
      "(-0.2, 0.2)\n",
      "(0, 0.4)\n",
      "(0.6, 0.6)\n",
      "(-0.6, -0.6)\n",
      "(-0.8, 0.65)\n",
      "(-0.8, 0.2)\n",
      "(-0.6, 0.4)\n",
      "(0.6, 0.8)\n",
      "(-0.6, 0.8)\n",
      "(0.6, -0.6)\n",
      "(-0.6, -0.8)\n",
      "(0.8, 0.2)\n",
      "(0.8, 0.4)\n",
      "(-0.4, 0.6)\n",
      "(0.6, -0.3)\n",
      "(0.6, 0.1)\n",
      "(0.2, 0.2)\n",
      "(0.4, -0.4)\n",
      "(-0.6, -0.4)\n",
      "(-0.8, -0.2)\n",
      "(0.2, 0.6)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "emotion_dict = model.config.id2label\n",
    "for i in range(len(emotion_dict)):\n",
    "    print(emotionsAsValenceArousal[emotion_dict[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'despair':(-.8,-.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'envy':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,.2),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n",
    "#moods=['energetic','excited','happy','relaxed','calm','depressed','sad','anxious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determineMoodLabel(valence,arousal):\n",
    "    #determine the diagonal of the circumplex model that the valence and arousal scores fall on\n",
    "    #MAKE 2 BOXES OF THE CIRCUMPLEX MODEL A MOOD \n",
    "\n",
    "    energetic =   -0.5<valence<0.5 and arousal>0.5\n",
    "    happy =       valence>0.5 and -.5<arousal<0.5\n",
    "    calm =       -0.5<valence<0.5 and arousal<-0.5\n",
    "    sad =         valence<-0.5 and -.5<arousal<0.5\n",
    "\n",
    "    excited =   not (happy or energetic) and valence>0 and arousal>0\n",
    "    relaxed =   not (calm or happy) and valence>0 and arousal<0\n",
    "    depressed = not (calm or sad) and valence<0 and arousal<0\n",
    "    anxious =   not (energetic or sad) and valence<0 and arousal>0\n",
    "\n",
    "\n",
    "    if energetic:\n",
    "        mood='energetic'\n",
    "    elif happy:\n",
    "        mood='happy'\n",
    "    elif calm:\n",
    "        mood='calm'\n",
    "    elif sad:\n",
    "        mood='sad'\n",
    "    elif excited:\n",
    "        mood='excited'\n",
    "    elif relaxed:\n",
    "        mood='relaxed'\n",
    "    elif depressed:\n",
    "        mood='depressed'\n",
    "    elif anxious:\n",
    "        mood='anxious'\n",
    "    else:\n",
    "        mood='neutral'\n",
    "    return mood     \n",
    "\n",
    "def convertScoresToLabels(softmaxScores, emotionsAsValenceArousal,emotion_dict,printValenceArousal=False):\n",
    "    #convert the softmax scores to a valence and arousal score\n",
    "    #softmax scores are in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    valence=0\n",
    "    arousal=0\n",
    "    for i in softmaxScores:\n",
    "        valence+=i*emotionsAsValenceArousal[emotion_dict[id]][0]\n",
    "        arousal+=i*emotionsAsValenceArousal[emotion_dict[id]][1]\n",
    "        id+=1\n",
    "    #convert valence and arousal from tensor to float\n",
    "    valence = valence.numpy()\n",
    "    arousal = arousal.numpy()\n",
    "    mood =determineMoodLabel(valence,arousal)\n",
    "    if printValenceArousal:\n",
    "        print(\"Valence: \",valence)\n",
    "        print(\"Arousal: \",arousal)\n",
    "    return mood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken function but cleaner code (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def determineMoodLabel(valence, arousal):\n",
    "    conditions = {\n",
    "        'energetic': (-0.5 < valence < 0.5) and (arousal > 0.5),\n",
    "        'happy': (valence > 0.5) and (-0.5 < arousal < 0.5),\n",
    "        'calm': (-0.5 < valence < 0.5) and (arousal < -0.5),\n",
    "        'sad': (valence < -0.5) and (-0.5 < arousal < 0.5),\n",
    "    }\n",
    "    conditions['excited']= (valence > 0) and (arousal > 0) and not ((conditions.get('happy') == True) or (conditions.get('energetic') == True))\n",
    "    conditions['relaxed'] =(valence > 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('happy') == True)),\n",
    "    conditions['depressed']= (valence < 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('sad') == True)),\n",
    "    conditions['anxious']= (valence < 0) and (arousal > 0) and not ((conditions.get('energetic') == True) or (conditions.get('sad') == True))\n",
    "\n",
    "    for mood, condition in conditions.items():\n",
    "        #print(mood)\n",
    "        if condition:\n",
    "            if condition:\n",
    "            #print(condition)\n",
    "                return mood\n",
    "    return 'neutral'\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determineMoodLabel(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.00014550616\n",
      "Arousal:  0.39976904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear, emotionsAsValenceArousal,emotion_dict,printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -6.28967e-06\n",
      "Arousal:  4.1340345e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear2, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.17935042\n",
      "Arousal:  0.0792139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestBraggingLyrics, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -1.578913e-06\n",
      "Arousal:  2.6779267e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestsadMetaphoricLyrics, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.4687149\n",
      "Arousal:  -0.37509394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'depressed'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestgoEasyOnMeSad, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Conversion Recap:\n",
    "\n",
    "- The code works but it tends to classify heavily towards the center of the coordinates\n",
    "- NOTE: This could be because it was just a few small samples, which may not reflect the overall distribution of the data\n",
    "- As an alternative, we could remove the neutral score and apply softmax to the remaining classes\n",
    "- OR, I could just exclude the inputs that result in overwhemingly neutral, and then continue to the next chunk of lyrics until I find all chunks that are not neutral and then get the average of those to get the final classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Class Conversion With Special Neutral Considerations\n",
    "\n",
    "First, in 6 and 7, we will try to get the average of the classes that are not overwhelmingly neutral to get final label.\n",
    "\n",
    "If that doesnt work, here we will drop the neutral score and apply softmax to the remaining classes\n",
    "\n",
    "- This would allow us to multiply the coordinates without shrinking the values due to the neutral score\n",
    "- Perhaps this would allow us to reach the classes that are further away from the center\n",
    "- If not, we could shift the boundaries of the classes closer to the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Breaking up Lyrics to fit into model\n",
    "\n",
    "In order to fit the lyrics into the model, we need to break up the lyrics. There are various ways to do this. We will try a few different methods and see which one works best.\n",
    "\n",
    "- We could break up the lyrics into 100 word chunks as that is what the model was trained on (maybe?)\n",
    "- We could break it up by sentences\n",
    "- We could break it up by line\n",
    "- We could break it up by paragraphs/verses/choruses etc. Below are the various headers that we could use to break up the lyrics\n",
    "https://genius.com/Genius-song-sections-and-headers-guide-annotated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "longLyricsTest = \"\"\"\n",
    "[Intro]\n",
    "Nah, nah, nah\n",
    "Yeah, oh-oh\n",
    "Yeah, oh no\n",
    "We love you Tecca\n",
    "Yeah, yeah\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (That's Tec)\n",
    "I just took her home, then I turn her to a sinner, yeah\n",
    "Rambow\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they say that I’m a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he know the answers, nigga, like he Bill Nye\n",
    "[Verse]\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they sayin’ I'm a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he got the answers, nigga, like he Bill Nye\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(longLyricsTest, return_tensors=\"pt\")\n",
    "tokens = tokens.cuda()\n",
    "max_length = model.config.max_position_embeddings\n",
    "#if the tokens are too long, break them up and put them in a list\n",
    "if len(tokens[0]) > max_length:\n",
    "    print('??')\n",
    "    tokens = tokens.split(max_length)\n",
    "#len(tokens[0][0])\n",
    "\n",
    "#result = model(tokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Function For Inferences based on Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoodLabelFromLyrics(model, lyrics, printRawScores=False, printTopN=False):\n",
    "    #probably first need to pass through to the functions the various dictionaries like emotion_dict and emotionsAsValenceArousal\n",
    "\n",
    "\n",
    "    #Deterime the lyrics breakdown (depending on how this is done, my for loop will either be chunks of tokens or lyrics)\n",
    "\n",
    "    #for lyricsChunk in LyricsChunks:\n",
    "        #convert the lyrics to tokens\n",
    "        #feed tokens to model and Get the softmax\n",
    "        #apply the softmax values to the valence and arousal values\n",
    "        #get the average valence and arousal values\n",
    "        #get the label of the appropriate range and keep track of it\n",
    "\n",
    "    #return the most common label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CudaTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2fa8f4dd4130559c9bb206ea5c1e5e62ed157dfd2663e7fcefd868ad60d1c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
