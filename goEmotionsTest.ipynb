{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if needed, he'll use for arousal: neutral/suprise\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:\n",
    "\"uriyas model total emotions: happy, sad, disgust, fear, neutral, anger, surprise\"\n",
    "\"use for valence: happy/sad\"\n",
    "\"if needed, he'll use for arousal: neutral/suprise\"\n",
    "#THEN, for me:\n",
    "#map the emotions to (x,y) coordinates of valence and arousal, then multiply it by the probability of the emotion, then take the weighted average and get the reslting x,y coordinates\n",
    "#valence and arousal are the two dimensions of the circumplex model and the resulting scores should get put in one of the 9(nuetral plus 8 categories) categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions: Testing Input to the Model, Adding Softmax Layer, Conversion Function for getting segment Label, Getting final Label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlar5\\anaconda3\\envs\\CudaTest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model monologg/bert-base-cased-goemotions-original from huggingface\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  146, 1821, 1177, 2816,  102]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#test the model on a sentence\n",
    "sentence = \"I am so happy\"\n",
    "tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "tokens = tokens.cuda()\n",
    "print(tokens)\n",
    "result = model(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Playing around/testing model (skip)\n",
    "this is to figure out what will be needed making softmax, and determining the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "#determine the max size of the input the model can handle\n",
    "max_length = model.config.max_position_embeddings\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 0, 13]\n"
     ]
    }
   ],
   "source": [
    "#identify the top 3 emotion with the highest probability\n",
    "emotion = result.logits\n",
    "emotion = emotion.cpu().detach().numpy()\n",
    "emotion = emotion[0]\n",
    "emotion = emotion.argsort()[-3:][::-1]\n",
    "emotion = emotion.tolist()\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert model.config.id2label to a list of emotions, where the key is the index of the emotion\n",
    "emotion_dict = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "admiration\n",
      "excitement\n"
     ]
    }
   ],
   "source": [
    "#identify the label of top 3 emotions from emotion list\n",
    "for i in emotion:\n",
    "    print(emotion_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "#identify the emotion with the highest probability\n",
    "emotion = result.logits.argmax()\n",
    "print(emotion)\n",
    "#which emotion is that?\n",
    "print(model.config.id2label[emotion.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict.values()\n",
    "emotionGroups=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionSet = set(emotion_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "approvedMoods=['neutral']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoftmax(model,tokenizer, tokens = None, sentence=None, n=3,printRawScores=False, printTopN=False):\n",
    "    if tokens is None:\n",
    "        tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "        tokens = tokens.cuda()\n",
    "    result = model(tokens)\n",
    "    emotion = result.logits\n",
    "    emotion = emotion.cpu().detach().numpy()\n",
    "    emotion = emotion[0]\n",
    "    softmax = tf.nn.softmax(emotion)\n",
    "    #convert to numpy array\n",
    "    softmax = softmax.numpy()\n",
    "    if printRawScores:\n",
    "        print(softmax)\n",
    "    \n",
    "    if printTopN:\n",
    "        emotion = emotion.argsort()[-n:][::-1]\n",
    "        emotion = emotion.tolist()\n",
    "        printTopEmotions(emotion,model, softmax)\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def printTopEmotions(emotion, model, softmax):\n",
    "    \n",
    "    #identify the label of top n emotions from emotion list\n",
    "    #softmax is in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    emotion_dict = model.config.id2label\n",
    "    for i in emotion:\n",
    "        print(emotion_dict[i])\n",
    "        print(softmax[emotion[id]]*100,\"%\")\n",
    "        id+=1\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences from songs to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear2 = \"'Cause you see people, people, people, people Don't really know you (They don't really know you) They don't really know you 'Cause you see people, people, people They don't really know you (Mmm) They don't really know—\"\n",
    "unclear = \"I've been drinking more alcohol for the past five days Did you check on me? Now, did you look for me? I walked in the room, eyes are red and I don't smoke banga Did you check on me? (Did you check on me?) Now, did you notice me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "braggingLyrics = \"She just hit my phone, she said, 'Tecca, you a winner' (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I’m a star I just wanna ball with my guys Drive off the Wock', he just caught a DUI He think he know the answers, nigga, like he Bill Nye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadMetaphoricLyrics = \"Hello darkness, my old friend, I've come to talk with you again, because a vision softly creeping, left its seeds while I was sleeping.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "goEasyOnMeSad = \"There ain't no gold in this river That I've been washin' my hands in forever I know there is hope in these waters But I can't bring myself to swim When I am drowning in this silence Baby, let me in. Go easy on me, baby I was still a child Didn't get the chance to Feel the world around me I had no time to choose what I chose to do So go easy on me\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curiosity\n",
      "99.90363121032715 %\n",
      "neutral\n",
      "0.034640790545381606 %\n",
      "confusion\n",
      "0.019302892906125635 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear=getSoftmax(model, sentence = unclear, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.9980092048645 %\n",
      "annoyance\n",
      "0.00058388282013766 %\n",
      "disappointment\n",
      "0.0003420888106120401 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear2=getSoftmax(model,sentence =unclear2, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "75.65684914588928 %\n",
      "joy\n",
      "16.482388973236084 %\n",
      "excitement\n",
      "4.176769405603409 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestBraggingLyrics=getSoftmax(model,sentence =braggingLyrics, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.99864101409912 %\n",
      "annoyance\n",
      "0.00020481845695030643 %\n",
      "caring\n",
      "0.00011883536217283108 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestsadMetaphoricLyrics=getSoftmax(model,sentence =sadMetaphoricLyrics, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointment\n",
      "63.13481330871582 %\n",
      "realization\n",
      "14.627596735954285 %\n",
      "sadness\n",
      "14.258602261543274 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestgoEasyOnMeSad=getSoftmax(model,sentence =goEasyOnMeSad, printTopN=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SoftMax Recap:\n",
    "\n",
    "1. There seems to be a dominance of neutral while the trailing classes seem to be more relevant. This does make sense considering the fact that not every lyric is emotionally charged.  \n",
    "\n",
    "- However, this does raise the question, \"How do we handle neutral?\"\n",
    "\n",
    "- similarly, \"Do we want neutral as a resulting category?\n",
    "\n",
    "2. Songs that are reliant on metaphores or to create emotion will not be captured via sentiment analysis\n",
    "\n",
    "- In these cases, we would want the linear model to give results\n",
    "- perhaps if this is specifially reated neutral we should rely on the linear classificiaton model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class Conversion Without Special Neutral Considerations\n",
    "\n",
    "Here we will:\n",
    "1. scale emotions to (valence, energy) based on the valence-arousal mood wheel\n",
    "2. multiply that value by the percent\n",
    "3. add up x values as well as y values\n",
    "4. place resulting values into the 8 main mood categories to get a class\n",
    "5. if close to 0, label it neutral instead\n",
    "    - If neutral, perhaps use as indicator to rely on 2nd model for classification\n",
    "\n",
    "NOTE: Some words did not have a perfect point plotted, but there were some synonyms\n",
    "- approval was mapped with satisfied\n",
    "- caring was with passionate\n",
    "- confused with a lessened amount of frustrated (1/2)\n",
    "- curious was mapped with interested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mood setup verification (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration\n",
      "amusement\n",
      "anger\n",
      "annoyance\n",
      "approval\n",
      "caring\n",
      "confusion\n",
      "curiosity\n",
      "desire\n",
      "disappointment\n",
      "disapproval\n",
      "disgust\n",
      "embarrassment\n",
      "excitement\n",
      "fear\n",
      "gratitude\n",
      "grief\n",
      "joy\n",
      "love\n",
      "nervousness\n",
      "optimism\n",
      "pride\n",
      "realization\n",
      "relief\n",
      "remorse\n",
      "sadness\n",
      "surprise\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "emotion_dict = model.config.id2label\n",
    "for key in range(len(emotion_dict)):\n",
    "    print(emotion_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary mapping all emotions to valence and arousal values\n",
    "# valence is the x axis, arousal is the y axis of the circumplex model\n",
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,-.3),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6, 0.4)\n",
      "(0.6, 0.2)\n",
      "(-0.8, 0.6)\n",
      "(-0.6, 0.6)\n",
      "(0.8, 0.6)\n",
      "(0.6, -0.2)\n",
      "(-0.2, 0.2)\n",
      "(0, 0.4)\n",
      "(0.6, 0.6)\n",
      "(-0.6, -0.6)\n",
      "(-0.8, 0.65)\n",
      "(-0.8, 0.2)\n",
      "(-0.6, 0.4)\n",
      "(0.6, 0.8)\n",
      "(-0.6, 0.8)\n",
      "(0.6, -0.6)\n",
      "(-0.6, -0.8)\n",
      "(0.8, 0.2)\n",
      "(0.8, 0.4)\n",
      "(-0.4, 0.6)\n",
      "(0.6, -0.3)\n",
      "(0.6, 0.1)\n",
      "(0.2, 0.2)\n",
      "(0.4, -0.4)\n",
      "(-0.6, -0.4)\n",
      "(-0.8, -0.2)\n",
      "(0.2, 0.6)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(emotion_dict)):\n",
    "    print(emotionsAsValenceArousal[emotion_dict[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'despair':(-.8,-.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'envy':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,.2),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n",
    "#moods=['energetic','excited','happy','relaxed','calm','depressed','sad','anxious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determineMoodLabel(valence,arousal):\n",
    "    #determine the diagonal of the circumplex model that the valence and arousal scores fall on\n",
    "    #MAKE 2 BOXES OF THE CIRCUMPLEX MODEL A MOOD \n",
    "\n",
    "    energetic =   -0.5<valence<0.5 and arousal>0.5\n",
    "    happy =       valence>0.5 and -.5<arousal<0.5\n",
    "    calm =       -0.5<valence<0.5 and arousal<-0.5\n",
    "    sad =         valence<-0.5 and -.5<arousal<0.5\n",
    "\n",
    "    excited =   not (happy or energetic) and valence>0 and arousal>0\n",
    "    relaxed =   not (calm or happy) and valence>0 and arousal<0\n",
    "    depressed = not (calm or sad) and valence<0 and arousal<0\n",
    "    anxious =   not (energetic or sad) and valence<0 and arousal>0\n",
    "\n",
    "\n",
    "    if energetic:\n",
    "        mood='energetic'\n",
    "    elif happy:\n",
    "        mood='happy'\n",
    "    elif calm:\n",
    "        mood='calm'\n",
    "    elif sad:\n",
    "        mood='sad'\n",
    "    elif excited:\n",
    "        mood='excited'\n",
    "    elif relaxed:\n",
    "        mood='relaxed'\n",
    "    elif depressed:\n",
    "        mood='depressed'\n",
    "    elif anxious:\n",
    "        mood='anxious'\n",
    "    else:\n",
    "        mood='neutral'\n",
    "    return mood     \n",
    "\n",
    "def convertScoresToLabels(softmaxScoresPerHeader,headerFreqs, emotionsAsValenceArousal,emotion_dict,disregardNeutral = True, printValenceArousal=False,printTopChunkEmotions=False):\n",
    "    #convert the softmax scores to a valence and arousal score\n",
    "    #softmax scores are in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    valence=0\n",
    "    arousal=0\n",
    "    #find the key in emotion_dict that corresponds to neutral\n",
    "    neuturalKey = [key for key, value in emotion_dict.items() if value == 'neutral'][0]\n",
    "    for key, softmaxScores in softmaxScoresPerHeader.items():\n",
    "        #check if neutral is the highest softmax score\n",
    "        if disregardNeutral and neuturalKey==softmaxScores.argmax():\n",
    "            continue\n",
    "        else:\n",
    "            #multiply the softmax score by the valence and arousal values and add to the total valence and arousal\n",
    "            #do this for the number in the headerFreqs dictionary\n",
    "            for i in range(headerFreqs[key]):\n",
    "                id=0\n",
    "                for i in softmaxScores:\n",
    "                    valence+=i*emotionsAsValenceArousal[emotion_dict[id]][0]\n",
    "                    arousal+=i*emotionsAsValenceArousal[emotion_dict[id]][1]\n",
    "                    id+=1\n",
    "    mood =determineMoodLabel(valence,arousal)\n",
    "    if printValenceArousal:\n",
    "        print(\"Valence: \",valence)\n",
    "        print(\"Arousal: \",arousal)\n",
    "    return mood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken function but cleaner code (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def determineMoodLabel(valence, arousal):\n",
    "    conditions = {\n",
    "        'energetic': (-0.5 < valence < 0.5) and (arousal > 0.5),\n",
    "        'happy': (valence > 0.5) and (-0.5 < arousal < 0.5),\n",
    "        'calm': (-0.5 < valence < 0.5) and (arousal < -0.5),\n",
    "        'sad': (valence < -0.5) and (-0.5 < arousal < 0.5),\n",
    "    }\n",
    "    conditions['excited']= (valence > 0) and (arousal > 0) and not ((conditions.get('happy') == True) or (conditions.get('energetic') == True))\n",
    "    conditions['relaxed'] =(valence > 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('happy') == True)),\n",
    "    conditions['depressed']= (valence < 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('sad') == True)),\n",
    "    conditions['anxious']= (valence < 0) and (arousal > 0) and not ((conditions.get('energetic') == True) or (conditions.get('sad') == True))\n",
    "\n",
    "    for mood, condition in conditions.items():\n",
    "        #print(mood)\n",
    "        if condition:\n",
    "            if condition:\n",
    "            #print(condition)\n",
    "                return mood\n",
    "    return 'neutral'\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determineMoodLabel(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.00014550616\n",
      "Arousal:  0.39976904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear, emotionsAsValenceArousal,emotion_dict,printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -6.28967e-06\n",
      "Arousal:  4.1340345e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestUnclear2, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.17935042\n",
      "Arousal:  0.0792139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestBraggingLyrics, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -1.578913e-06\n",
      "Arousal:  2.6779267e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestsadMetaphoricLyrics, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.4687149\n",
      "Arousal:  -0.37509394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'depressed'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels(softmaxtestgoEasyOnMeSad, emotionsAsValenceArousal,emotion_dict,True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class Conversion Recap:\n",
    "\n",
    "- The code works but it tends to classify heavily towards the center of the coordinates\n",
    "- NOTE: This could be because it was just a few small samples, which may not reflect the overall distribution of the data\n",
    "- As an alternative, we could remove the neutral score and apply softmax to the remaining classes\n",
    "- OR, I could just exclude the inputs that result in overwhemingly neutral, and then continue to the next chunk of lyrics until I find all chunks that are not neutral and then get the average of those to get the final classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Class Conversion With Special Neutral Considerations\n",
    "\n",
    "First, in 6 and 7, we will try to get the average of the classes that are not overwhelmingly neutral to get final label.\n",
    "\n",
    "If that doesnt work, here we will drop the neutral score and apply softmax to the remaining classes\n",
    "\n",
    "- This would allow us to multiply the coordinates without shrinking the values due to the neutral score\n",
    "- Perhaps this would allow us to reach the classes that are further away from the center\n",
    "- If not, we could shift the boundaries of the classes closer to the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Breaking up Lyrics to fit into model\n",
    "\n",
    "In order to fit the lyrics into the model, we need to break up the lyrics. There are various ways to do this. We will try a few different methods and see which one works best.\n",
    "\n",
    "\n",
    "- (Best) We could break it up by headers. Below are the various headers that we could use to break up the lyrics\n",
    "https://genius.com/Genius-song-sections-and-headers-guide-annotated\n",
    "    - in general, the intro is least emotional, the chorus is most emotional, and the verses are in between\n",
    "    - This could mean we could skip the intro/outro and rely on the chorus and verses (maybe just the chorus when need fast results)\n",
    "\n",
    "Some other ideas:\n",
    "- We could break it up by sentences (some songs have no punctuation, so this may not work)\n",
    "- We could break it up by line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Samples used in testing (skip if not interested, but run cells)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song sample 1.\n",
    "\n",
    "This one is intentionally vague, but it is more relaxed or happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsLilTecca = \"\"\"\n",
    "[Intro]\n",
    "Nah, nah, nah\n",
    "Yeah, oh-oh\n",
    "Yeah, oh no\n",
    "We love you Tecca\n",
    "Yeah, yeah\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (That's Tec)\n",
    "I just took her home, then I turn her to a sinner, yeah\n",
    "Rambow\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they say that I’m a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he know the answers, nigga, like he Bill Nye\n",
    "[Verse]\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they sayin’ I'm a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he got the answers, nigga, like he Bill Nye\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsLilTeccaTripleVerse = \"\"\"\n",
    "[Intro]\n",
    "Nah, nah, nah\n",
    "Yeah, oh-oh\n",
    "Yeah, oh no\n",
    "We love you Tecca\n",
    "Yeah, yeah\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (That's Tec)\n",
    "I just took her home, then I turn her to a sinner, yeah\n",
    "Rambow\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they say that I’m a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he know the answers, nigga, like he Bill Nye\n",
    "[Verse]\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they sayin’ I'm a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he got the answers, nigga, like he Bill Nye\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song sample 2.\n",
    "\n",
    "This one is more sad, and it is Go easy on me by Adele\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsAdele =\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0.1. Determining split when tokenizing lyrics exceeds 512 (model input limit) (skip)\n",
    "\n",
    "The goal should be to split it as evenly as possible.\n",
    "\n",
    "If over limit but under 1024, we can split it into 2 chunks, either at the nerest line break or paragraph break to the middle of the chunk\n",
    "\n",
    "If it is bigger, we can divide by 512 to get n and then split it as smooth as possible into n+1 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def breakUpLargeLyricChunks1(lyricsChunkString, returnLyricsSegments=False):\n",
    "    songSegments=[lyricsChunkString]\n",
    "    tokenSegments = []\n",
    "\n",
    "    #convert the string to a list of lines in the string and also store the start and end index of each line\n",
    "    lines = lyricsChunkString.splitlines()\n",
    "\n",
    "    tokens = tokenizer.encode(lyricsChunkString)\n",
    "    max_length = 512# model.config.max_position_embeddings is always 512 and it does not change\n",
    "\n",
    "    if len(tokens) < max_length and torch.cuda.is_available():\n",
    "        tokenSegment = tokenizer.encode(segment, return_tensors=\"pt\").cuda()\n",
    "        tokenSegments.append(tokenSegment)\n",
    "    elif len(tokens) < max_length:\n",
    "        tokenSegment= tokenizer.encode(segment, return_tensors=\"pt\")\n",
    "        tokenSegments.append(tokenSegment)\n",
    "    else:\n",
    "        songSegments = []\n",
    "        songSegmentCount = int(len(tokens)/max_length)+1+1\n",
    "        averageSegmentSize = int(len(lines)/songSegmentCount)\n",
    "\n",
    "        #for the number of songSegmentCount, decode the tokens by the average segment size to get the string\n",
    "        for i in range(songSegmentCount):\n",
    "            #decode the tokens by the average segment size to get the string\n",
    "            startidx=averageSegmentSize*(i)\n",
    "            endidx=averageSegmentSize*(i+1)\n",
    "\n",
    "            #if it is the last i then set the endidx to the last line\n",
    "            if i == songSegmentCount-1:\n",
    "                endidx = len(lines)\n",
    "\n",
    "            #make a segment of the lyrics combining the range of lines\n",
    "            segment = \" \".join(lines[startidx:endidx])\n",
    "\n",
    "            songSegments.append(segment)\n",
    "\n",
    "            #if cuda is available,  add to tokenSegments\n",
    "            if torch.cuda.is_available():\n",
    "                tokenSegment = tokenizer.encode(segment, return_tensors=\"pt\").cuda()\n",
    "                if len(tokenSegment) < max_length:\n",
    "                    tokenSegments.append(tokenSegment)\n",
    "                else:\n",
    "                    print(\"segment is too long\")\n",
    "\n",
    "            else:\n",
    "                tokenSegment= tokenizer.encode(segment, return_tensors=\"pt\")\n",
    "                if len(tokenSegment) < max_length:\n",
    "                    tokenSegments.append(tokenSegment)\n",
    "                else:\n",
    "                    print(\"segment is too long\")\n",
    "\n",
    "    #NOTE: I should add a check for the chunk size to make sure it is still not over the max length\n",
    "    if returnLyricsSegments:\n",
    "        return tokenSegments, songSegments\n",
    "    else:\n",
    "        return tokenSegments\n",
    "        '''\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0.2 Making function 6.0.1 more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakUpLargeLyricChunks(lyricsChunkString, lines,tokenizer, max_length=512, device=\"cuda\", returnLyricsSegments=False):\n",
    "    #lines = lyricsChunkString.splitlines()  # split the lyrics into lines\n",
    "    segments = []  # store the lyrics segments\n",
    "    token_segments = []  # store the tokenized segments as tensors\n",
    "    #print(type(lyricsChunkString))\n",
    "    token_segment = tokenizer.encode(lyricsChunkString, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    if len(token_segment[0]) <= max_length:\n",
    "        token_segment = token_segment.unsqueeze(0)\n",
    "        token_segments.append(token_segment)\n",
    "        segments.append(lyricsChunkString)\n",
    "    else:\n",
    "        # calculate the average number of lines per segment. Add +2 to ensure segments are not still too long\n",
    "        avg_lines_per_segment = len(lines) // ((len(token_segment[0]) // max_length) + 2)\n",
    "\n",
    "        # loop through the lines and group them into segments of roughly the same length\n",
    "        for start_idx in range(0, len(lines), avg_lines_per_segment):\n",
    "            end_idx = start_idx + avg_lines_per_segment\n",
    "\n",
    "            smallLastChunk = end_idx >= len(lines)-2\n",
    "            \n",
    "            if smallLastChunk:\n",
    "                segment = \" \".join(lines[start_idx:])\n",
    "            else:\n",
    "                segment = \" \".join(lines[start_idx:end_idx])\n",
    "            segments.append(segment)\n",
    "\n",
    "            # tokenize the segment and convert to tensor\n",
    "            token_segment = tokenizer.encode(segment, return_tensors=\"pt\").to(device)\n",
    "            token_segment = token_segment.unsqueeze(0)\n",
    "            token_segments.append(token_segment)\n",
    "            #NOTE: ^^ If I use batch_encode_plus, I can get the tokenized segments as a list of tensors in one step\n",
    "            #I would just have to do it after the loop. \n",
    "            #Since it is a small list though, I don't think it will make a difference in this case\n",
    "\n",
    "            if smallLastChunk:\n",
    "                #this is the last segment early, so break out of the loop\n",
    "                break\n",
    "\n",
    "    if returnLyricsSegments:  \n",
    "        return token_segments, segments\n",
    "    else:\n",
    "        return token_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xlyrics= breakUpLargeLyricChunks(fullLyricsLilTecca, fullLyricsLilTecca.splitlines(),  tokenizer,returnLyricsSegments=True )#, max_length=512, device=\"cuda\", returnLyricsSegments=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can\\'t chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor  [Chorus] She just hit my phone, she said, \"Tecca, you a winner\" (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they sayin’ I\\'m a star I just wanna ball with my guys Drive off the Wock\\', he just caught a DUI He think he got the answers, nigga, like he Bill Nye'"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlyrics[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Breaking up by headers\n",
    "\n",
    "Now that we accounted for the limit, we can break up the lyrics by headers and split large chunks if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old function (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# input: a string of whole song\n",
    "# output: a dictionary of with header values and a list of tensors (sometmes more than 1 item) for each header chunk\n",
    "def breakUpSongByHeaders(fullSongLyricsString, tokenizer, max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "    songSegmentsDict = {}\n",
    "    tokenSegmentsDict = {}\n",
    "    headerFreqsDict = {}\n",
    "\n",
    "    #split the song into a list of lines\n",
    "    lines = fullSongLyricsString.splitlines()[1:]\n",
    "    #find the lines that start with [ and end with ]\n",
    "    headerLinesIndex = [i for i, s in enumerate(lines) if \"[\" in s and \"]\" in s]\n",
    "    #update the lines function by removing the [ and ] from the lines\n",
    "    lines = [line.replace(\"[\",\"\").replace(\"]\",\"\") for line in lines]\n",
    "\n",
    "    for index in headerLinesIndex:\n",
    "        print(lines[index])\n",
    "    #create a dictionary of the header lines and the lines that follow before the next header line\n",
    "    for i in range(len(headerLinesIndex)):\n",
    "        if lines[headerLinesIndex[i]] in songSegmentsDict:\n",
    "            songSegmentsDict[lines[headerLinesIndex[i]]][0] += 1\n",
    "        elif i == len(headerLinesIndex)-1:\n",
    "            songSegmentsDict[lines[headerLinesIndex[i]]] = [1,\" \".join(lines[headerLinesIndex[i]+1:]),lines[headerLinesIndex[i]+1:]]\n",
    "        else:\n",
    "            songSegmentsDict[lines[headerLinesIndex[i]]] = [1,\" \".join(lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]),lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]]\n",
    "    for header, lyrics in songSegmentsDict.items():\n",
    "        if returnSongSegments:\n",
    "            tokenSegmentsDict[header],subLyrics = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "            songSegmentsDict[header]=subLyrics\n",
    "        else:\n",
    "            tokenSegmentsDict[header] = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "        headerFreqsDict[header] = lyrics[0]\n",
    "        \n",
    "    if returnSongSegments:\n",
    "        return tokenSegmentsDict,headerFreqsDict,songSegmentsDict\n",
    "    else:\n",
    "        return tokenSegmentsDict,headerFreqsDict\n",
    "'''\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slightly cleaner code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: a string of whole song\n",
    "# output: a dictionary of with header values and a list of tensors (sometmes more than 1 item) for each header chunk\n",
    "def breakUpSongByHeaders(fullSongLyricsString, tokenizer, max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "    songSegmentsDict = {}\n",
    "    tokenSegmentsDict = {}\n",
    "    headerFreqsDict = {}\n",
    "\n",
    "    #split the song into a list of lines\n",
    "    lines = fullSongLyricsString.splitlines()\n",
    "    #find the lines that start with [ and end with ]\n",
    "    headerLinesIndex = [i for i, line in enumerate(lines) if line.startswith('[') and line.endswith(']')]\n",
    "\n",
    "    for i in range(len(headerLinesIndex)):\n",
    "        header_line = lines[headerLinesIndex[i]][1:-1]  # remove square brackets\n",
    "        if header_line in songSegmentsDict:\n",
    "            songSegmentsDict[header_line][0] += 1\n",
    "        elif i == len(headerLinesIndex)-1:\n",
    "            songSegmentsDict[header_line] = [1, \" \".join(lines[headerLinesIndex[i]+1:]), lines[headerLinesIndex[i]+1:]]\n",
    "        else:\n",
    "            songSegmentsDict[header_line] = [1, \" \".join(lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]), lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]]\n",
    "\n",
    "    for header, lyrics in songSegmentsDict.items():\n",
    "        if returnSongSegments:\n",
    "            tokenSegmentsDict[header],subLyrics = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "            songSegmentsDict[header]=subLyrics\n",
    "        else:\n",
    "            tokenSegmentsDict[header] = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "        headerFreqsDict[header] = lyrics[0]\n",
    "\n",
    "    if returnSongSegments:\n",
    "        return tokenSegmentsDict,headerFreqsDict,songSegmentsDict\n",
    "    else:\n",
    "        return tokenSegmentsDict,headerFreqsDict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "songChunks,freqs =breakUpSongByHeaders(fullLyricsLilTecca,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songChunks['Verse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "songChunks,freqs,songSegs =breakUpSongByHeaders(fullLyricsLilTeccaTripleVerse,tokenizer,returnSongSegments=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songSegs['Verse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nah, nah, nah Yeah, oh-oh Yeah, oh no We love you Tecca Yeah, yeah She just hit my phone, she said, \"Tecca, you a winner\" (That\\'s Tec) I just took her home, then I turn her to a sinner, yeah Rambow ']"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songSegs['Intro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intro': ['Nah, nah, nah Yeah, oh-oh Yeah, oh no We love you Tecca Yeah, yeah She just hit my phone, she said, \"Tecca, you a winner\" (That\\'s Tec) I just took her home, then I turn her to a sinner, yeah Rambow '],\n",
       " 'Chorus': ['She just hit my phone, she said, \"Tecca, you a winner\" (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I’m a star I just wanna ball with my guys Drive off the Wock\\', he just caught a DUI He think he know the answers, nigga, like he Bill Nye'],\n",
       " 'Verse': [\"Bitch, I feel like A.I., nigga, never need to practice I got two clips 'cause that chopper automatic And I started talkin’ shit, I got tired of this rappin' But I been making' hits, most these niggas, they been nappin' And my lyrics hit her hard, like her nigga, he was stabbin' LSD hit his brain, yeah, that nigga, he been tabbin' I just got your shorty, yeah, my niggas, we been tappin' Walk to the bank, Chief Keef, I be laughin' Red, blue, yellow, nigga, you could pick your Power Ranger I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can't chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor\",\n",
       "  \"Bitch, I feel like A.I., nigga, never need to practice I got two clips 'cause that chopper automatic And I started talkin’ shit, I got tired of this rappin' But I been making' hits, most these niggas, they been nappin' And my lyrics hit her hard, like her nigga, he was stabbin' LSD hit his brain, yeah, that nigga, he been tabbin' I just got your shorty, yeah, my niggas, we been tappin' Walk to the bank, Chief Keef, I be laughin' Red, blue, yellow, nigga, you could pick your Power Ranger I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can't chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor\",\n",
       "  \"Bitch, I feel like A.I., nigga, never need to practice I got two clips 'cause that chopper automatic And I started talkin’ shit, I got tired of this rappin' But I been making' hits, most these niggas, they been nappin' And my lyrics hit her hard, like her nigga, he was stabbin' LSD hit his brain, yeah, that nigga, he been tabbin' I just got your shorty, yeah, my niggas, we been tappin' Walk to the bank, Chief Keef, I be laughin' Red, blue, yellow, nigga, you could pick your Power Ranger I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can't chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor \"]}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songSegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  101, 24883,   117,  9468,  1324,   117,  9468,  1324,  2814,   117,\n",
       "           9294,   118,  9294,  2814,   117,  9294,  1185,  1284,  1567,  1128,\n",
       "          12008, 19495,  2814,   117,  8147,  1153,  1198,  1855,  1139,  2179,\n",
       "            117,  1131,  1163,   117,   107, 12008, 19495,   117,  1128,   170,\n",
       "           2981,   107,   113,  1337,   112,   188, 12008,  1665,   114,   146,\n",
       "           1198,  1261,  1123,  1313,   117,  1173,   146,  1885,  1123,  1106,\n",
       "            170, 11850,  2511,   117,  8147, 11447, 14251,   102]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songChunks['Intro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intro': 1, 'Chorus': 2, 'Verse': 1}"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for header,tokenChunks in songChunks.items():\n",
    "    for tokenChunk in tokenChunks:\n",
    "    #softmax takes in a sentence but its already encoded, so make sure to add param to skip that line if its already encoded\n",
    "        softmaxScores=getSoftmax(model,tokenizer,tokens=tokenChunk, printTopN=True)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28,), dtype=float32, numpy=\n",
       "array([4.71507868e-04, 6.64192426e-04, 1.88800669e+00, 3.85590866e-02,\n",
       "       3.15132347e-05, 1.03654747e-03, 4.55209432e-04, 1.04930070e-04,\n",
       "       1.36494738e-04, 1.86057400e-03, 2.81385286e-03, 1.09431548e-02,\n",
       "       2.42148017e-04, 5.44508148e-05, 3.08011728e-03, 7.79700422e-05,\n",
       "       5.52225101e-04, 3.27373593e-04, 3.33590171e-04, 6.30960785e-05,\n",
       "       3.88773886e-04, 1.23360354e-04, 1.20458135e-04, 4.15803333e-05,\n",
       "       1.43959711e-04, 4.34775429e-04, 2.44906842e-04, 4.86875474e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmaxScores+softmaxScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-472-cc5443263fc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#covert softmax scores to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msoftmaxScores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmaxScores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "#covert softmax scores to numpy array\n",
    "softmaxScores = softmaxScores.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap: The function now breaks up the lyrics by headers and splits large chunks if needed. While the example of the verse with a large chunk I showed was storing the same lyrics 3x, that's just becase I copy-pasted the lyrics. In reality, the lyrics would've been different but successfully broken up into chunks if needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Final Function For Inferences based on Lyrics\n",
    "\n",
    "NOTE 1 - if top rating is neutral, Either we should \n",
    "1. discard segment and move on to next segment\n",
    "2. Take the second highest rating and use that as the sgement label\n",
    "\n",
    "Note 2 - If all ratings are neutral, we should use the linear model to get the final label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge cases taken into account:\n",
    "- the song segments that are too long are divided by n+1 chunks where n is the number of chunks it should take to fit into the model. This is because the songs are split by lines so to avoid a long line making the chunk too big, we split it into n+1 chunks\n",
    "- factoring in the frequencies of headers in the song to determine the weights of the headers\n",
    "\n",
    "Edge cases not taken into account:\n",
    "- adding periods at the end of lines\n",
    "- adding a check for songs with no headers\n",
    "- adding a check for songs not in english\n",
    "- considering random brackets that are not headers!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoodLabelFromLyrics(lyrics,model, tokenizer, emotion_dict, emotionsAsValenceArousal,disregardNeutral=True, printRawScores=False, printTopN=False,topScoresToPrint=3,max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "    softmaxScoresPerHeader = {}\n",
    "    #part 1 - break up the lyrics into chunks and get the tokens\n",
    "    if returnSongSegments:\n",
    "        songTokenChunks,freqs,songSegs =breakUpSongByHeaders(lyrics,tokenizer,returnSongSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "    else:\n",
    "        songTokenChunks,freqs =breakUpSongByHeaders(lyrics,tokenizer,returnSongSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "\n",
    "    #part 2 - get the softmax score for each chunk\n",
    "\n",
    "    #softmax scores returns COMBINED SINGLE LABEL -- MAYBE TRY MULTIPLE LABELS AND TAKE THE MOST COMMON\n",
    "    for header,tokenChunksPerHeaders in songTokenChunks.items():\n",
    "        for tokenChunks in tokenChunksPerHeaders:\n",
    "            for tokenChunk in tokenChunks:\n",
    "                if header not in softmaxScoresPerHeader:\n",
    "                    softmaxScoresPerHeader[header] = getSoftmax(model,tokenizer,tokens=tokenChunk,n=topScoresToPrint, printTopN=printTopN, printRawScores=printRawScores)\n",
    "                else:\n",
    "                    softmaxScoresPerHeader[header] += getSoftmax(model,tokenizer,tokens=tokenChunk,n=topScoresToPrint, printTopN=printTopN, printRawScores=printRawScores)\n",
    "            # ^^ I could encode the tokens in batches, but there aren't many to encode so it shouldn't be a problem\n",
    "            \n",
    "    #Part 3 determine what to do with the neutral labels\n",
    "\n",
    "    moodLabel = convertScoresToLabels(softmaxScoresPerHeader,freqs, emotionsAsValenceArousal,emotion_dict,disregardNeutral=disregardNeutral)\n",
    "        #^^ rewrite function to account for freqs of header and disregard softmaxes with neutral labels as top score!\n",
    "\n",
    "\n",
    "    #part 4 - return the most common label\n",
    "    return moodLabel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMoodLabelFromLyrics(fullLyricsLilTecca,model, tokenizer, emotion_dict, emotionsAsValenceArousal,disregardNeutral=True, printRawScores=False, printTopN=False,topScoresToPrint=3,max_length=512, device=\"cuda\",  returnSongSegments=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CudaTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2fa8f4dd4130559c9bb206ea5c1e5e62ed157dfd2663e7fcefd868ad60d1c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
