{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if needed, he'll use for arousal: neutral/suprise\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:\n",
    "\"uriyas model total emotions: happy, sad, disgust, fear, neutral, anger, surprise\"\n",
    "\"use for valence: happy/sad\"\n",
    "\"if needed, he'll use for arousal: neutral/suprise\"\n",
    "#THEN, for me:\n",
    "#map the emotions to (x,y) coordinates of valence and arousal, then multiply it by the probability of the emotion, then take the weighted average and get the reslting x,y coordinates\n",
    "#valence and arousal are the two dimensions of the circumplex model and the resulting scores should get put in one of the 9(nuetral plus 8 categories) categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoEmotions: Testing Input to the Model, Adding Softmax Layer, Conversion Function for getting segment Label, Getting final Label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlar5\\anaconda3\\envs\\CudaTest\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model monologg/bert-base-cased-goemotions-original from huggingface\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  146, 1821, 1177, 2816,  102]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#test the model on a sentence\n",
    "sentence = \"I am so happy\"\n",
    "tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "tokens = tokens.cuda()\n",
    "print(tokens)\n",
    "result = model(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Playing around/testing model (skip)\n",
    "this is to figure out what will be needed making softmax, and determining the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "#determine the max size of the input the model can handle\n",
    "max_length = model.config.max_position_embeddings\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 0, 13]\n"
     ]
    }
   ],
   "source": [
    "#identify the top 3 emotion with the highest probability\n",
    "emotion = result.logits\n",
    "emotion = emotion.cpu().detach().numpy()\n",
    "emotion = emotion[0]\n",
    "emotion = emotion.argsort()[-3:][::-1]\n",
    "emotion = emotion.tolist()\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert model.config.id2label to a list of emotions, where the key is the index of the emotion\n",
    "emotion_dict = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n",
      "admiration\n",
      "excitement\n"
     ]
    }
   ],
   "source": [
    "#identify the label of top 3 emotions from emotion list\n",
    "for i in emotion:\n",
    "    print(emotion_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17, device='cuda:0')\n",
      "joy\n"
     ]
    }
   ],
   "source": [
    "#identify the emotion with the highest probability\n",
    "emotion = result.logits.argmax()\n",
    "print(emotion)\n",
    "#which emotion is that?\n",
    "print(model.config.id2label[emotion.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict.values()\n",
    "emotionGroups=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionSet = set(emotion_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "approvedMoods=['neutral']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoftmax(model,tokenizer, tokens = None, sentence=None, n=3,printRawScores=False, printTopN=False,device='cuda'):\n",
    "    if tokens is None:\n",
    "        tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "    if device=='cuda':\n",
    "        tokens = tokens.cuda()\n",
    "    result = model(tokens)\n",
    "    emotion = result.logits\n",
    "    emotion = emotion.cpu().detach().numpy()\n",
    "    emotion = emotion[0]\n",
    "    softmax = tf.nn.softmax(emotion)\n",
    "    #convert to numpy array\n",
    "    softmax = softmax.numpy()\n",
    "    if printRawScores:\n",
    "        print(softmax)\n",
    "    \n",
    "    if printTopN:\n",
    "        emotion = emotion.argsort()[-n:][::-1]\n",
    "        emotion = emotion.tolist()\n",
    "        printTopEmotions(emotion,model, softmax)\n",
    "    return softmax\n",
    "\n",
    "\n",
    "def printTopEmotions(emotion, model, softmax):\n",
    "    \n",
    "    #identify the label of top n emotions from emotion list\n",
    "    #softmax is in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    id=0\n",
    "    emotion_dict = model.config.id2label\n",
    "    for i in emotion:\n",
    "        print(emotion_dict[i])\n",
    "        print(softmax[emotion[id]]*100,\"%\")\n",
    "        id+=1\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentences from songs to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear2 = \"'Cause you see people, people, people, people Don't really know you (They don't really know you) They don't really know you 'Cause you see people, people, people They don't really know you (Mmm) They don't really know—\"\n",
    "unclear = \"I've been drinking more alcohol for the past five days Did you check on me? Now, did you look for me? I walked in the room, eyes are red and I don't smoke banga Did you check on me? (Did you check on me?) Now, did you notice me?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "braggingLyrics = \"She just hit my phone, she said, 'Tecca, you a winner' (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I’m a star I just wanna ball with my guys Drive off the Wock', he just caught a DUI He think he know the answers, nigga, like he Bill Nye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadMetaphoricLyrics = \"Hello darkness, my old friend, I've come to talk with you again, because a vision softly creeping, left its seeds while I was sleeping.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "goEasyOnMeSad = \"There ain't no gold in this river That I've been washin' my hands in forever I know there is hope in these waters But I can't bring myself to swim When I am drowning in this silence Baby, let me in. Go easy on me, baby I was still a child Didn't get the chance to Feel the world around me I had no time to choose what I chose to do So go easy on me\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curiosity\n",
      "99.90363121032715 %\n",
      "neutral\n",
      "0.034640790545381606 %\n",
      "confusion\n",
      "0.019302892906125635 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear=getSoftmax(model, tokenizer,sentence = unclear, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.9980092048645 %\n",
      "annoyance\n",
      "0.00058388282013766 %\n",
      "disappointment\n",
      "0.0003420888106120401 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestUnclear2=getSoftmax(model,tokenizer,sentence =unclear2, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "75.65684914588928 %\n",
      "joy\n",
      "16.482388973236084 %\n",
      "excitement\n",
      "4.176769405603409 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestBraggingLyrics=getSoftmax(model,tokenizer,sentence =braggingLyrics, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "99.99864101409912 %\n",
      "annoyance\n",
      "0.00020481845695030643 %\n",
      "caring\n",
      "0.00011883536217283108 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestsadMetaphoricLyrics=getSoftmax(model,tokenizer,sentence =sadMetaphoricLyrics, printTopN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointment\n",
      "63.13481330871582 %\n",
      "realization\n",
      "14.627596735954285 %\n",
      "sadness\n",
      "14.258602261543274 %\n"
     ]
    }
   ],
   "source": [
    "softmaxtestgoEasyOnMeSad=getSoftmax(model,tokenizer,sentence =goEasyOnMeSad, printTopN=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SoftMax Recap:\n",
    "\n",
    "1. There seems to be a dominance of neutral while the trailing classes seem to be more relevant. This does make sense considering the fact that not every lyric is emotionally charged.  \n",
    "\n",
    "- However, this does raise the question, \"How do we handle neutral?\"\n",
    "\n",
    "- similarly, \"Do we want neutral as a resulting category?\n",
    "\n",
    "2. Songs that are reliant on metaphores or to create emotion will not be captured via sentiment analysis\n",
    "\n",
    "- In these cases, we would want the linear model to give results\n",
    "- perhaps if this is specifially reated neutral we should rely on the linear classificiaton model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class Conversion With Adjustments to Neutral Considerations\n",
    "\n",
    "Here we will:\n",
    "1. scale emotions to (valence, energy) based on the valence-arousal mood wheel\n",
    "2. multiply that value by the percent\n",
    "3. add up x values as well as y values\n",
    "4. place resulting values into the 8 main mood categories to get a class\n",
    "5. if close to 0, label it neutral instead\n",
    "    - If neutral, perhaps use as indicator to rely on 2nd model for classification\n",
    "\n",
    "NOTE: Some words did not have a perfect point plotted, but there were some synonyms\n",
    "- approval was mapped with satisfied\n",
    "- caring was with passionate\n",
    "- confused with a lessened amount of frustrated (1/2)\n",
    "- curious was mapped with interested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mood setup verification (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admiration\n",
      "amusement\n",
      "anger\n",
      "annoyance\n",
      "approval\n",
      "caring\n",
      "confusion\n",
      "curiosity\n",
      "desire\n",
      "disappointment\n",
      "disapproval\n",
      "disgust\n",
      "embarrassment\n",
      "excitement\n",
      "fear\n",
      "gratitude\n",
      "grief\n",
      "joy\n",
      "love\n",
      "nervousness\n",
      "optimism\n",
      "pride\n",
      "realization\n",
      "relief\n",
      "remorse\n",
      "sadness\n",
      "surprise\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "emotion_dict = model.config.id2label\n",
    "for key in range(len(emotion_dict)):\n",
    "    print(emotion_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary mapping all emotions to valence and arousal values\n",
    "# valence is the x axis, arousal is the y axis of the circumplex model\n",
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,-.3),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6, 0.4)\n",
      "(0.6, 0.2)\n",
      "(-0.8, 0.6)\n",
      "(-0.6, 0.6)\n",
      "(0.8, 0.6)\n",
      "(0.6, -0.2)\n",
      "(-0.2, 0.2)\n",
      "(0, 0.4)\n",
      "(0.6, 0.6)\n",
      "(-0.6, -0.6)\n",
      "(-0.8, 0.65)\n",
      "(-0.8, 0.2)\n",
      "(-0.6, 0.4)\n",
      "(0.6, 0.8)\n",
      "(-0.6, 0.8)\n",
      "(0.6, -0.6)\n",
      "(-0.6, -0.8)\n",
      "(0.8, 0.2)\n",
      "(0.8, 0.4)\n",
      "(-0.4, 0.6)\n",
      "(0.6, -0.3)\n",
      "(0.6, 0.1)\n",
      "(0.2, 0.2)\n",
      "(0.4, -0.4)\n",
      "(-0.6, -0.4)\n",
      "(-0.8, -0.2)\n",
      "(0.2, 0.6)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(emotion_dict)):\n",
    "    print(emotionsAsValenceArousal[emotion_dict[i]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'despair':(-.8,-.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'envy':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,.2),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n",
    "#moods=['energetic','excited','happy','relaxed','calm','depressed','sad','anxious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determineMoodLabel(valence,arousal):\n",
    "    #determine the diagonal of the circumplex model that the valence and arousal scores fall on\n",
    "    #MAKE 2 BOXES OF THE CIRCUMPLEX MODEL A MOOD \n",
    "\n",
    "    energetic =   -0.5<valence<0.5 and arousal>0.5\n",
    "    happy =       valence>0.5 and -.5<arousal<0.5\n",
    "    calm =       -0.5<valence<0.5 and arousal<-0.5\n",
    "    sad =         valence<-0.5 and -.5<arousal<0.5\n",
    "\n",
    "    excited =   not (happy or energetic) and valence>0 and arousal>0\n",
    "    relaxed =   not (calm or happy) and valence>0 and arousal<0\n",
    "    depressed = not (calm or sad) and valence<0 and arousal<0\n",
    "    anxious =   not (energetic or sad) and valence<0 and arousal>0\n",
    "\n",
    "\n",
    "    if energetic:\n",
    "        mood='energetic'\n",
    "    elif happy:\n",
    "        mood='happy'\n",
    "    elif calm:\n",
    "        mood='calm'\n",
    "    elif sad:\n",
    "        mood='sad'\n",
    "    elif excited:\n",
    "        mood='excited'\n",
    "    elif relaxed:\n",
    "        mood='relaxed'\n",
    "    elif depressed:\n",
    "        mood='depressed'\n",
    "    elif anxious:\n",
    "        mood='anxious'\n",
    "    else:\n",
    "        mood='neutral'\n",
    "    return mood     \n",
    "\n",
    "def convertScoresToLabels(softmaxScoresPerHeader,headerFreqs, emotionsAsValenceArousal,emotion_dict,disregardNeutral = True, printValenceArousal=False,printTopChunkEmotions=False):\n",
    "    #convert the softmax scores to a valence and arousal score\n",
    "    #softmax scores are in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "    valence=0\n",
    "    arousal=0\n",
    "    softmaxScoresApplied=0\n",
    "    #find the key in emotion_dict that corresponds to neutral\n",
    "    neuturalKey = [key for key, value in emotion_dict.items() if value == 'neutral'][0]\n",
    "    for key, softmaxScores in softmaxScoresPerHeader.items():\n",
    "        #check if neutral is the highest softmax score\n",
    "        if disregardNeutral and neuturalKey==softmaxScores.argmax():\n",
    "            continue\n",
    "        else:\n",
    "            #multiply the softmax score by the valence and arousal values and add to the total valence and arousal\n",
    "            #do this for the number in the headerFreqs dictionary\n",
    "            for i in range(headerFreqs[key]):\n",
    "                id=0\n",
    "                softmaxScoresApplied+=1\n",
    "                for i in softmaxScores:\n",
    "                    valence+=i*emotionsAsValenceArousal[emotion_dict[id]][0]\n",
    "                    arousal+=i*emotionsAsValenceArousal[emotion_dict[id]][1]\n",
    "                    id+=1\n",
    "    #divide the total valence and arousal by the number of softmax scores applied\n",
    "    normalizedValence=valence/softmaxScoresApplied\n",
    "    normalizedArousal=arousal/softmaxScoresApplied\n",
    "    mood =determineMoodLabel(normalizedValence,normalizedArousal)\n",
    "    if printValenceArousal:\n",
    "        print(\"Valence: \",normalizedValence)\n",
    "        print(\"Arousal: \",normalizedArousal)\n",
    "    return mood"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broken function but cleaner code (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def determineMoodLabel(valence, arousal):\n",
    "    conditions = {\n",
    "        'energetic': (-0.5 < valence < 0.5) and (arousal > 0.5),\n",
    "        'happy': (valence > 0.5) and (-0.5 < arousal < 0.5),\n",
    "        'calm': (-0.5 < valence < 0.5) and (arousal < -0.5),\n",
    "        'sad': (valence < -0.5) and (-0.5 < arousal < 0.5),\n",
    "    }\n",
    "    conditions['excited']= (valence > 0) and (arousal > 0) and not ((conditions.get('happy') == True) or (conditions.get('energetic') == True))\n",
    "    conditions['relaxed'] =(valence > 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('happy') == True)),\n",
    "    conditions['depressed']= (valence < 0) and (arousal < 0) and not ((conditions.get('calm')==True) or (conditions.get('sad') == True)),\n",
    "    conditions['anxious']= (valence < 0) and (arousal > 0) and not ((conditions.get('energetic') == True) or (conditions.get('sad') == True))\n",
    "\n",
    "    for mood, condition in conditions.items():\n",
    "        #print(mood)\n",
    "        if condition:\n",
    "            if condition:\n",
    "            #print(condition)\n",
    "                return mood\n",
    "    return 'neutral'\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determineMoodLabel(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.00014550615968573764\n",
      "Arousal:  0.39976903293313065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels({'WholeText':softmaxtestUnclear},{'WholeText':1} ,emotionsAsValenceArousal,emotion_dict,printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0\n",
      "Arousal:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels({'WholeText':softmaxtestUnclear2},{'WholeText':1}, emotionsAsValenceArousal,emotion_dict,disregardNeutral=True,  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -6.289669458681146e-06\n",
      "Arousal:  4.134034234937189e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels({'WholeText':softmaxtestUnclear2},{'WholeText':1}, emotionsAsValenceArousal,emotion_dict,disregardNeutral=False,  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.179350444616648\n",
      "Arousal:  0.0792138909397181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels({'WholeText':softmaxtestBraggingLyrics},{'WholeText':1}, emotionsAsValenceArousal,emotion_dict,disregardNeutral=False,printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -1.5789130628718345e-06\n",
      "Arousal:  2.6779267059851014e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anxious'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels({'WholeText':softmaxtestsadMetaphoricLyrics},{'WholeText':1}, emotionsAsValenceArousal,emotion_dict,disregardNeutral=False,printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.4687148983321094\n",
      "Arousal:  -0.3750938911114646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'depressed'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertScoresToLabels({'WholeText':softmaxtestgoEasyOnMeSad},{'WholeText':1}, emotionsAsValenceArousal,emotion_dict,disregardNeutral=False,printValenceArousal=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Class Conversion Recap:\n",
    "\n",
    "- The code works but it tends to classify heavily towards the center of the coordinates\n",
    "- NOTE: This could be because it was just a few small samples, which may not reflect the overall distribution of the data\n",
    "- As an alternative, we could remove the neutral score and apply softmax to the remaining classes\n",
    "- OR, I could just exclude the inputs that result in overwhemingly neutral, and then continue to the next chunk of lyrics until I find all chunks that are not neutral and then get the average of those to get the final classification\n",
    "\n",
    "What works best:\n",
    "\n",
    "If whole song is only 1 chunk, then keep the neutral, else, you want to remove the neutral-dominating chunks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Other idea: remove neutral and apply softmax to remaining classes\n",
    "\n",
    "If #4 doesnt work, here we will drop the neutral score and apply softmax to the remaining classes\n",
    "\n",
    "- This would allow us to multiply the coordinates without shrinking the values due to the neutral score\n",
    "- Perhaps this would allow us to reach the classes that are further away from the center\n",
    "- If not, we could shift the boundaries of the classes closer to the center"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Breaking up Lyrics to fit into model\n",
    "\n",
    "In order to fit the lyrics into the model, we need to break up the lyrics. There are various ways to do this. We will try a few different methods and see which one works best.\n",
    "\n",
    "\n",
    "- (Best) We could break it up by headers. Below are the various headers that we could use to break up the lyrics\n",
    "https://genius.com/Genius-song-sections-and-headers-guide-annotated\n",
    "    - in general, the intro is least emotional, the chorus is most emotional, and the verses are in between\n",
    "    - This could mean we could skip the intro/outro and rely on the chorus and verses (maybe just the chorus when need fast results)\n",
    "\n",
    "Some other ideas:\n",
    "- We could break it up by sentences (some songs have no punctuation, so this may not work)\n",
    "- We could break it up by line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Samples used in testing (skip if not interested, but run cells)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song sample 1.\n",
    "\n",
    "This one is intentionally vague, but it is more relaxed or happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsLilTecca = \"\"\"\n",
    "[Intro]\n",
    "Nah, nah, nah\n",
    "Yeah, oh-oh\n",
    "Yeah, oh no\n",
    "We love you Tecca\n",
    "Yeah, yeah\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (That's Tec)\n",
    "I just took her home, then I turn her to a sinner, yeah\n",
    "Rambow\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they say that I’m a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he know the answers, nigga, like he Bill Nye\n",
    "[Verse]\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they sayin’ I'm a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he got the answers, nigga, like he Bill Nye\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsLilTeccaTripleVerse = \"\"\"\n",
    "[Intro]\n",
    "Nah, nah, nah\n",
    "Yeah, oh-oh\n",
    "Yeah, oh no\n",
    "We love you Tecca\n",
    "Yeah, yeah\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (That's Tec)\n",
    "I just took her home, then I turn her to a sinner, yeah\n",
    "Rambow\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they say that I’m a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he know the answers, nigga, like he Bill Nye\n",
    "[Verse]\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "Bitch, I feel like A.I., nigga, never need to practice\n",
    "I got two clips 'cause that chopper automatic\n",
    "And I started talkin’ shit, I got tired of this rappin'\n",
    "But I been making' hits, most these niggas, they been nappin'\n",
    "And my lyrics hit her hard, like her nigga, he was stabbin'\n",
    "LSD hit his brain, yeah, that nigga, he been tabbin'\n",
    "I just got your shorty, yeah, my niggas, we been tappin'\n",
    "Walk to the bank, Chief Keef, I be laughin'\n",
    "Red, blue, yellow, nigga, you could pick your Power Ranger\n",
    "I could fuck, but I won’t date ya\n",
    "Getting bands, but I can’t save her\n",
    "Fast nigga, but I can't chase her\n",
    "360, quick scope, FaZe him\n",
    "God-mode, aim-bot, laser\n",
    "Cut you off, I got that razor\n",
    "\n",
    "[Chorus]\n",
    "She just hit my phone, she said, \"Tecca, you a winner\" (Yeah)\n",
    "Took her home, then I turn her to a sinner, yeah\n",
    "I just got a check, I ate lobster for dinner\n",
    "She like my style, she tryna turn me to her nigga, yeah\n",
    "I just woke up, now they sayin’ I'm a star\n",
    "I just wanna ball with my guys\n",
    "Drive off the Wock', he just caught a DUI\n",
    "He think he got the answers, nigga, like he Bill Nye\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song sample 2.\n",
    "\n",
    "This one is more sad, and it is Go easy on me by Adele\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsGoEasyOnMe = \"\"\"\n",
    "[Verse 1]\n",
    "There ain't no gold in this river\n",
    "That I've been washin' my hands in forever\n",
    "I know there is hope in these waters\n",
    "But I can't bring myself to swim\n",
    "When I am drowning in this silence\n",
    "Baby, let me in\n",
    "\n",
    "[Chorus]\n",
    "Go easy on me, baby\n",
    "I was still a child\n",
    "Didn't get the chance to\n",
    "Feel the world around me\n",
    "I had no time to choose what I chose to do\n",
    "So go easy on me\n",
    "[Verse 2]\n",
    "There ain't no room for things to change\n",
    "When we are both so deeply stuck in our ways\n",
    "You can't deny how hard I've tried\n",
    "I changed who I was to put you both first\n",
    "But now I give up\n",
    "\n",
    "[Chorus]\n",
    "Go easy on mе, baby\n",
    "I was still a child\n",
    "Didn't get the chance to\n",
    "Feel thе world around me\n",
    "Had no time to choose what I chose to do\n",
    "So go easy on me\n",
    "\n",
    "[Bridge]\n",
    "I had good intentions\n",
    "And the highest hopes\n",
    "But I know right now\n",
    "It probably doesn't even show\n",
    "\n",
    "[Chorus]\n",
    "Go easy on me, baby\n",
    "I was still a child\n",
    "I didn't get the chance to\n",
    "Feel the world around me\n",
    "I had no time to choose what I chose to do\n",
    "So go easy on me\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsDieForYouRemix = \"\"\"\n",
    "[Verse 1: The Weeknd]\n",
    "I'm findin' ways to articulate the feelin' I'm goin' through\n",
    "I just can't say I don't love you (Yeah)\n",
    "'Cause I love you, yeah\n",
    "It's hard for me to communicate the thoughts that I hold\n",
    "But tonight, I'm gon' let you know\n",
    "Let me tell the truth\n",
    "Baby, let me tell the truth, yeah\n",
    "\n",
    "[Pre-Chorus: The Weeknd]\n",
    "You know what I'm thinkin', see it in your eyes\n",
    "You hate that you want me, hate it when you cry\n",
    "You're scared to be lonely, 'specially in the night\n",
    "I'm scared that I'll miss you, happens every time\n",
    "I don't want this feelin', I can't afford love\n",
    "I try to find a reason to pull us apart\n",
    "It ain't workin' 'cause you're perfеct\n",
    "And I know that you're worth it\n",
    "I can't walk away, oh\n",
    "[Chorus: Both, Ariana Grande, The Weeknd]\n",
    "Even though we'rе goin' through it (Ah)\n",
    "And it makes you feel alone\n",
    "Just know that I would die for you (Ooh, ooh)\n",
    "Baby, I would die for you, yeah\n",
    "The distance and the time between us (Distance and the time)\n",
    "It'll never change my mind 'cause\n",
    "Baby, I would die for you (I would die for you)\n",
    "Baby, I would die for you, yeah\n",
    "[Verse 2: Ariana Grande]\n",
    "I'm findin' ways to stay concentrated on what I gotta do\n",
    "But, baby boy, it's so hard 'round you\n",
    "And yes, I'm blamin' you\n",
    "And you know I can't fake it, now or never\n",
    "And you insinuatin' that you think we might be better\n",
    "Better me and you\n",
    "Yeah, I know you do\n",
    "\n",
    "[Pre-Chorus: Ariana Grande]\n",
    "You know what I'm thinkin', see it in your eyes\n",
    "You hate that you want me, hate it when you cry\n",
    "It ain't workin' 'cause you're perfect (Mm)\n",
    "And I know you deserve it\n",
    "I can't walk away\n",
    "\n",
    "[Chorus: Both, Ariana Grande, The Weeknd]\n",
    "Even though we're goin' through it\n",
    "And it makes you (Me) feel alone\n",
    "Just know that I would die for you (I would die for you)\n",
    "Baby, I would die for you, yeah\n",
    "The distance and the time between us\n",
    "It'll never change my mind 'cause\n",
    "Baby, I would die for you (I would die for you, uh)\n",
    "Baby, I would die for you, yeah (I would die for you)\n",
    "\n",
    "[Bridge: The Weeknd]\n",
    "I would die for you, I would lie for you\n",
    "Keep it real with you, I would kill for you, my baby\n",
    "I'm just sayin', yeah\n",
    "I would die for you, I would lie for you\n",
    "Keep it real with you, I would kill for you, my baby\n",
    "Na-na-na, na-na-na, na-na-na\n",
    "\n",
    "[Chorus: The Weeknd]\n",
    "Even though we're goin' through it (Ooh)\n",
    "And it makes you feel alone (No, no)\n",
    "Just know that I would die for you (No)\n",
    "Baby, I would die for you, yeah\n",
    "The distance and the time between us (Ooh)\n",
    "It'll never change my mind 'cause (No, no)\n",
    "Baby, I would die for you (No)\n",
    "Baby, I would die for you, yeah (Oh, babe)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsCrazyInLove = \"\"\"\n",
    "[Intro: JAY-Z & Beyoncé]\n",
    "Yes! (Whoo, ow!)\n",
    "So crazy right now\n",
    "Most incredibly\n",
    "It's your girl, B\n",
    "It's your boy, Young\n",
    "You ready?\n",
    "\n",
    "[Refrain: Beyoncé & JAY-Z]\n",
    "Oh oh, oh oh, oh oh, oh no no (Oww!)\n",
    "Oh oh, oh oh, oh oh, oh no no\n",
    "Oh oh, oh oh, oh oh, oh no no\n",
    "Oh oh, oh oh, oh oh, oh no no\n",
    "[Interlude: JAY-Z]\n",
    "Ch-yeah!\n",
    "History in the making, part two!\n",
    "It's so crazy right now\n",
    "\n",
    "[Verse 1: Beyoncé]\n",
    "I look and stare so deep in your eyes\n",
    "I touch on you more and more every time\n",
    "When you leave, I'm beggin' you not to go\n",
    "Call your name two, three times in a row\n",
    "Such a funny thing for me to try to explain\n",
    "How I'm feelin', and my pride is the one to blame (Yeah, yeah)\n",
    "'Cause I know I don't understand\n",
    "Just how your love can do what no one else can\n",
    "\n",
    "[Chorus: Beyoncé]\n",
    "Got me looking so crazy right now\n",
    "Your love's got me looking so crazy right now (Your love)\n",
    "Got me looking so crazy right now\n",
    "Your touch got me looking so crazy right now (Your touch)\n",
    "Got me hoping you'll page me right now\n",
    "Your kiss got me hoping you'll save me right now\n",
    "Looking so crazy, your love's got me looking\n",
    "Got me looking so crazy in love\n",
    "\n",
    "[Refrain: Beyoncé]\n",
    "Oh oh, oh oh, oh oh, oh no no\n",
    "Oh oh, oh oh, oh oh, oh no no\n",
    "Oh oh, oh oh, oh oh, oh no no\n",
    "Oh oh, oh oh, oh oh, oh no no\n",
    "\n",
    "[Verse 2: Beyoncé]\n",
    "When I talk to my friends so quietly\n",
    "(\"Who he think he is?\") Look at what you did to me\n",
    "Tennis shoes, don't even need to buy a new dress\n",
    "If you ain't there, ain't nobody else to impress\n",
    "It's the way that you know what I thought I knew\n",
    "It's the beat that my heart skips when I'm with you\n",
    "But I still don't understand\n",
    "Just how your love can do what no one else can\n",
    "\n",
    "[Chorus: Beyoncé & JAY-Z]\n",
    "Got me looking so crazy right now\n",
    "Your love's got me looking so crazy right now (So crazy, your love)\n",
    "Got me looking so crazy right now (Your love)\n",
    "Your touch got me looking so crazy right now (Oh, your touch)\n",
    "Got me hoping you'll page me right now (Yeah)\n",
    "Your kiss got me hoping you'll save me right now (Hey)\n",
    "Looking so crazy, your love's got me looking (Ch-yeah!)\n",
    "Got me looking so crazy in love (Ch-yeah!)\n",
    "I'm looking so crazy, your love's got me looking (Whoo!)\n",
    "Got me looking so crazy in love (I'm warmed up now, let's go)\n",
    "\n",
    "[Verse 3: JAY-Z & Beyoncé]\n",
    "Young Hov, y'all know when the flow is loco (No)\n",
    "Young B and the R-O-C, uh-oh (Oh, no)\n",
    "O.G. Big Homie, the one and only (No, no)\n",
    "Stick bony, but the pockets is fat like Tony (No, no, no)\n",
    "Soprano, the ROC handle like Van Exel\n",
    "I shake phonies man you can't get next to\n",
    "The genuine article, I do not sing though\n",
    "I sling though, if anything, I bling yo\n",
    "A star like Ringo, war like a Green Beret\n",
    "You crazy? Bring your whole set (Oh)\n",
    "JAY-Z in the Range, crazy and deranged\n",
    "They can't figure him out, they like, \"Hey, is he insane?\"\n",
    "Yes sir, I'm cut from a different cloth\n",
    "My texture is the best fur, chinchilla\n",
    "I've been iller than chain smokers (Oh oh, oh oh, oh oh, oh no no)\n",
    "How you think I got the name Hova? (Oh oh, oh oh, oh oh, oh no no)\n",
    "I been realer, the game's over\n",
    "Fall back, Young (Oh oh, oh oh, oh oh, oh no no)\n",
    "Ever since I made the change over to platinum (Oh oh, oh oh, oh oh, oh no no)\n",
    "The game's been a wrap, one\n",
    "[Bridge: Beyoncé]\n",
    "Got me looking, so crazy, my baby\n",
    "I'm not myself lately, I'm foolish, I don't do this\n",
    "I've been playing myself, baby, I don't care\n",
    "'Cause your love's got the best of me\n",
    "And baby, you're making a fool of me\n",
    "You got me sprung and I don't care who sees\n",
    "'Cause baby, you got me, you got me\n",
    "You got me so crazy, baby (Hey!)\n",
    "\n",
    "[Chorus: Beyoncé]\n",
    "Got me looking so crazy right now (Your love)\n",
    "Your love's got me looking so crazy right now (Looking crazy)\n",
    "Got me looking so crazy right now\n",
    "Your touch got me looking so crazy right now (Baby, your touch)\n",
    "Got me hoping you'll page me right now (Yeah, babe)\n",
    "Your kiss got me hoping you'll save me right now (Oh)\n",
    "Looking so crazy, your love's got me looking (Yeah)\n",
    "Got me looking so crazy in love (Whoa)\n",
    "Got me looking so crazy right now\n",
    "Your love's got me looking so crazy right now (Your love)\n",
    "Got me looking so crazy right now\n",
    "Your touch got me looking so crazy right now (Your touch)\n",
    "Got me hoping you'll page me right now\n",
    "Your kiss got me hoping you'll save me right now\n",
    "Looking so crazy, your love's got me looking\n",
    "Got me looking so crazy in love\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullLyricsNumb = \"\"\"\n",
    "[Chorus]\n",
    "And every single year\n",
    "I'm drowning in my tears, I'm drowning in my tears again\n",
    "I can't seem to forget the pain you seem to give\n",
    "The pain you seem to give, my friend\n",
    "And every single year\n",
    "I'm drowning in my tears, I'm drowning in my tears again\n",
    "I can't seem to forget the pain you seem to give\n",
    "The pain you seem to give, my friend\n",
    "\n",
    "[Bridge]\n",
    "Woah, oh, woah, oh\n",
    "Woah, oh, woah, oh\n",
    "Woah, oh, woah, oh\n",
    "Woah, oh, woah, oh\n",
    "Woah, oh, woah, oh\n",
    "[Chorus]\n",
    "And every single year\n",
    "I'm drowning in my tears, I'm drowning in my tears again\n",
    "I can't seem to forget the pain you seem to give\n",
    "The pain you seem to give, my friend\n",
    "Woah, oh\n",
    "And every single year\n",
    "I'm drowning in my tears, I'm drowning in my tears again\n",
    "Woah, oh\n",
    "I can't seem to forget the pain you seem to give\n",
    "The pain you seem to give, my friend\n",
    "Woah, oh, woah, oh, woah, oh\n",
    "\n",
    "[Break]\n",
    "\n",
    "[Chorus]\n",
    "And every single year\n",
    "I'm drowning in my tears, I'm drowning in my tears again\n",
    "I can't seem to forget the pain you seem to give\n",
    "The pain you seem to give, my friend\n",
    "Woah, oh\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0.1. Determining split when tokenizing lyrics exceeds 512 (model input limit) (skip)\n",
    "\n",
    "The goal should be to split it as evenly as possible.\n",
    "\n",
    "If over limit but under 1024, we can split it into 2 chunks, either at the nerest line break or paragraph break to the middle of the chunk\n",
    "\n",
    "If it is bigger, we can divide by 512 to get n and then split it as smooth as possible into n+1 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def breakUpLargeLyricChunks1(lyricsChunkString, returnLyricsSegments=False):\n",
    "    songSegments=[lyricsChunkString]\n",
    "    tokenSegments = []\n",
    "\n",
    "    #convert the string to a list of lines in the string and also store the start and end index of each line\n",
    "    lines = lyricsChunkString.splitlines()\n",
    "\n",
    "    tokens = tokenizer.encode(lyricsChunkString)\n",
    "    max_length = 512# model.config.max_position_embeddings is always 512 and it does not change\n",
    "\n",
    "    if len(tokens) < max_length and torch.cuda.is_available():\n",
    "        tokenSegment = tokenizer.encode(segment, return_tensors=\"pt\").cuda()\n",
    "        tokenSegments.append(tokenSegment)\n",
    "    elif len(tokens) < max_length:\n",
    "        tokenSegment= tokenizer.encode(segment, return_tensors=\"pt\")\n",
    "        tokenSegments.append(tokenSegment)\n",
    "    else:\n",
    "        songSegments = []\n",
    "        songSegmentCount = int(len(tokens)/max_length)+1+1\n",
    "        averageSegmentSize = int(len(lines)/songSegmentCount)\n",
    "\n",
    "        #for the number of songSegmentCount, decode the tokens by the average segment size to get the string\n",
    "        for i in range(songSegmentCount):\n",
    "            #decode the tokens by the average segment size to get the string\n",
    "            startidx=averageSegmentSize*(i)\n",
    "            endidx=averageSegmentSize*(i+1)\n",
    "\n",
    "            #if it is the last i then set the endidx to the last line\n",
    "            if i == songSegmentCount-1:\n",
    "                endidx = len(lines)\n",
    "\n",
    "            #make a segment of the lyrics combining the range of lines\n",
    "            segment = \" \".join(lines[startidx:endidx])\n",
    "\n",
    "            songSegments.append(segment)\n",
    "\n",
    "            #if cuda is available,  add to tokenSegments\n",
    "            if torch.cuda.is_available():\n",
    "                tokenSegment = tokenizer.encode(segment, return_tensors=\"pt\").cuda()\n",
    "                if len(tokenSegment) < max_length:\n",
    "                    tokenSegments.append(tokenSegment)\n",
    "                else:\n",
    "                    print(\"segment is too long\")\n",
    "\n",
    "            else:\n",
    "                tokenSegment= tokenizer.encode(segment, return_tensors=\"pt\")\n",
    "                if len(tokenSegment) < max_length:\n",
    "                    tokenSegments.append(tokenSegment)\n",
    "                else:\n",
    "                    print(\"segment is too long\")\n",
    "\n",
    "    #NOTE: I should add a check for the chunk size to make sure it is still not over the max length\n",
    "    if returnLyricsSegments:\n",
    "        return tokenSegments, songSegments\n",
    "    else:\n",
    "        return tokenSegments\n",
    "        '''\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0.2 Making function 6.0.1 more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakUpLargeLyricChunks(lyricsChunkString, lines,tokenizer, max_length=512, device=\"cuda\", returnLyricsSegments=False):\n",
    "    #lines = lyricsChunkString.splitlines()  # split the lyrics into lines\n",
    "    segments = []  # store the lyrics segments\n",
    "    token_segments = []  # store the tokenized segments as tensors\n",
    "    #print(type(lyricsChunkString))\n",
    "    token_segment = tokenizer.encode(lyricsChunkString, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    if len(token_segment[0]) <= max_length:\n",
    "        token_segment = token_segment.unsqueeze(0)\n",
    "        token_segments.append(token_segment)\n",
    "        segments.append(lyricsChunkString)\n",
    "    else:\n",
    "        # calculate the average number of lines per segment. Add +2 to ensure segments are not still too long\n",
    "        avg_lines_per_segment = len(lines) // ((len(token_segment[0]) // max_length) + 2)\n",
    "\n",
    "        # loop through the lines and group them into segments of roughly the same length\n",
    "        for start_idx in range(0, len(lines), avg_lines_per_segment):\n",
    "            end_idx = start_idx + avg_lines_per_segment\n",
    "\n",
    "            smallLastChunk = end_idx >= len(lines)-2\n",
    "            \n",
    "            if smallLastChunk:\n",
    "                segment = \" \".join(lines[start_idx:])\n",
    "            else:\n",
    "                segment = \" \".join(lines[start_idx:end_idx])\n",
    "            segments.append(segment)\n",
    "\n",
    "            # tokenize the segment and convert to tensor\n",
    "            token_segment = tokenizer.encode(segment, return_tensors=\"pt\").to(device)\n",
    "            token_segment = token_segment.unsqueeze(0)\n",
    "            token_segments.append(token_segment)\n",
    "            #NOTE: ^^ If I use batch_encode_plus, I can get the tokenized segments as a list of tensors in one step\n",
    "            #I would just have to do it after the loop. \n",
    "            #Since it is a small list though, I don't think it will make a difference in this case\n",
    "\n",
    "            if smallLastChunk:\n",
    "                #this is the last segment early, so break out of the loop\n",
    "                break\n",
    "\n",
    "    if returnLyricsSegments:  \n",
    "        return token_segments, segments\n",
    "    else:\n",
    "        return token_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "x, xlyrics= breakUpLargeLyricChunks(fullLyricsLilTecca, fullLyricsLilTecca.splitlines(),  tokenizer,returnLyricsSegments=True )#, max_length=512, device=\"cuda\", returnLyricsSegments=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can\\'t chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor  [Chorus] She just hit my phone, she said, \"Tecca, you a winner\" (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they sayin’ I\\'m a star I just wanna ball with my guys Drive off the Wock\\', he just caught a DUI He think he got the answers, nigga, like he Bill Nye'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlyrics[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Breaking up by headers\n",
    "\n",
    "Now that we accounted for the limit, we can break up the lyrics by headers and split large chunks if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### old function (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# input: a string of whole song\n",
    "# output: a dictionary of with header values and a list of tensors (sometmes more than 1 item) for each header chunk\n",
    "def breakUpSongByHeaders(fullSongLyricsString, tokenizer, max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "    songSegmentsDict = {}\n",
    "    tokenSegmentsDict = {}\n",
    "    headerFreqsDict = {}\n",
    "\n",
    "    #split the song into a list of lines\n",
    "    lines = fullSongLyricsString.splitlines()[1:]\n",
    "    #find the lines that start with [ and end with ]\n",
    "    headerLinesIndex = [i for i, s in enumerate(lines) if \"[\" in s and \"]\" in s]\n",
    "    #update the lines function by removing the [ and ] from the lines\n",
    "    lines = [line.replace(\"[\",\"\").replace(\"]\",\"\") for line in lines]\n",
    "\n",
    "    for index in headerLinesIndex:\n",
    "        print(lines[index])\n",
    "    #create a dictionary of the header lines and the lines that follow before the next header line\n",
    "    for i in range(len(headerLinesIndex)):\n",
    "        if lines[headerLinesIndex[i]] in songSegmentsDict:\n",
    "            songSegmentsDict[lines[headerLinesIndex[i]]][0] += 1\n",
    "        elif i == len(headerLinesIndex)-1:\n",
    "            songSegmentsDict[lines[headerLinesIndex[i]]] = [1,\" \".join(lines[headerLinesIndex[i]+1:]),lines[headerLinesIndex[i]+1:]]\n",
    "        else:\n",
    "            songSegmentsDict[lines[headerLinesIndex[i]]] = [1,\" \".join(lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]),lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]]\n",
    "    for header, lyrics in songSegmentsDict.items():\n",
    "        if returnSongSegments:\n",
    "            tokenSegmentsDict[header],subLyrics = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "            songSegmentsDict[header]=subLyrics\n",
    "        else:\n",
    "            tokenSegmentsDict[header] = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "        headerFreqsDict[header] = lyrics[0]\n",
    "        \n",
    "    if returnSongSegments:\n",
    "        return tokenSegmentsDict,headerFreqsDict,songSegmentsDict\n",
    "    else:\n",
    "        return tokenSegmentsDict,headerFreqsDict\n",
    "'''\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slightly cleaner code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: a string of whole song\n",
    "# output: a dictionary of with header values and a list of tensors (sometmes more than 1 item) for each header chunk\n",
    "def breakUpSongByHeaders(fullSongLyricsString, tokenizer, max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "    songSegmentsDict = {}\n",
    "    tokenSegmentsDict = {}\n",
    "    headerFreqsDict = {}\n",
    "\n",
    "    #split the song into a list of lines\n",
    "    lines = fullSongLyricsString.splitlines()\n",
    "    #find the lines that start with [ and end with ]\n",
    "    headerLinesIndex = [i for i, line in enumerate(lines) if line.startswith('[') and line.endswith(']')]\n",
    "\n",
    "    for i in range(len(headerLinesIndex)):\n",
    "        header_line = lines[headerLinesIndex[i]][1:-1]  # remove square brackets\n",
    "        if header_line in songSegmentsDict:\n",
    "            songSegmentsDict[header_line][0] += 1\n",
    "        elif i == len(headerLinesIndex)-1:\n",
    "            songSegmentsDict[header_line] = [1, \" \".join(lines[headerLinesIndex[i]+1:]), lines[headerLinesIndex[i]+1:]]\n",
    "        else:\n",
    "            songSegmentsDict[header_line] = [1, \" \".join(lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]), lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]]\n",
    "\n",
    "    for header, lyrics in songSegmentsDict.items():\n",
    "        if returnSongSegments:\n",
    "            tokenSegmentsDict[header],subLyrics = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "            songSegmentsDict[header]=subLyrics\n",
    "        else:\n",
    "            tokenSegmentsDict[header] = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "        headerFreqsDict[header] = lyrics[0]\n",
    "\n",
    "    if returnSongSegments:\n",
    "        return tokenSegmentsDict,headerFreqsDict,songSegmentsDict\n",
    "    else:\n",
    "        return tokenSegmentsDict,headerFreqsDict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "songChunks,freqs =breakUpSongByHeaders(fullLyricsLilTecca,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songChunks['Verse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "songChunks,freqs,songSegs =breakUpSongByHeaders(fullLyricsLilTeccaTripleVerse,tokenizer,returnSongSegments=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songSegs['Verse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nah, nah, nah Yeah, oh-oh Yeah, oh no We love you Tecca Yeah, yeah She just hit my phone, she said, \"Tecca, you a winner\" (That\\'s Tec) I just took her home, then I turn her to a sinner, yeah Rambow ']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songSegs['Intro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intro': ['Nah, nah, nah Yeah, oh-oh Yeah, oh no We love you Tecca Yeah, yeah She just hit my phone, she said, \"Tecca, you a winner\" (That\\'s Tec) I just took her home, then I turn her to a sinner, yeah Rambow '],\n",
       " 'Chorus': ['She just hit my phone, she said, \"Tecca, you a winner\" (Yeah) Took her home, then I turn her to a sinner, yeah I just got a check, I ate lobster for dinner She like my style, she tryna turn me to her nigga, yeah I just woke up, now they say that I’m a star I just wanna ball with my guys Drive off the Wock\\', he just caught a DUI He think he know the answers, nigga, like he Bill Nye'],\n",
       " 'Verse': [\"Bitch, I feel like A.I., nigga, never need to practice I got two clips 'cause that chopper automatic And I started talkin’ shit, I got tired of this rappin' But I been making' hits, most these niggas, they been nappin' And my lyrics hit her hard, like her nigga, he was stabbin' LSD hit his brain, yeah, that nigga, he been tabbin' I just got your shorty, yeah, my niggas, we been tappin' Walk to the bank, Chief Keef, I be laughin' Red, blue, yellow, nigga, you could pick your Power Ranger I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can't chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor\",\n",
       "  \"Bitch, I feel like A.I., nigga, never need to practice I got two clips 'cause that chopper automatic And I started talkin’ shit, I got tired of this rappin' But I been making' hits, most these niggas, they been nappin' And my lyrics hit her hard, like her nigga, he was stabbin' LSD hit his brain, yeah, that nigga, he been tabbin' I just got your shorty, yeah, my niggas, we been tappin' Walk to the bank, Chief Keef, I be laughin' Red, blue, yellow, nigga, you could pick your Power Ranger I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can't chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor\",\n",
       "  \"Bitch, I feel like A.I., nigga, never need to practice I got two clips 'cause that chopper automatic And I started talkin’ shit, I got tired of this rappin' But I been making' hits, most these niggas, they been nappin' And my lyrics hit her hard, like her nigga, he was stabbin' LSD hit his brain, yeah, that nigga, he been tabbin' I just got your shorty, yeah, my niggas, we been tappin' Walk to the bank, Chief Keef, I be laughin' Red, blue, yellow, nigga, you could pick your Power Ranger I could fuck, but I won’t date ya Getting bands, but I can’t save her Fast nigga, but I can't chase her 360, quick scope, FaZe him God-mode, aim-bot, laser Cut you off, I got that razor \"]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songSegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[  101, 24883,   117,  9468,  1324,   117,  9468,  1324,  2814,   117,\n",
       "            9294,   118,  9294,  2814,   117,  9294,  1185,  1284,  1567,  1128,\n",
       "           12008, 19495,  2814,   117,  8147,  1153,  1198,  1855,  1139,  2179,\n",
       "             117,  1131,  1163,   117,   107, 12008, 19495,   117,  1128,   170,\n",
       "            2981,   107,   113,  1337,   112,   188, 12008,  1665,   114,   146,\n",
       "            1198,  1261,  1123,  1313,   117,  1173,   146,  1885,  1123,  1106,\n",
       "             170, 11850,  2511,   117,  8147, 11447, 14251,   102]]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songChunks['Intro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intro': 1, 'Chorus': 2, 'Verse': 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap: The function now breaks up the lyrics by headers and splits large chunks if needed. While the example of the verse with a large chunk I showed was storing the same lyrics 3x, that's just becase I copy-pasted the lyrics. In reality, the lyrics would've been different but successfully broken up into chunks if needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Final Function For Inferences based on Lyrics\n",
    "\n",
    "NOTE 1 - if top rating is neutral, Either we should \n",
    "1. discard segment and move on to next segment\n",
    "2. Take the second highest rating and use that as the sgement label\n",
    "\n",
    "Note 2 - If all ratings are neutral, we should use the linear model to get the final label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge cases taken into account:\n",
    "- the song segments that are too long are divided by n+1 chunks where n is the number of chunks it should take to fit into the model. This is because the songs are split by lines so to avoid a long line making the chunk too big, we split it into n+1 chunks\n",
    "- factoring in the frequencies of headers in the song to determine the weights of the headers\n",
    "\n",
    "Edge cases not taken into account:\n",
    "- adding periods at the end of lines\n",
    "- adding a check for songs with no headers\n",
    "- adding a check for songs not in english\n",
    "- considering random brackets that are not headers!\n",
    "- no headers at all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoodLabelFromLyrics(lyrics,model, tokenizer, emotion_dict, emotionsAsValenceArousal,printValenceArousal = False,disregardNeutral=True, printRawScores=False, printTopN=False,topScoresToPrint=3,max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "    softmaxScoresPerHeader = {}\n",
    "    model.to(device)\n",
    "    \n",
    "    #part 1 - break up the lyrics into chunks and get the tokens\n",
    "    if returnSongSegments:\n",
    "        songTokenChunks,freqs,songSegs =breakUpSongByHeaders(lyrics,tokenizer,returnSongSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "    else:\n",
    "        songTokenChunks,freqs =breakUpSongByHeaders(lyrics,tokenizer,returnSongSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "\n",
    "    #part 2 - get the softmax score for each chunk\n",
    "\n",
    "    if len(songTokenChunks) == 1:\n",
    "        disregardNeutral=False\n",
    "\n",
    "    #softmax scores returns COMBINED SINGLE LABEL -- MAYBE TRY MULTIPLE LABELS AND TAKE THE MOST COMMON\n",
    "    for header,tokenChunksPerHeaders in songTokenChunks.items():\n",
    "        for tokenChunk in tokenChunksPerHeaders:\n",
    "            ## ^^ If I encode multiple songs in batches, then I would make another for loop here and not just use tokenChunk[0]\n",
    "## but it might be too complicated to do that this way.  I'd have to make a function that breaks up the lyrics into chunks, and then return the chunks in a way that we still know which chunk belongs to which song and header\n",
    "            if header not in softmaxScoresPerHeader:\n",
    "                softmaxScoresPerHeader[header] = getSoftmax(model,tokenizer,tokens=tokenChunk[0],n=topScoresToPrint, printTopN=printTopN, printRawScores=printRawScores,device=device)\n",
    "            else:\n",
    "                softmaxScoresPerHeader[header] += getSoftmax(model,tokenizer,tokens=tokenChunk[0],n=topScoresToPrint, printTopN=printTopN, printRawScores=printRawScores,device=device)\n",
    "            \n",
    "            \n",
    "    #Part 3 determine what to do with the neutral labels\n",
    "    moodLabel = convertScoresToLabels(softmaxScoresPerHeader,freqs, emotionsAsValenceArousal,emotion_dict,disregardNeutral=disregardNeutral,printValenceArousal=printValenceArousal)\n",
    "\n",
    "    #part 4 - return the most common label\n",
    "    return moodLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOnlyMoodLabelFromLyrics(lyrics,model=model, tokenizer=tokenizer, emotion_dict=emotion_dict, emotionsAsValenceArousal=emotionsAsValenceArousal,device='cpu',printValenceArousal=False):\n",
    "    mood = getMoodLabelFromLyrics(lyrics,model, tokenizer, emotion_dict, emotionsAsValenceArousal, device=device,printValenceArousal=printValenceArousal)\n",
    "    return mood\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Function\n",
    "\n",
    "It appears to run faster on cpu, probalby because it is a single inference\n",
    "\n",
    "Also, the wrapper function could be made to initialize the input arguments as opposed to how I currently passed them in since they were global variables.  Every other argument not in debugging mode could just be ignored.\n",
    "\n",
    "The wrapper function could also be adjusted to just takes spotify UID which then could be used to get the lyrics and then get the mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.23153104957236811\n",
      "Arousal:  0.36577051177246167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsLilTecca,device='cuda',printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.2315299444111588\n",
      "Arousal:  0.3657697230805753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsLilTecca,device='cpu',printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.15500063256877183\n",
      "Arousal:  0.6561800880383092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'energetic'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsLilTeccaTripleVerse,device='cpu',  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.15499951472283996\n",
      "Arousal:  0.6561808570475477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'energetic'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsLilTeccaTripleVerse,device='cuda',  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.1908565733454516\n",
      "Arousal:  0.23083973527383403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsDieForYouRemix,device='cuda',  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.19085645680389843\n",
      "Arousal:  0.23083977220239832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsDieForYouRemix,device='cpu',  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.4649246821842638\n",
      "Arousal:  0.47514038863251995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsCrazyInLove,device='cpu',  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  0.46492462691114106\n",
      "Arousal:  0.4751403152463806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'excited'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsCrazyInLove,device='cuda', printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.13130829774284705\n",
      "Arousal:  -0.12478131703577068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'depressed'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsGoEasyOnMe,device='cpu', printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.13130859021733457\n",
      "Arousal:  -0.12478142331046903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'depressed'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsGoEasyOnMe,device='cuda',  printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.5494499269660424\n",
      "Arousal:  -0.00013627082760764297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsNumb,device='cpu', printValenceArousal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence:  -0.5494499265712764\n",
      "Arousal:  -0.00013627050615819258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOnlyMoodLabelFromLyrics(fullLyricsNumb,device='cuda', printValenceArousal=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Integration with the rest of the project\n",
    "\n",
    "in order to use this, there are two big things that need to be done:\n",
    "\n",
    "0. Going from the users song ID to the lyrics\n",
    "\n",
    "1. get the lyrics from the song to input to function - this is done by using the genius api. Ideally it should be a single string with clear line breaks in order to split the lines.  If we can already get the lines split, then this function needs to be adjusted to account for that\n",
    "\n",
    "2. Applying tokenization and obtaining inferences - while we could call the huggingface API, I'm not sure if the tokenization is also something we could use thru the API.  If not, we might be able to pickle the tokenizer/model and use a cloud function with a CPU since it is fast\n",
    "\n",
    "3. Determine how to communicate when to use the results of the linear model and when to use the sentiment analysis model (Probably if this is close to a neutral result we want to communicate to rely on the linear model)\n",
    "\n",
    "3. Storing the labels in the database\n",
    "\n",
    "4. Using the label to determine which users centroid should be updated.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CudaTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2fa8f4dd4130559c9bb206ea5c1e5e62ed157dfd2663e7fcefd868ad60d1c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
