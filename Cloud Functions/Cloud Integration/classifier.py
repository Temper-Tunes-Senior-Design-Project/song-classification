import pandas as pd
import pickle;
import database

from sklearn.preprocessing import StandardScaler

'''
Gathers the song ids for all the user's liked songs
------------------------------------
Parameters
------------------------------------
    sp- Instance of an authenticated Spotipy client
'''
def getLikedTrackIDs(sp):
    track_ids = []
    offset = 0
    limit = 50
    liked_tracks = sp.current_user_saved_tracks(limit=limit, offset=offset)
    #TODO: Add logic to check if we can avoid the break
    while True:
        for item in liked_tracks['items']:
            track_ids.append(item['track']['id'])
        offset += limit
        
        if len(liked_tracks['items']) < limit:
            # All tracks have been retrieved
            break
        
        liked_tracks = sp.current_user_saved_tracks(limit=limit, offset=offset)
    
    return track_ids

'''
Gathers the track features for the songs provided 
------------------------------------
Parameters
------------------------------------
    sp- Instance of an authenticated Spotipy client
    track_ids - A list of track_ids to get the features for
'''
def getTrackFeatures(sp, track_ids):
    dfs = []
    #Retrieves the features for 50 tracks at a time from spotipy
    for i in range(0, len(track_ids), 50):
        # Retrieve track features with current offset
        current_features = sp.audio_features(track_ids[i:i+50])
        
        # Convert to DataFrame
        df = pd.DataFrame(current_features)
        
        # Remove columns that we don't need
        df = df.drop(['type', 'uri', 'analysis_url', 'track_href','id'], axis=1)
        
        
        # Append to list of dataframes
        dfs.append(df)
    
    # Concatenate all dataframes into a single one
    features_df = pd.concat(dfs, ignore_index=True)
    
    features = features_df.to_numpy()
    
    return features_df

'''
Gathers the track features of songs that aren't yet present within our database
------------------------------------
Parameters
------------------------------------
    access_token - A Spotify OAuth2.0 credential
    uid - The users unique identifier generated by Firebase
    model - The pickled TF model(this could be stored as a global)
'''
def getSongLabels(access_token,uid):
    track_ids = getLikedTrackIDs(access_token)#supposed to be track_ids = retrieveTrackIdsToken(access_token, user_prior_login_date)
#DB track_ids = checkIdsInDatabase(track_ids)
    features = getTrackFeatures(access_token, track_ids) 
#DB saveTrackFeaturesToDatabase(features)  also maybe UID to update user info
#DB updateUserLastLoginDate(UID)
    return features, track_ids

'''
Bounds the data to fit within the BERT model classification
------------------------------------
Parameters
------------------------------------
    features - A pandas dataframe containing all of the features of the users playlist
'''
def clipAndNormalize(features):
    #clip the features to the range of the training data

    features['danceability'] = features['danceability'].clip(lower=0.22718080000000002, upper=0.906)
    features['energy'] = features['energy'].clip(lower=0.03545904, upper=0.978)
    features['loudness'] = features['loudness'].clip(lower=-26.4981552, upper=-1.6015904000000007)
    features['speechiness'] = features['speechiness'].clip(lower=0.0257, upper=0.46640959999999926)
    features['acousticness'] = features['acousticness'].clip(lower=8.353136000000001e-05, upper=0.9884095999999992)
    features['instrumentalness'] = features['instrumentalness'].clip(lower=0.0, upper=0.956)
    features['liveness'] = features['liveness'].clip(lower=0.0494, upper=0.697)
    features['valence'] = features['valence'].clip(lower=0.0382, upper=0.923)
    features['tempo'] = features['tempo'].clip(lower=63.7631808, upper=188.00344319999996)
    features['duration_ms'] = features['duration_ms'].clip(lower=88264.8768, upper=372339.1727999991)
    features['time_signature'] = features['time_signature'].clip(lower=3.0, upper=5.0)
    
    #normalize the data
    scaler = StandardScaler()
    preprocessedFeatures = scaler.fit_transform(features)
    return preprocessedFeatures

'''
Get the mood label of a song given its features
------------------------------------
Parameters
------------------------------------
    model - The pickled TF model(this could be stored as a global)
    songFeatures - A pandas dataframe containing all of the songs to be predicted
'''
def getMoodLabelMLP(songFeautures):
        with open('MLP1.pkl','rb') as f:
            model = pickle.load(f)
        prediction = model.predict(songFeautures)
        pred_probability=model.predict_proba(songFeautures)
        return prediction, pred_probability

'''
Perform classification on all of the songs within a users liked song library
------------------------------------
Parameters
------------------------------------
    spotipy - The authenticated spotipy client
    uid - The users unique identifier generated by Firebase
    model - The pickled TF model(this could be stored as a global)
'''
def populateTrackMoods(spotipy,UID):
    features,track_ids = getSongLabels(spotipy,UID)
    preprocessedFeatures = clipAndNormalize(features)
    prediction, probablity = getMoodLabelMLP(preprocessedFeatures)
    for i in range(0, len(track_ids)):
        database.updateSong(track_ids[i], int(prediction[i]))
    #either this can return these 3 pieces of information or we can save them to the database and return nothing
    return prediction, probablity, track_ids