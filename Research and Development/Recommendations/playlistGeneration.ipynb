{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c770d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "\n",
    "# from sklearn.discriminant_analysis import StandardScaler\n",
    "import scipy.stats as stats\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import pickle\n",
    "# #this folder location will be changed to DB location in actual cloud function\n",
    "# from os import chdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from bs4 import element\n",
    "# from copy import deepcopy\n",
    "# import re\n",
    "import random\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e35ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b039a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Spotify and Firebase Credentials\n",
    "sp = None\n",
    "def spotify_client():\n",
    "    global sp\n",
    "    sp_cred = None\n",
    "    with open('spotify_credentials.json') as credentials:\n",
    "        sp_cred = json.load(credentials)\n",
    "    sp = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(sp_cred[\"client_id\"],sp_cred['client_secret']))\n",
    "\n",
    "\n",
    "cred,db = None,None\n",
    "def firestoreConnection():\n",
    "    global cred\n",
    "    global db\n",
    "    cred = credentials.Certificate(\"mood-swing-6c9d0-firebase-adminsdk-9cm02-66f39cc0dd.json\")\n",
    "    if not firebase_admin._apps:\n",
    "        firebase_admin.initialize_app(cred)\n",
    "    db = firestore.client()\n",
    "    \n",
    "LR_model = None\n",
    "def load_LR_model():\n",
    "    global LR_model\n",
    "    with open('logreg_model1.pkl','rb') as f:\n",
    "        LR_model = pickle.load(f)\n",
    "    warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but LogisticRegression was fitted with feature names\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689f4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moods = ['sad','angry','energetic','excited','happy','content','calm','depressed'] #Represents DB indexing of moods\n",
    "\n",
    "# Function to return new songs to be added to the user's generated playlist\n",
    "# Takes the specified mood, the number of new songs, and the 5 closest songs to plug into the recommended function\n",
    "def generateNewSongsList(mood, num_songs, closest_song_ids, old_songs_list): ###user_id???\n",
    "    global sp\n",
    "    if sp == None:\n",
    "        spotify_client()\n",
    "        firestoreConnection()\n",
    "    \n",
    "    mood_index = moods.index(mood) #Numbered label of mood\n",
    "    #specify target and close moods\n",
    "    acceptable_moods = [mood_index, (mood_index + len(moods) - 1) % len(moods), (mood_index + 1)%len(moods)] \n",
    "    song_count = 0\n",
    "    count_mood_index = 0 #TESTING TO DETERMINE RATE OF SONG ADDITION\n",
    "    count_other_moods = 0\n",
    "    count_similar_moods = 0\n",
    "    counts = {}\n",
    "        \n",
    "    #         #0. get the track ids of unlabelled songs from the list of new liked songs from the user\n",
    "    #         last_login = DB.get_last_login(UID) #IF NONE, return ''\n",
    "\n",
    "    #         #If last login is a string, we need to convert it to a utc datetime object\n",
    "    #         #if isinstance(last_login, str):\n",
    "    #         #        last_login = datetime.strptime(last_login, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    # Use Spotipy to retrieve track information\n",
    "    track_info = sp.tracks(closest_song_ids)['tracks']\n",
    "    # Remove any elements that are None\n",
    "    track_info = [track for track in track_info if track is not None]\n",
    "    if len(track_info) == 0:\n",
    "        return {\"error\": \"could not identify any tracks in the closest songs list\"}\n",
    "    # Extract the URIs from the track information\n",
    "    track_uris = [track['uri'] for track in track_info]\n",
    "    final_song_ids = []\n",
    "    while len(final_song_ids) < num_songs:        \n",
    "        # Get recommended tracks and add them to final_song_ids if mood is classified as specified mood\n",
    "        tracks = sp.recommendations(seed_tracks=track_uris[:5], limit=50)['tracks'] ##############################LIMIT\n",
    "        track_ids = [track[\"id\"] for track in tracks if track[\"id\"] not in final_song_ids and track[\"id\"] not in old_songs_list]\n",
    "        #Split ids by whether they are already labelled or not\n",
    "        known_track_moods_dict = getAlreadyLabelled(track_ids)\n",
    "        new_track_ids = [track_id for track_id in track_ids if track_id not in known_track_moods_dict.keys()]\n",
    "        # Get song features of the new ids\n",
    "        features_df = retrieveTrackFeatures(new_track_ids)\n",
    "#         features_df = retrieveTrackFeatures(new_track_ids)\n",
    "#         # Preprocess features\n",
    "#         features_dict = clipAndNormalize(features_df)\n",
    "        \n",
    "# #         Make a dictionary of song titles and artist names\n",
    "#         scraper_inputs = getTitlesAndArtists(new_track_ids)\n",
    "        \n",
    "        # Dictionary for lyrics of songs that are found\n",
    "#         all_lyrics_dict = getScrapedLyrics(scraper_inputs)\n",
    "        \n",
    "#         overlap_keys = [key for key in features_dict.keys() if key in all_lyrics_dict.keys()]\n",
    "#         only_features = [key for key in features_dict.keys() if key not in overlap_keys]\n",
    "#         only_lyrics = [key for key in all_lyrics_dict.keys() if key not in overlap_keys]\n",
    "        \n",
    "        # Get predictions and update database\n",
    "        # If there are no features or lyrics, and no songs are already labelled return an error\n",
    "#         if len(features_dict.keys()) == 0 and len(all_lyrics_dict.keys()) == 0 and len(known_track_moods_dict.keys()) == 0:\n",
    "        if features_df.shape[0] == 0 and len(known_track_moods_dict.keys()) == 0:\n",
    "            return {\"error\": \"Issue with model and/or spotify server\"}\n",
    "        else:\n",
    "            predictions = {}\n",
    "            stop_loops = False\n",
    "            \n",
    "#             #for first version, tokenize the lyrics and then pass then to the model inside the for loop\n",
    "#             for key in overlap_keys: #- could probably be done in batches regardless\n",
    "#                 if not(stop_loops):\n",
    "#                     #################TEST\n",
    "#                     RF_pred, RF_pred_probability = getMoodLabelRF([features_dict[key]])\n",
    "#                     predictions[key]=RF_pred\n",
    "#                     if RF_pred == mood_index: song_count += 1\n",
    "#                     stop_loops = song_count == num_songs\n",
    "#                     ############\n",
    "                    \n",
    "#                     RF_pred, RF_pred_probability = getMoodLabelRF(features_dict[key])\n",
    "\n",
    "#                     BERT_pred, RF_flag = getOnlyMoodLabelFromLyrics(all_lyrics_dict[key])\n",
    "#                     if RF_pred == BERT_pred or RF_flag == True:\n",
    "#                         prediction = RF_pred\n",
    "#                     else:\n",
    "#                         model_pred_diffs = (RF_pred - BERT_pred)\n",
    "#                         if RF_pred > BERT_pred:\n",
    "#                             sum_probabilities = RF_pred + model_pred_diffs\n",
    "#                         else:\n",
    "#                             sum_probabilities = RF_pred - model_pred_diffs\n",
    "#                         #if sum_probabilities outside of below 0, then do 8-sum_probabilities\n",
    "#                         if sum_probabilities < 0:\n",
    "#                             prediction = 8 + sum_probabilities\n",
    "#                         elif sum_probabilities > 7:\n",
    "#                             prediction = sum_probabilities - 7\n",
    "#                         else:\n",
    "#                             prediction = sum_probabilities\n",
    "\n",
    "#                     predictions[key]=prediction\n",
    "#                     if prediction == mood_index: song_count += 1\n",
    "#                     stop_loops = song_count == num_songs\n",
    "                    \n",
    "\n",
    "#             for key in only_features:\n",
    "            for key, row in features_df.iterrows():\n",
    "                if not(stop_loops):\n",
    "                    data = row.values.reshape(1,-1)\n",
    "                    LR_pred, LR_pred_probability = getMoodLabelLR(data)\n",
    "                    predictions[key]=LR_pred\n",
    "                    if LR_pred in acceptable_moods: song_count += 1\n",
    "                    stop_loops = (song_count == num_songs)\n",
    "\n",
    "            # Add song moods to DB\n",
    "#             addTrackMoodToDB(predictions)\n",
    "            \n",
    "            # Combine predictions and known labels\n",
    "            # Currently, this will prioritize adding new songs to playlist over hits in our DB\n",
    "            num_songs_remaining = num_songs - song_count\n",
    "            ###STAT DICT FOR TESTING\n",
    "            stat_dict = {**known_track_moods_dict, **predictions}\n",
    "            #Shorten list of songs if necessary, start with the known moods (will add close moods as well)\n",
    "            ids_to_add = [key for key in known_track_moods_dict.keys() \n",
    "                          if known_track_moods_dict[key] in acceptable_moods]\n",
    "            if len(ids_to_add) > num_songs_remaining:\n",
    "                ids_to_add = ids_to_add[:num_songs_remaining]\n",
    "            song_count += len(ids_to_add)\n",
    "        \n",
    "        # Add the remaining (newly predicted) song IDs where mood = mood_index\n",
    "        ids_to_add.extend([key for key in predictions.keys() if predictions[key] in acceptable_moods])\n",
    "        final_song_ids.extend(ids_to_add)\n",
    "        # TESTING TO DETERMINE RATE OF SONG ADDITION\n",
    "        count_mood_index += len([key for key in stat_dict.keys() if stat_dict[key] == mood_index])\n",
    "        count_other_moods += len(stat_dict) - len(ids_to_add)\n",
    "        count_similar_moods += len([key for key in stat_dict.keys() \n",
    "                                    if stat_dict[key] != mood_index \n",
    "                                    and stat_dict[key] in acceptable_moods])\n",
    "       \n",
    "        ###TESTING\n",
    "        print(f\"count of specified moods: {count_mood_index}\")\n",
    "        print(f\"count of other moods: {count_other_moods}\")\n",
    "        print(f\"count of similar moods: {count_similar_moods}\")\n",
    "        \n",
    "        unique_elements = range(8)\n",
    "        for elem in unique_elements:\n",
    "            count = list(stat_dict.values()).count(elem)\n",
    "            counts[elem] = counts.get(elem,0) + count\n",
    "        print(f\"count of labels: {counts}\")\n",
    "        count_prob = {k: v/sum(counts.values()) for k,v in counts.items()}\n",
    "        print(f\"probability of labels: {count_prob}\")\n",
    "\n",
    "\n",
    "#           DB.update_user_liked_songs(UID,predictions.keys()) \n",
    "            # ^^Need to add a check to discard songs no longer on spotify, \n",
    "            # otherwise we might recommend songs that are no longer on spotify\n",
    "\n",
    "#           DB.update_last_login(UID,datetime.utcnow())\n",
    "    return final_song_ids\n",
    "\n",
    "# Function that takes in the closest songs to the user's centroid and \n",
    "# Returns a list of randomly selected ids which favors the closest songs\n",
    "# to the user's centroid\n",
    "def generateOldSongsList(num_old_songs, closest_song_ids):\n",
    "    if num_old_songs > len(closest_song_ids): return closest_song_ids\n",
    "    song_ids_list = []\n",
    "    final_list = []\n",
    "    songs_to_iterate_over = closest_song_ids.copy()\n",
    "    while len(final_list) < num_old_songs:\n",
    "        song_ids_list = songs_to_iterate_over\n",
    "        for index, song_id in enumerate(song_ids_list):\n",
    "            # add an item to the list 70% of the time if we don't have enough songs yet\n",
    "            if not(len(final_list) >= num_old_songs) and random.random() < 0.7:\n",
    "                final_list.append(song_id)\n",
    "                songs_to_iterate_over.pop(index)\n",
    "    return final_list\n",
    "\n",
    "# Combines the lists created by the generation functions to return the new list\n",
    "def buildPlaylist(mood, percentage_new_songs, num_total_songs, closest_songs_list):\n",
    "    # Generate a list of already liked songs\n",
    "    # Check if there are enough songs in closest_songs_list\n",
    "    num_old_songs = int(round((1 - percentage_new_songs) * num_total_songs))\n",
    "    if len(closest_songs_list) < num_old_songs:\n",
    "        num_old_songs = len(closest_songs_list)\n",
    "        old_songs_list = closest_songs_list\n",
    "    else:\n",
    "        old_songs_list = generateOldSongsList(num_old_songs, closest_songs_list)\n",
    "    # Generate a list of newer songs\n",
    "    num_new_songs = num_total_songs - num_old_songs\n",
    "    new_songs_list = generateNewSongsList(mood, num_new_songs, closest_songs_list[:5], old_songs_list)\n",
    "    if type(new_songs_list) is dict:\n",
    "        err = new_songs_list['error']\n",
    "        return err\n",
    "    \n",
    "    # Combine the lists, shuffle and return the playlist (song ids)\n",
    "    combined_ids = old_songs_list + new_songs_list \n",
    "    random.shuffle(combined_ids)\n",
    "    return combined_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51b14dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#______________________________________________\n",
    "# Database Operations\n",
    "#______________________________________________\n",
    "            \n",
    "def getTrackMoodFromDB(track_id):\n",
    "    doc_ref = db.collection('songs').document(track_id)\n",
    "    doc_data = doc_ref.get()\n",
    "    if doc_data.exists:\n",
    "        return doc_data.to_dict().get('mood')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getAlreadyLabelled(track_ids):\n",
    "    already_labelled = {}\n",
    "    for track_id in track_ids:\n",
    "        mood = getTrackMoodFromDB(track_id)\n",
    "        if mood is not None:\n",
    "            already_labelled[track_id] = mood\n",
    "    return already_labelled\n",
    "\n",
    "def addTrackMoodToDB(tracks_dict):\n",
    "    for track_id, mood in tracks_dict.items():\n",
    "        doc_ref = db.collection('songs').document(track_id)\n",
    "        doc_ref.set({\n",
    "            'mood': int(mood[0])\n",
    "        })\n",
    "    \n",
    "#______________________________________________\n",
    "# LR Model Classifcation\n",
    "#______________________________________________\n",
    "\n",
    "def getMoodLabelLR(songFeaturesDF):\n",
    "    if LR_model is None:\n",
    "        load_LR_model()\n",
    "    prediction = LR_model.predict(songFeaturesDF)\n",
    "    pred_probability= LR_model.predict_proba(songFeaturesDF)\n",
    "    return prediction, pred_probability\n",
    "\n",
    "def retrieveTrackFeatures(track_ids):\n",
    "    dfs = []\n",
    "    for i in range(0, len(track_ids), 50):\n",
    "        # Retrieve track features with current offset\n",
    "        current_features = sp.audio_features(track_ids[i:i+50])\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(current_features)\n",
    "        \n",
    "#         # Remove columns that we don't need\n",
    "#         df = df.drop(['type', 'uri', 'analysis_url', 'track_href'], axis=1)\n",
    "        \n",
    "        df = df[['id', 'valence', 'energy']]\n",
    "        \n",
    "        # Append to list of dataframes\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes into a single one\n",
    "    features_df = pd.concat(dfs, ignore_index=True)\n",
    "    features_df.set_index(\"id\", inplace=True)\n",
    "    #convert to dictionary, with track id as key\n",
    "#     features_dict = features_df.set_index('id').T.to_dict('list')\n",
    "    return features_df\n",
    "\n",
    "\n",
    "# def clipAndNormalize(features):\n",
    "#     #clip the features to the range of the training data\n",
    "#     features['danceability'] = features['danceability'].clip(lower=0.25336000000000003, upper=0.9188199999999997)\n",
    "#     features['energy'] = features['energy'].clip(lower=0.047536, upper=0.982)\n",
    "#     features['loudness'] = features['loudness'].clip(lower=-24.65708, upper=-0.8038200000000288)\n",
    "#     features['speechiness'] = features['speechiness'].clip(lower=0.0263, upper=0.5018199999999997)\n",
    "#     features['acousticness'] = features['acousticness'].clip(lower=1.4072e-04, upper=0.986)\n",
    "#     features['instrumentalness'] = features['instrumentalness'].clip(lower=0.0, upper=0.951)\n",
    "#     features['liveness'] = features['liveness'].clip(lower=0.044836, upper=0.7224599999999991)\n",
    "#     features['valence'] = features['valence'].clip(lower=0.038318, upper=0.9348199999999998)\n",
    "#     features['tempo'] = features['tempo'].clip(lower=66.34576, upper=189.87784)\n",
    "#     features['duration_ms'] = features['duration_ms'].clip(lower=86120.0, upper=341848.79999999976)\n",
    "#     features['time_signature'] = features['time_signature'].clip(lower=3.0, upper=5.0)\n",
    "    \n",
    "#     columns_to_log=['liveness', 'instrumentalness', 'acousticness', 'speechiness','loudness','energy']\n",
    "#     columns_to_log = ['energy']\n",
    "\n",
    "#     for i in columns_to_log:\n",
    "#         if i == 'loudness':\n",
    "#             features[i] = features[i] + 60\n",
    "#         features[i] = np.log(features[i]+1)\n",
    "\n",
    "#     #normalize the data\n",
    "#     scaler = pickle.load(open('scaler3.pkl', 'rb'))\n",
    "#     #fit on all columns except the track id\n",
    "#     rawfeatures = features.drop(['id'], axis=1)\n",
    "#     preprocessedFeatures = scaler.transform(rawfeatures)\n",
    "\n",
    "#     #convert to dictionary, with track id as key\n",
    "#     preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    \n",
    "#     #apply z-score normalization\n",
    "#     for i in columns_to_log:\n",
    "#         preprocessedFeatures[i] = stats.zscore(preprocessedFeatures[i])\n",
    "#         preprocessedFeatures.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "#     preprocessedFeatures['id']= features['id']\n",
    "    \n",
    "#     preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')\n",
    "#     return preprocessedFeatures\n",
    "\n",
    "\n",
    "# #______________________________________________\n",
    "# # Scraper Functions\n",
    "# #______________________________________________\n",
    "\n",
    "# def getTitlesAndArtists(track_ids):\n",
    "#     titleArtistPairs = {}\n",
    "#     for i in range(0,len(track_ids),50):\n",
    "#         tracks = sp.tracks(track_ids[i:i+50])\n",
    "#         for track in tracks['tracks']:\n",
    "#             title=track['name']\n",
    "#             #check if the track ends with (feat. artist) using a regex\n",
    "#             if re.search(r' \\(feat. .*\\)$', title):\n",
    "#                 #remove the (feat. artist) from the title\n",
    "#                 title = re.sub(r' \\(feat. .*\\)$', '', title)\n",
    "\n",
    "#             artists=[]\n",
    "#             for artist in track['artists']:\n",
    "#                 artists.append(artist['name'])\n",
    "#             titleArtistPairs[track['id']] = {'title':title,'artist(s)':artists}\n",
    "\n",
    "#     return titleArtistPairs\n",
    "\n",
    "# def getScrapedLyrics(scraperInputs):\n",
    "#         all_lyrics_dict = {}\n",
    "#         for id, songInfo in scraperInputs.items():\n",
    "#                 #maybe add a sleep or something to prevent getting blocked\n",
    "#                 lyrics = scrapeLyrics(songInfo['artist(s)'],songInfo['title'])\n",
    "#                 if len(lyrics) > 0:\n",
    "#                         all_lyrics_dict[id]=lyrics\n",
    "#         return all_lyrics_dict\n",
    "\n",
    "# #Helps parse miscellaneous tags <i>, </br>, etc,.\n",
    "# def _lyricsHelper(html, lyrics_list):\n",
    "#     for tag in html.childGenerator():\n",
    "#         if type(tag) == element.NavigableString:\n",
    "#             _handleLyricAppend(lyrics_list, tag.text.strip())\n",
    "#         elif tag.name == 'br' and lyrics_list[len(lyrics_list) - 1] != '':\n",
    "#             lyrics_list.append('')\n",
    "#         elif html.name == 'a':\n",
    "#             _lyricsHelper(tag, lyrics_list)\n",
    "\n",
    "# #Reads the HTML for lyrics dividers (if they exist) and appends the lyrics line by line to a list\n",
    "# def _getLyricsFromHTML(html):\n",
    "#     lyrics = html.findAll(\"div\", {\"data-lyrics-container\" : \"true\"})\n",
    "#     lyrics_list = ['']\n",
    "#     for segment in lyrics:\n",
    "#         for a in segment.childGenerator():\n",
    "#             lyric = None\n",
    "#             if type(a) == element.NavigableString:\n",
    "#                 lyric = a.strip()\n",
    "#                 _handleLyricAppend(lyrics_list, lyric)\n",
    "#             else:\n",
    "#                 _lyricsHelper(a, lyrics_list)\n",
    "#             if a.name == 'br' and lyrics_list[len(lyrics_list) - 1] != '':\n",
    "#                 lyrics_list.append('')\n",
    "#     return lyrics_list\n",
    "\n",
    "# #Helper function to handle appending and manipulating lyrics_list. A new line is generated only for </br> tags\n",
    "# def _handleLyricAppend(lyrics_list, lyric):\n",
    "#     if lyric is not None:\n",
    "#         last_index = len(lyrics_list) - 1\n",
    "#         #Handle special cases (parenthesis and symbols stick with words for instance)\n",
    "#         if lyrics_list[last_index] != '' and (lyrics_list[last_index][-1] in ['(','[','{','<'] or lyric in [')',']','}','>','!','?',',','.']):\n",
    "#             lyrics_list[last_index] += lyric\n",
    "#         else:\n",
    "#             lyrics_list[last_index] += \" \" + lyric if lyrics_list[last_index] != '' else lyric\n",
    "\n",
    "# #Determines whether a song will need to be translated (returns the link if it does, otherwise returns None)\n",
    "# def _getSongTranslationLink(html):\n",
    "#     translation_tags = html.find_all('a', {\"class\": re.compile('TextButton*')})\n",
    "#     for tag in translation_tags:\n",
    "#         if \"english-translations\" in tag['href']:\n",
    "#             return tag['href']\n",
    "#     return None\n",
    "\n",
    "# #Determines whether a page exists\n",
    "# def _pageExists(html):\n",
    "#     return html.find('div', class_='render_404') == None\n",
    "        \n",
    "# #function to scrape lyrics from genius, takes an array of artists, and songname\n",
    "# def scrapeLyrics(artistnames, songname):\n",
    "#     lyrics_list = []\n",
    "#     found = False\n",
    "#     i = 0\n",
    "#     html = None\n",
    "#     while i < len(artistnames) and not(found):\n",
    "#         artistname = artistnames[i]\n",
    "#         artistname2 = str(artistname.replace(' ','-')) if ' ' in artistname else str(artistname)\n",
    "#         songname2 = str(songname.replace(' ','-')) if ' ' in songname else str(songname)\n",
    "#         page_url = 'https://genius.com/'+ artistname2 + '-' + songname2 + '-' + 'lyrics'\n",
    "#         page = requests.get(page_url)\n",
    "#         html = BeautifulSoup(page.text, 'html.parser') \n",
    "#         found = _pageExists(html)\n",
    "#         i += 1\n",
    "#     if found:\n",
    "#         #check if there is an english translation\n",
    "#         translation_url = _getSongTranslationLink(html)\n",
    "#         if translation_url is not None:\n",
    "#             page = requests.get(translation_url)\n",
    "#             html = BeautifulSoup(page.text, 'html.parser') \n",
    "#             lyrics_list = _getLyricsFromHTML(html)\n",
    "#         else:\n",
    "#             #If there isn't a translation, make sure it's in english in the first place\n",
    "#             english = False\n",
    "#             for script in html.findAll('script'):\n",
    "#                 if \"language\\\\\\\":\\\\\\\"en\" in str(script):\n",
    "#                     english = True\n",
    "#             if english: lyrics_list = _getLyricsFromHTML(html)\n",
    "#     return lyrics_list\n",
    "\n",
    "\n",
    "# #______________________________________________\n",
    "# # BERT Sentiment Analysis Functions\n",
    "# #______________________________________________\n",
    "\n",
    "# def getOnlyMoodLabelFromLyrics(lyrics):\n",
    "    \n",
    "#     #PART 1: DATA SETUP\n",
    "#     moods = ['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "#     nums = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "#     # create dictionary mapping strings to integers\n",
    "#     mood_to_num = {mood: num for mood,num in zip(moods,nums)}\n",
    "    \n",
    "#     #device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "    \n",
    "#     #change to ./path/goemotions_model\n",
    "#     BERT_model = AutoModelForSequenceClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\",local_files_only=True)\n",
    "#     #change to ./path/goemotions_tokenizer\n",
    "#     BERT_Tokenizer = AutoTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\",local_files_only=True)\n",
    "#     emotionsAsValenceArousal= { 'admiration':(.6,.4),'amusement':(.6,.2),'anger':(-.8,.6),'annoyance':(-.6,.6),'approval':(.8,.6),'caring':(.6,-.2),'confusion':(-.2,.2),'curiosity':(0,.4),'desire':(.6,.6),'despair':(-.8,-.6),'disappointment':(-.6,-.6),'disapproval':(-.8,.65),'disgust':(-.8,.2),'embarrassment':(-.6,.4),'envy':(-.6,.4),'excitement':(.6,.8),'fear':(-.6,.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'gratitude':(.6,-.6),'grief':(-.6,-.8),'joy':(.8,.2),'love':(.8,.4),'nervousness':(-.4,.6),'optimism':(.6,.2),'pride':(.6,.1),'realization':(.2,.2),'relief':(.4,-.4),'remorse':(-.6,-.4),'sadness':(-.8,-.2),'surprise':(.2,.6),'neutral':(0,0)}\n",
    "\n",
    "#     emotion_dict = BERT_model.config.id2label\n",
    "\n",
    "\n",
    "#     #PART 2 - get the mood label\n",
    "#     mood,relyOnLinearModel = getMoodLabelFromLyrics(lyrics,BERT_model, BERT_Tokenizer, emotion_dict, emotionsAsValenceArousal, device='cpu',printValenceArousal=False)\n",
    "#     mood = mood_to_num[mood]\n",
    "#     return mood,relyOnLinearModel\n",
    "\n",
    "\n",
    "# def getMoodLabelFromLyrics(lyrics,model, tokenizer, emotion_dict, emotionsAsValenceArousal,printValenceArousal = False,disregardNeutral=True, printRawScores=False, printTopN=False,topScoresToPrint=3,max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "#     relyOnLinearResults = False\n",
    "#     softmaxScoresPerHeader = {}\n",
    "#     model.to(device)\n",
    "    \n",
    "#     #part 1 - break up the lyrics into chunks and get the tokens\n",
    "#     if returnSongSegments:\n",
    "#         songTokenChunks,freqs,songSegs =breakUpSongByHeaders(lyrics,tokenizer,returnSongSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "#     else:\n",
    "#         songTokenChunks,freqs =breakUpSongByHeaders(lyrics,tokenizer,returnSongSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "\n",
    "#     #part 2 - get the softmax score for each chunk\n",
    "\n",
    "#     if len(songTokenChunks) == 1:\n",
    "#         disregardNeutral=False\n",
    "\n",
    "#     #softmax scores returns COMBINED SINGLE LABEL -- MAYBE TRY MULTIPLE LABELS AND TAKE THE MOST COMMON\n",
    "#     for header,tokenChunksPerHeaders in songTokenChunks.items():\n",
    "#         for tokenChunk in tokenChunksPerHeaders:\n",
    "#             ## ^^ If I encode multiple songs in batches, then I would make another for loop here and not just use tokenChunk[0]\n",
    "#             ## but it might be too complicated to do that this way.  \n",
    "#             # I'd have to make a function that breaks up the lyrics into chunks, \n",
    "#             # and then return the chunks in a way that we still know which chunk belongs to which song and header\n",
    "#             if header not in softmaxScoresPerHeader:\n",
    "#                 softmaxScoresPerHeader[header] = getSoftmax(model,tokenizer,tokens=tokenChunk[0],n=topScoresToPrint, printTopN=printTopN, printRawScores=printRawScores,device=device)\n",
    "#             else:\n",
    "#                 softmaxScoresPerHeader[header] += getSoftmax(model,tokenizer,tokens=tokenChunk[0],n=topScoresToPrint, printTopN=printTopN, printRawScores=printRawScores,device=device)\n",
    "            \n",
    "            \n",
    "#     #Part 3 determine what to do with the neutral labels\n",
    "#     moodLabel, valence, arousal = convertScoresToLabels(softmaxScoresPerHeader,freqs, emotionsAsValenceArousal,emotion_dict,disregardNeutral=disregardNeutral,printValenceArousal=printValenceArousal)\n",
    "\n",
    "#     if moodLabel=='top ratings all neutral':\n",
    "#         disregardNeutral=False\n",
    "#         moodLabel, valence, arousal = convertScoresToLabels(softmaxScoresPerHeader,freqs, emotionsAsValenceArousal,emotion_dict,disregardNeutral=disregardNeutral,printValenceArousal=printValenceArousal)\n",
    "#         relyOnLinearResults = True\n",
    "#     if moodLabel=='neutral' or (-0.1<valence<0.1 and -0.1<arousal<0.1):\n",
    "#         relyOnLinearResults = True\n",
    "#     #part 4 - return the most common label\n",
    "#     return moodLabel, relyOnLinearResults\n",
    "\n",
    "\n",
    "# # input: a string of whole song\n",
    "# # output: a dictionary of with header values and a list of tensors (sometmes more than 1 item) for each header chunk\n",
    "# def breakUpSongByHeaders(songLines, tokenizer, max_length=512, device=\"cuda\",  returnSongSegments=False):\n",
    "#     songSegmentsDict = {}\n",
    "#     tokenSegmentsDict = {}\n",
    "#     headerFreqsDict = {}\n",
    "\n",
    "#     #strip the trailing whitespace\n",
    "#     lines = [line.strip() for line in songLines]\n",
    "\n",
    "#     #find the lines that start with [ and end with ]\n",
    "#     headerLinesIndex = [i for i, line in enumerate(lines) if line.startswith('[') and line.endswith(']')]\n",
    "#     #check for consecutive headers indexes and remove the first one\n",
    "#     for i in range(len(headerLinesIndex)-1):\n",
    "#         if headerLinesIndex[i+1] - headerLinesIndex[i] == 1:\n",
    "#             headerLinesIndex[i] = -1\n",
    "#     headerLinesIndex = [i for i in headerLinesIndex if i != -1]\n",
    "\n",
    "#     for i in range(len(headerLinesIndex)):\n",
    "#         header_line = lines[headerLinesIndex[i]][1:-1]  # remove square brackets\n",
    "#         if header_line in songSegmentsDict:\n",
    "#             songSegmentsDict[header_line][0] += 1\n",
    "#         elif i == len(headerLinesIndex)-1:\n",
    "#             songSegmentsDict[header_line] = [1, \" \".join(lines[headerLinesIndex[i]+1:]), lines[headerLinesIndex[i]+1:]]\n",
    "#         else:\n",
    "#             songSegmentsDict[header_line] = [1, \" \".join(lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]), lines[headerLinesIndex[i]+1:headerLinesIndex[i+1]]]\n",
    "\n",
    "#     for header, lyrics in songSegmentsDict.items():\n",
    "#         if returnSongSegments:\n",
    "#             tokenSegmentsDict[header],subLyrics = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "#             songSegmentsDict[header]=subLyrics\n",
    "#         else:\n",
    "#             tokenSegmentsDict[header] = breakUpLargeLyricChunks(lyrics[1],lyrics[2],tokenizer,returnLyricsSegments=returnSongSegments,max_length=max_length, device=device)\n",
    "#         headerFreqsDict[header] = lyrics[0]\n",
    "\n",
    "#     if returnSongSegments:\n",
    "#         return tokenSegmentsDict,headerFreqsDict,songSegmentsDict\n",
    "#     else:\n",
    "#         return tokenSegmentsDict,headerFreqsDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def breakUpLargeLyricChunks(lyricsChunkString, lines,tokenizer, max_length=512, device=\"cuda\", returnLyricsSegments=False):\n",
    "#     #lines = lyricsChunkString.splitlines()  # split the lyrics into lines\n",
    "#     segments = []  # store the lyrics segments\n",
    "#     token_segments = []  # store the tokenized segments as tensors\n",
    "\n",
    "#     token_segment = tokenizer.encode(lyricsChunkString, return_tensors=\"pt\")#.to(device)\n",
    "\n",
    "#     if len(token_segment[0]) <= max_length:\n",
    "#         token_segment = token_segment.unsqueeze(0)\n",
    "#         token_segments.append(token_segment)\n",
    "#         segments.append(lyricsChunkString)\n",
    "#     else:\n",
    "#         # calculate the average number of lines per segment. Add +2 to ensure segments are not still too long\n",
    "#         avg_lines_per_segment = len(lines) // ((len(token_segment[0]) // max_length) + 2)\n",
    "\n",
    "#         # loop through the lines and group them into segments of roughly the same length\n",
    "#         for start_idx in range(0, len(lines), avg_lines_per_segment):\n",
    "#             end_idx = start_idx + avg_lines_per_segment\n",
    "\n",
    "#             smallLastChunk = end_idx >= len(lines)-2\n",
    "            \n",
    "#             if smallLastChunk:\n",
    "#                 segment = \" \".join(lines[start_idx:])\n",
    "#             else:\n",
    "#                 segment = \" \".join(lines[start_idx:end_idx])\n",
    "#             segments.append(segment)\n",
    "\n",
    "#             # tokenize the segment and convert to tensor\n",
    "#             token_segment = tokenizer.encode(segment, return_tensors=\"pt\")#.to(device)\n",
    "#             token_segment = token_segment.unsqueeze(0)\n",
    "#             token_segments.append(token_segment)\n",
    "#             #NOTE: ^^ If I use batch_encode_plus, I can get the tokenized segments as a list of tensors in one step\n",
    "#             #I would just have to do it after the loop. \n",
    "#             #Since it is a small list though, I don't think it will make a difference in this case\n",
    "\n",
    "#             if smallLastChunk:\n",
    "#                 #this is the last segment early, so break out of the loop\n",
    "#                 break\n",
    "\n",
    "#     if returnLyricsSegments:  \n",
    "#         return token_segments, segments\n",
    "#     else:\n",
    "#         return token_segments\n",
    "\n",
    "\n",
    "# def getSoftmax(model,tokenizer, tokens = None, sentence=None, n=3,printRawScores=False, printTopN=False,device='cuda'):\n",
    "#     if tokens is None:\n",
    "#         tokens = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "#     if device=='cuda':\n",
    "#         tokens = tokens.cuda()\n",
    "#     result = model(tokens)\n",
    "#     emotion = result.logits\n",
    "#     emotion = emotion.cpu().detach().numpy()\n",
    "#     emotion = emotion[0]\n",
    "#     softmax = tf.nn.softmax(emotion)\n",
    "#     #convert to numpy array\n",
    "#     softmax = softmax.numpy()\n",
    "#     if printRawScores:\n",
    "#         print(softmax)\n",
    "    \n",
    "#     if printTopN:\n",
    "#         emotion = emotion.argsort()[-n:][::-1]\n",
    "#         emotion = emotion.tolist()\n",
    "#         printTopEmotions(emotion,model, softmax)\n",
    "#     return softmax\n",
    "\n",
    "# def printTopEmotions(emotion, model, softmax):\n",
    "    \n",
    "#     #identify the label of top n emotions from emotion list\n",
    "#     #softmax is in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "#     id=0\n",
    "#     emotion_dict = model.config.id2label\n",
    "#     for i in emotion:\n",
    "#         print(emotion_dict[i])\n",
    "#         print(softmax[emotion[id]]*100,\"%\")\n",
    "#         id+=1\n",
    "#     return\n",
    "\n",
    "\n",
    "# def convertScoresToLabels(softmaxScoresPerHeader,headerFreqs, emotionsAsValenceArousal,emotion_dict,disregardNeutral = True, printValenceArousal=False,printTopChunkEmotions=False):\n",
    "#     #convert the softmax scores to a valence and arousal score\n",
    "#     #softmax scores are in the order of the values in emotion_dict so we can use emotion[id] to get the softmax value\n",
    "#     valence=0\n",
    "#     arousal=0\n",
    "#     softmaxScoresApplied=0\n",
    "#     #find the key in emotion_dict that corresponds to neutral\n",
    "#     neuturalKey = [key for key, value in emotion_dict.items() if value == 'neutral'][0]\n",
    "#     for key, softmaxScores in softmaxScoresPerHeader.items():\n",
    "#         #check if neutral is the highest softmax score\n",
    "#         if disregardNeutral and neuturalKey==softmaxScores.argmax():\n",
    "#             continue\n",
    "#         else:\n",
    "#             #multiply the softmax score by the valence and arousal values and add to the total valence and arousal\n",
    "#             #do this for the number in the headerFreqs dictionary\n",
    "#             for i in range(headerFreqs[key]):\n",
    "#                 id=0\n",
    "#                 softmaxScoresApplied+=1\n",
    "#                 for i in softmaxScores:\n",
    "#                     valence+=i*emotionsAsValenceArousal[emotion_dict[id]][0]\n",
    "#                     arousal+=i*emotionsAsValenceArousal[emotion_dict[id]][1]\n",
    "#                     id+=1\n",
    "#     #divide the total valence and arousal by the number of softmax scores applied\n",
    "#     if softmaxScoresApplied!=0:\n",
    "#         valence=valence/softmaxScoresApplied\n",
    "#         arousal=arousal/softmaxScoresApplied\n",
    "#         mood =determineMoodLabel(valence,arousal,printValenceArousal=printValenceArousal)\n",
    "#         return mood, valence, arousal\n",
    "#     else:\n",
    "#         return 'top ratings all neutral', valence, arousal\n",
    "#     #note this means all top chunk emotions were neutral as opposed to true neutral where all emotions balance out to neutral\n",
    "\n",
    "# def determineMoodLabel(valence,arousal,printValenceArousal=False):\n",
    "#     #determine the diagonal of the circumplex model that the valence and arousal scores fall on\n",
    "#     #MAKE 2 BOXES OF THE CIRCUMPLEX MODEL A MOOD \n",
    "\n",
    "#     energetic =   -0.5<valence<0.5 and arousal>0.5\n",
    "#     happy =       valence>0.5 and -.5<arousal<0.5\n",
    "#     calm =       -0.5<valence<0.5 and arousal<-0.5\n",
    "#     sad =         valence<-0.5 and -.5<arousal<0.5\n",
    "\n",
    "#     excited =   not (happy or energetic) and valence>0 and arousal>0\n",
    "#     content =   not (calm or happy) and valence>0 and arousal<0\n",
    "#     depressed = not (calm or sad) and valence<0 and arousal<0\n",
    "#     angry =   not (energetic or sad) and valence<0 and arousal>0\n",
    "\n",
    "\n",
    "#     if energetic:\n",
    "#         mood='energetic'\n",
    "#     elif happy:\n",
    "#         mood='happy'\n",
    "#     elif calm:\n",
    "#         mood='calm'\n",
    "#     elif sad:\n",
    "#         mood='sad'\n",
    "#     elif excited:\n",
    "#         mood='excited'\n",
    "#     elif content:\n",
    "#         mood='content'\n",
    "#     elif depressed:\n",
    "#         mood='depressed'\n",
    "#     elif angry:\n",
    "#         mood='angry'\n",
    "#     else:\n",
    "#         mood='neutral'\n",
    "    \n",
    "#     if printValenceArousal:\n",
    "#         print(\"Valence: \",valence)\n",
    "#         print(\"Arousal: \",arousal)\n",
    "#     return mood     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8703eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "#COMBINED MODEL OUTLINE -- \n",
    "# inputs:  sp_user( aka the client!!!), UID\n",
    "#^note: we could pass in the user's last login date, instead of UID if we waned to, \n",
    "# as this would provide beter separation of concerns of updating last login date vs the function \n",
    "# thats supposed to be getting the song moods\n",
    "\n",
    "#outputs: verifies success or failure of the function\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# def get_user_song_moods_advanced(sp_user,UID):\n",
    "\n",
    "#         #0. get the track ids of unlabelled songs from the list of new liked songs from the user\n",
    "#         last_login = DB.get_last_login(UID) #IF NONE, return ''\n",
    "\n",
    "#         #If last login is a string, we need to convert it to a utc datetime object\n",
    "#         #if isinstance(last_login, str):\n",
    "#         #        last_login = datetime.strptime(last_login, '%Y-%m-%d %H:%M:%S.%f')\n",
    "        \n",
    "#         track_ids = retrieveTrackIds(sp_user,last_login)\n",
    "\n",
    "#         remaining_track_ids = DB.check_if_already_labelled(track_ids)\n",
    "\n",
    "#         if len(remaining_track_ids) == 0:\n",
    "#                 DB.update_user_liked_songs(UID,track_ids)\n",
    "#                 DB.update_last_login(UID,datetime.utcnow())\n",
    "#                 return \"success\"\n",
    "\n",
    "#         #1. get the song features of unlabelled songs\n",
    "\n",
    "#         featuresDF = retrieveTrackFeatures(remaining_track_ids) #this should drop the ids of songs that dont have features\n",
    "#         featuresDict = clipAndNormalize(featuresDF)#.set_index('id').T.to_dict('list')\n",
    "\n",
    "#         #2. if possible, get the lyrics of the songs\n",
    "\n",
    "#         #make a dictionary of song titles and artist names\n",
    "#         scraperInputs = getTitlesAndArtists(sp_user, remaining_track_ids)\n",
    "\n",
    "\n",
    "#         #-------------------------------------------------\n",
    "#         #compute gets expensive here, so just do a for loop on remaining_track_ids\n",
    "#         #where u \n",
    "#         # 1. get lyrics, \n",
    "#         # 2. check if features are available as well \n",
    "#         # 3. make a prediction, based on 1 and 2 \n",
    "#         # 4. immediately update the database and last added_at date, in case of a time out\n",
    "#         #-------------------------------------------------\n",
    "#         all_lyrics_dict = getScrapedLyrics(scraperInputs)\n",
    "\n",
    "#         #MAYBE Tokenize THE LYRICS HERE (use batch processing?!) \n",
    "#         #would need to verify compute restrictions of cloud function first!\n",
    "\n",
    "#         overlap_keys = [key for key in featuresDict.keys() if key in all_lyrics_dict.keys()]\n",
    "#         only_features = [key for key in featuresDict.keys() if key not in overlap_keys]\n",
    "#         only_lyrics = [key for key in all_lyrics_dict.keys() if key not in overlap_keys]\n",
    "\n",
    "\n",
    "#         #3 get predictions and update database\n",
    "\n",
    "#         #3a. if there are no features or lyrics, return an error\n",
    "#         if len(featuresDict.keys()) == 0 and len(all_lyrics_dict.keys()) == 0:\n",
    "#                 #probably just return a flag that says there are no features or lyrics not the response here\n",
    "#                 return \"songs found but no data available for predictions\"\n",
    "        \n",
    "#         else:\n",
    "#                 predictions = {}\n",
    "#                 #for first version, tokenize the lyrics and then pass then to the model inside the for loop\n",
    "\n",
    "#                 for key in overlap_keys: #- could probably be done in batches regardless\n",
    "#                     RF_pred, RF_pred_probability = getMoodLabelRF(featuresDict[key])\n",
    "\n",
    "#                     #BERT_pred, BERT_pred_probability = getMoodLabelBERT(BERT_model,all_lyrics_dict[key])\n",
    "#                     BERT_pred, RF_flag = getOnlyMoodLabelFromLyrics(all_lyrics_dict[key])\n",
    "#                     if RF_pred == BERT_pred or RF_flag == True:\n",
    "#                         prediction = RF_pred\n",
    "#                     else:\n",
    "                        \n",
    "#                         model_pred_diffs = (RF_pred - BERT_pred)\n",
    "\n",
    "#                         if RF_pred > BERT_pred:\n",
    "#                             sum_probabilities = RF_pred + model_pred_diffs\n",
    "#                         else:\n",
    "#                             sum_probabilities = RF_pred - model_pred_diffs\n",
    "#                         #if sum_probabilities outside of below 0, then do 8-sum_probabilities\n",
    "#                         if sum_probabilities < 0:\n",
    "#                             prediction = 8 + sum_probabilities\n",
    "#                         elif sum_probabilities > 7:\n",
    "#                             prediction = sum_probabilities - 7\n",
    "#                         else:\n",
    "#                             prediction = sum_probabilities\n",
    "\n",
    "#                     predictions[key]=prediction\n",
    "\n",
    "#                 for key in only_features:\n",
    "#                         RF_pred, RF_pred_probability = getMoodLabelRF(featuresDict[key])\n",
    "#                         predictions[key]=RF_pred\n",
    "\n",
    "#                 DB.add_song_moods(predictions)\n",
    "                \n",
    "#                 DB.update_user_liked_songs(UID,predictions.keys()) \n",
    "#                 # ^^Need to add a check to discard songs no longer on spotify, \n",
    "#                 # otherwise we might recommend songs that are no longer on spotify\n",
    "\n",
    "#                 DB.update_last_login(UID,datetime.utcnow())\n",
    "\n",
    "#         return \"success\"\n",
    "\n",
    "#________________________________________________________________________________________________________________\n",
    "### Helper Functions of get_User_Song_Moods_2_models\n",
    "#________________________________________________________________________________________________________________\n",
    "\n",
    "# def retrieveTrackIds(user_prior_login_date):\n",
    "#     track_ids = []\n",
    "#     offset = 0\n",
    "#     limit = 50\n",
    "#     liked_tracks = sp.current_user_saved_tracks(limit=limit, offset=offset)\n",
    "#     endLoopEarly = False\n",
    "#     while True:\n",
    "#         for item in liked_tracks['items']:\n",
    "#             if user_prior_login_date != '':\n",
    "#                 if datetime.strptime(item['added_at'],'%Y-%m-%dT%H:%M:%SZ')> user_prior_login_date:\n",
    "#                     track_ids.append(item['track']['id'])\n",
    "#                 else:\n",
    "#                     endLoopEarly = True\n",
    "#                     break\n",
    "#             else:\n",
    "#                 track_ids.append(item['track']['id'])\n",
    "#         offset += limit\n",
    "        \n",
    "#         if len(liked_tracks['items']) < limit or endLoopEarly:\n",
    "#             # All tracks have been retrieved\n",
    "#             break\n",
    "        \n",
    "#         liked_tracks = sp.current_user_saved_tracks(limit=limit, offset=offset)\n",
    "    \n",
    "#     return track_ids\n",
    "\n",
    "\n",
    "# '''def getSongFeaturesToDict(track_ids):\n",
    "#         featuresDict = {}\n",
    "#         for i in range(0,len(track_ids),100):\n",
    "#                 features = sp.audio_features(track_ids[i:i+100])\n",
    "#                 for feature in features:\n",
    "#                         if feature != None:\n",
    "#                                 featuresDict[feature['id']]=feature\n",
    "#         return featuresDict'''\n",
    "\n",
    "\n",
    "# def getMoodLabelRF(songFeautures):\n",
    "#         with open('RF1.pkl','rb') as f:\n",
    "#             model = pickle.load(f)\n",
    "#         prediction = model.predict(songFeautures)\n",
    "#         pred_probability=model.predict_proba(songFeautures)\n",
    "#         return prediction, pred_probability\n",
    "\n",
    "#________________________________________________________________________________________________________________\n",
    "#                  MAIN\n",
    "#________________________________________________________________________________________________________________\n",
    "\n",
    "def generate_song_classification_advanced(request):\n",
    "        spotify_access_token = request.args['spotify_token']\n",
    "        userID = request.args['uid']\n",
    "        client = loadSpotipyClient(spotify_access_token)\n",
    "\n",
    "        feedback = get_user_song_moods_advanced(client, userID)\n",
    "\n",
    "\n",
    "        #CORS-Policy Headers\n",
    "        headers = {\n",
    "        'Access-Control-Allow-Origin': '*',\n",
    "        'Access-Control-Allow-Methods': 'GET',\n",
    "        'Access-Control-Allow-Headers': 'Content-Type',\n",
    "        'Access-Control-Max-Age': '3600'\n",
    "        }\n",
    "        # Jsonify predictions\n",
    "        if feedback == \"success\":\n",
    "                return (jsonify({}), 200, headers)\n",
    "        else:\n",
    "                return (jsonify({\"warning\":feedback}), 200, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0b17881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user_id = \"\"\n",
    "# mood = moods[2]\n",
    "# num_songs = 100\n",
    "# # closest_song_ids = ['4uLU6hMCjMI75M1A2tKUQC', '2takcwOaAZWiXQijPHIx7B', '0JrXhKXDZpcOzYUvV2fYhZ']\n",
    "# closest_song_ids = [\"4jLv3tDBu8ww2R07DvL12s\", \"0MMMZ2N7aH0QXLMItwBQVe\", \"1L7pxD7WYdm3cKvAp5UT3n\", \"1iV8d9WtdtUJGsV3fmWB1U\", \"7uQftgqxvkdl9GLE1Q3OOQ\"] #Classified as depressed\n",
    "# final_song_ids = generateNewSongsList(mood, num_songs, closest_song_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc36f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of specified moods: 3\n",
      "count of other moods: 8\n",
      "count of similar moods: 5\n",
      "count of labels: {0: 1, 1: 1, 2: 3, 3: 4, 4: 2, 5: 0, 6: 5, 7: 0}\n",
      "probability of labels: {0: 0.0625, 1: 0.0625, 2: 0.1875, 3: 0.25, 4: 0.125, 5: 0.0, 6: 0.3125, 7: 0.0}\n"
     ]
    }
   ],
   "source": [
    "mood = moods[2]\n",
    "num_total_songs = 10\n",
    "# closest_song_ids = ['4uLU6hMCjMI75M1A2tKUQC', '2takcwOaAZWiXQijPHIx7B', '0JrXhKXDZpcOzYUvV2fYhZ']\n",
    "closest_song_ids = [\"4jLv3tDBu8ww2R07DvL12s\", \"0MMMZ2N7aH0QXLMItwBQVe\", \"1L7pxD7WYdm3cKvAp5UT3n\", \"1iV8d9WtdtUJGsV3fmWB1U\", \"7uQftgqxvkdl9GLE1Q3OOQ\"] #Classified as depressed\n",
    "percentage_new_songs = 0.8\n",
    "final_song_ids = buildPlaylist(mood, percentage_new_songs, num_total_songs, closest_song_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "014c4deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3beYmUcaXJZiSZMPbsMI7p',\n",
       " '0Ku4H5iDJZnsClOF16le4g',\n",
       " '4OqBolVLgArilln6zni9gH',\n",
       " '4jLv3tDBu8ww2R07DvL12s',\n",
       " '6RM7EnZNWsEhdikBnNFeDf',\n",
       " '1e7HeWfhUPAaQ4Dw9UuGG4',\n",
       " '63WY1u5pDf6Nk5Z7xqmn9f',\n",
       " '0lIoY4ZQsdn5QzhraM9o9u',\n",
       " '5rtLYy3wI7BrqRBWP0ulhZ',\n",
       " '1iV8d9WtdtUJGsV3fmWB1U']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(final_song_ids))\n",
    "final_song_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc74c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
