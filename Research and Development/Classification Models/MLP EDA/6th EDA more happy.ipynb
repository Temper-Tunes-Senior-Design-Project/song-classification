{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from os import chdir\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAndNormalize(features):\n",
    "    #clip the features to the range of the training data\n",
    "    #clip outliers to 1st and 99th percentile\n",
    "    features['danceability'] = features['danceability'].clip(lower=features['danceability'].quantile(0.01), upper=features['danceability'].quantile(0.99))\n",
    "    features['energy'] = features['energy'].clip(lower=features['energy'].quantile(0.01), upper=features['energy'].quantile(0.99))\n",
    "    features['loudness'] = features['loudness'].clip(lower=features['loudness'].quantile(0.01), upper=features['loudness'].quantile(0.99))\n",
    "    features['speechiness'] = features['speechiness'].clip(lower=features['speechiness'].quantile(0.01), upper=features['speechiness'].quantile(0.99))\n",
    "    features['acousticness'] = features['acousticness'].clip(lower=features['acousticness'].quantile(0.01), upper=features['acousticness'].quantile(0.99))\n",
    "    features['instrumentalness'] = features['instrumentalness'].clip(lower=features['instrumentalness'].quantile(0.01), upper=features['instrumentalness'].quantile(0.99))\n",
    "    features['liveness'] = features['liveness'].clip(lower=features['liveness'].quantile(0.01), upper=features['liveness'].quantile(0.99))\n",
    "    features['valence'] = features['valence'].clip(lower=features['valence'].quantile(0.01), upper=features['valence'].quantile(0.99))\n",
    "    features['tempo'] = features['tempo'].clip(lower=features['tempo'].quantile(0.01), upper=features['tempo'].quantile(0.99))\n",
    "    features['duration_ms'] = features['duration_ms'].clip(lower=features['duration_ms'].quantile(0.01), upper=features['duration_ms'].quantile(0.99))\n",
    "    features['time_signature'] = features['time_signature'].clip(lower=features['time_signature'].quantile(0.01), upper=features['time_signature'].quantile(0.99))\n",
    "\n",
    "    columns_to_log=['liveness', 'instrumentalness', 'acousticness', 'speechiness','loudness','energy']\n",
    "\n",
    "    for i in columns_to_log:\n",
    "        if i == 'loudness':\n",
    "            features[i] = features[i] + 60\n",
    "        features[i] = np.log(features[i]+1)\n",
    "\n",
    "    \n",
    "    #normalize the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #if id is a column, drop it\n",
    "    if 'id' in features.columns:\n",
    "        #fit on all columns except the track id\n",
    "        rawfeatures = features.drop(['id'], axis=1)\n",
    "    else:\n",
    "        rawfeatures = features\n",
    "    preprocessedFeatures = scaler.fit_transform(rawfeatures)\n",
    "\n",
    "    preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    #apply z-score normalization\n",
    "    for i in columns_to_log:\n",
    "        preprocessedFeaturesDF[i] = stats.zscore(preprocessedFeaturesDF[i])\n",
    "        preprocessedFeaturesDF.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    '''#convert to dictionary, with track id as key\n",
    "    preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "    preprocessedFeatures['id']= features['id']\n",
    "    preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')'''\n",
    "    return preprocessedFeaturesDF, preprocessedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCategorical(df):\n",
    "    mood_order=['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "    mood_codes, mood_categories = pd.factorize(mood_order)\n",
    "    \n",
    "    # Create a categorical object with the desired order\n",
    "    cat = pd.Categorical(df['mood'], categories=mood_order, ordered=True)\n",
    "\n",
    "    # Get the integer codes of the categories\n",
    "    codes = cat.codes\n",
    "\n",
    "    # Add the codes as a new column to the dataframe\n",
    "    df['mood_code'] = codes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offByOne(y_test_standard, y_pred,digits=3):\n",
    "    #compare y_test_standard with y_pred_list. If y_pred_list is +-1 from y_test_standard, then it change it to be the same as y_test_standard\n",
    "    y_test_standard_list=list(y_test_standard)\n",
    "    y_pred_list = list(y_pred)\n",
    "    for id in range(len(y_test_standard_list)):\n",
    "        if y_test_standard_list[id] != 0 and y_test_standard_list[id] != 7:\n",
    "            if y_pred_list[id] == y_test_standard_list[id] - 1 or y_pred_list[id] == y_test_standard_list[id] + 1:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 0:\n",
    "            if y_pred_list[id] ==  1 or y_pred_list[id] == 7:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 7:\n",
    "            if y_pred_list[id] ==  0 or y_pred_list[id] == 6:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "    print(classification_report(y_test_standard_list, y_pred_list,digits = digits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('C:/Users/mlar5/OneDrive/Desktop/Code Folder/Python Projects/IRL projects/Aspire - Affective Computing Project/Playlists Data/Audio Features/emotion joint data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = pd.read_csv('Merged Emotions Data5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = makeCategorical(emotionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3779\n",
       "6    1218\n",
       "0    1020\n",
       "5     770\n",
       "1     694\n",
       "2     630\n",
       "3     628\n",
       "4     618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionsDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    618\n",
       "6    618\n",
       "5    618\n",
       "7    618\n",
       "2    618\n",
       "3    618\n",
       "4    618\n",
       "0    618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df with only up to 500 songs per mood_code\n",
    "# this is to balance the data\n",
    "\n",
    "balancedDF = pd.DataFrame(columns=emotionsDF.columns)\n",
    "\n",
    "largest_balanced_sample = emotionsDF['mood_code'].value_counts().min()\n",
    "\n",
    "for i in emotionsDF['mood_code'].unique():\n",
    "    df = emotionsDF[emotionsDF['mood_code']==i]\n",
    "    #if the value count of the mood_code is larger than 500, sample 500\n",
    "    if df['mood_code'].value_counts()[i] >= largest_balanced_sample:\n",
    "        df = df.sample(n=largest_balanced_sample, random_state=42)\n",
    "    #if the value count of the mood_code is less than 500, sample the value count\n",
    "    else:\n",
    "        df = df.sample(n=df['mood_code'].value_counts()[i])\n",
    "    balancedDF = pd.concat([balancedDF, df])\n",
    "\n",
    "balancedDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song</th>\n",
       "      <th>mood</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.304</td>\n",
       "      <td>149.996</td>\n",
       "      <td>spotify:track:2XSrt1dcuOXPgl3B4bxmBz</td>\n",
       "      <td>203897</td>\n",
       "      <td>4</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.698</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.480</td>\n",
       "      <td>124.973</td>\n",
       "      <td>spotify:track:1SSv8SA2OHfOUwLgb8yOum</td>\n",
       "      <td>180062</td>\n",
       "      <td>4</td>\n",
       "      <td>Cheat Cxdes</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.125</td>\n",
       "      <td>130.058</td>\n",
       "      <td>spotify:track:0A8Mrg7ButLr17K3A0R61D</td>\n",
       "      <td>133308</td>\n",
       "      <td>4</td>\n",
       "      <td>TOTALITARIANISM</td>\n",
       "      <td>angry</td>\n",
       "      <td>EDM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.396</td>\n",
       "      <td>95.971</td>\n",
       "      <td>spotify:track:583TaS41X2JJGKoGXnTY3l</td>\n",
       "      <td>107159</td>\n",
       "      <td>4</td>\n",
       "      <td>KILLTHEPHARAOH</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.836</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.397</td>\n",
       "      <td>175.060</td>\n",
       "      <td>spotify:track:7CMy59461Q3pgsPZ4Cj8CP</td>\n",
       "      <td>89143</td>\n",
       "      <td>4</td>\n",
       "      <td>EASE</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy key  loudness mode  speechiness  acousticness  \\\n",
       "381         0.848   0.520   5   -10.663    0       0.5010      0.002250   \n",
       "666         0.713   0.698  10    -7.435    0       0.1680      0.180000   \n",
       "257         0.757   0.423   1    -2.311    1       0.0527      0.000004   \n",
       "338         0.516   0.515   1   -13.005    1       0.2790      0.033600   \n",
       "319         0.618   0.836   6    -4.750    0       0.0813      0.002400   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  \\\n",
       "381          0.000799     0.679    0.304  149.996   \n",
       "666          0.000001     0.304    0.480  124.973   \n",
       "257          0.897000     0.118    0.125  130.058   \n",
       "338          0.000002     0.119    0.396   95.971   \n",
       "319          0.000000     0.363    0.397  175.060   \n",
       "\n",
       "                                      uri duration_ms time_signature  \\\n",
       "381  spotify:track:2XSrt1dcuOXPgl3B4bxmBz      203897              4   \n",
       "666  spotify:track:1SSv8SA2OHfOUwLgb8yOum      180062              4   \n",
       "257  spotify:track:0A8Mrg7ButLr17K3A0R61D      133308              4   \n",
       "338  spotify:track:583TaS41X2JJGKoGXnTY3l      107159              4   \n",
       "319  spotify:track:7CMy59461Q3pgsPZ4Cj8CP       89143              4   \n",
       "\n",
       "                song   mood genre mood_code  \n",
       "381       Carrollton  angry   rap         1  \n",
       "666      Cheat Cxdes  angry   rap         1  \n",
       "257  TOTALITARIANISM  angry   EDM         1  \n",
       "338   KILLTHEPHARAOH  angry   rap         1  \n",
       "319             EASE  angry   rap         1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeatures = balancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeaturesDF, rawfeatures = clipAndNormalize(rawfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482419</td>\n",
       "      <td>-0.322342</td>\n",
       "      <td>-0.065799</td>\n",
       "      <td>-0.665392</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.958541</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.552893</td>\n",
       "      <td>0.940143</td>\n",
       "      <td>0.272427</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545890</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>1.318501</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>-0.245604</td>\n",
       "      <td>-0.492971</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>0.071470</td>\n",
       "      <td>-0.199505</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851129</td>\n",
       "      <td>-0.735754</td>\n",
       "      <td>-1.173239</td>\n",
       "      <td>1.136073</td>\n",
       "      <td>0.779283</td>\n",
       "      <td>-0.530916</td>\n",
       "      <td>-0.967633</td>\n",
       "      <td>2.350764</td>\n",
       "      <td>-0.477927</td>\n",
       "      <td>-1.311172</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>-1.125231</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.820748</td>\n",
       "      <td>-0.342998</td>\n",
       "      <td>-1.173239</td>\n",
       "      <td>-1.224490</td>\n",
       "      <td>0.779283</td>\n",
       "      <td>1.695751</td>\n",
       "      <td>-0.824045</td>\n",
       "      <td>-0.492970</td>\n",
       "      <td>-0.469337</td>\n",
       "      <td>-0.163163</td>\n",
       "      <td>-0.935335</td>\n",
       "      <td>-1.642980</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.113148</td>\n",
       "      <td>0.861786</td>\n",
       "      <td>0.211061</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.957888</td>\n",
       "      <td>-0.492977</td>\n",
       "      <td>1.425940</td>\n",
       "      <td>-0.158927</td>\n",
       "      <td>1.810239</td>\n",
       "      <td>-1.999696</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy       key  loudness      mode  speechiness  \\\n",
       "0      1.482419 -0.322342 -0.065799 -0.665392 -1.283231     2.700000   \n",
       "1      0.545890  0.371919  1.318501  0.064003 -1.283231     0.657598   \n",
       "2      0.851129 -0.735754 -1.173239  1.136073  0.779283    -0.530916   \n",
       "3     -0.820748 -0.342998 -1.173239 -1.224490  0.779283     1.695751   \n",
       "4     -0.113148  0.861786  0.211061  0.637965 -1.283231    -0.224387   \n",
       "\n",
       "   acousticness  instrumentalness  liveness   valence     tempo  duration_ms  \\\n",
       "0     -0.958541         -0.489430  2.700000 -0.552893  0.940143     0.272427   \n",
       "1     -0.245604         -0.492971  1.000754  0.192677  0.071470    -0.199505   \n",
       "2     -0.967633          2.350764 -0.477927 -1.311172  0.247995    -1.125231   \n",
       "3     -0.824045         -0.492970 -0.469337 -0.163163 -0.935335    -1.642980   \n",
       "4     -0.957888         -0.492977  1.425940 -0.158927  1.810239    -1.999696   \n",
       "\n",
       "   time_signature  \n",
       "0        0.173859  \n",
       "1        0.173859  \n",
       "2        0.173859  \n",
       "3        0.173859  \n",
       "4        0.173859  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balancedDF['mood_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it to categorical\n",
    "y = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new dataframe of all the rows in emotionsDF that are not in balancedDF\n",
    "unbalancedDF = emotionsDF[~emotionsDF.index.isin(balancedDF.index)]\n",
    "extra_test_features = unbalancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)\n",
    "extra_test_features_DF, extra_test_features = clipAndNormalize(extra_test_features)\n",
    "extra_test_y = unbalancedDF['mood_code'].astype('category')\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#combine the extra test features to the test set numpy arrays\n",
    "X_test_standard = np.concatenate((X_test_standard, extra_test_features), axis=0)\n",
    "y_test_standard = np.concatenate((y_test_standard, extra_test_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5402"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128),random_state=42,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.30      0.24       525\n",
      "           1       0.24      0.55      0.33       199\n",
      "           2       0.09      0.66      0.16       136\n",
      "           3       0.07      0.46      0.12       134\n",
      "           4       0.11      0.38      0.17       124\n",
      "           5       0.14      0.24      0.18       275\n",
      "           6       0.38      0.61      0.47       724\n",
      "           7       0.77      0.07      0.13      3285\n",
      "\n",
      "    accuracy                           0.22      5402\n",
      "   macro avg       0.25      0.41      0.23      5402\n",
      "weighted avg       0.56      0.22      0.20      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the resampled data\n",
    "mlp.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance of micro-averaged F1 score\n",
    "\n",
    "print(classification_report(y_test_standard, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.559     0.370     0.445       525\n",
      "           1      0.343     0.839     0.487       199\n",
      "           2      0.124     0.838     0.215       136\n",
      "           3      0.113     0.739     0.196       134\n",
      "           4      0.195     0.621     0.297       124\n",
      "           5      0.307     0.473     0.372       275\n",
      "           6      0.924     0.771     0.840       724\n",
      "           7      0.979     0.402     0.570      3285\n",
      "\n",
      "    accuracy                          0.492      5402\n",
      "   macro avg      0.443     0.632     0.428      5402\n",
      "weighted avg      0.812     0.492     0.556      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm =SVC(kernel='poly', degree=3,class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.38      0.27       525\n",
      "           1       0.27      0.52      0.36       199\n",
      "           2       0.10      0.62      0.18       136\n",
      "           3       0.08      0.34      0.12       134\n",
      "           4       0.07      0.57      0.13       124\n",
      "           5       0.10      0.19      0.13       275\n",
      "           6       0.44      0.34      0.38       724\n",
      "           7       0.74      0.12      0.21      3285\n",
      "\n",
      "    accuracy                           0.22      5402\n",
      "   macro avg       0.25      0.38      0.22      5402\n",
      "weighted avg       0.55      0.22      0.23      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_SVM = svm.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.536     0.450     0.489       525\n",
      "           1      0.379     0.779     0.510       199\n",
      "           2      0.130     0.750     0.221       136\n",
      "           3      0.156     0.746     0.258       134\n",
      "           4      0.092     0.661     0.161       124\n",
      "           5      0.325     0.502     0.394       275\n",
      "           6      0.965     0.677     0.795       724\n",
      "           7      0.970     0.384     0.550      3285\n",
      "\n",
      "    accuracy                          0.475      5402\n",
      "   macro avg      0.444     0.619     0.422      5402\n",
      "weighted avg      0.811     0.475     0.543      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.25      0.22       525\n",
      "           1       0.20      0.50      0.28       199\n",
      "           2       0.09      0.49      0.15       136\n",
      "           3       0.05      0.24      0.08       134\n",
      "           4       0.05      0.25      0.09       124\n",
      "           5       0.09      0.22      0.13       275\n",
      "           6       0.34      0.38      0.36       724\n",
      "           7       0.68      0.15      0.25      3285\n",
      "\n",
      "    accuracy                           0.22      5402\n",
      "   macro avg       0.21      0.31      0.19      5402\n",
      "weighted avg       0.50      0.22      0.25      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.586     0.421     0.490       525\n",
      "           1      0.287     0.739     0.413       199\n",
      "           2      0.136     0.721     0.229       136\n",
      "           3      0.106     0.537     0.177       134\n",
      "           4      0.110     0.500     0.180       124\n",
      "           5      0.215     0.480     0.297       275\n",
      "           6      0.896     0.692     0.781       724\n",
      "           7      0.949     0.398     0.561      3285\n",
      "\n",
      "    accuracy                          0.470      5402\n",
      "   macro avg      0.411     0.561     0.391      5402\n",
      "weighted avg      0.784     0.470     0.538      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_DT = dt.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_DT))\n",
    "\n",
    "offByOne(y_test_standard, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.215     0.371     0.273       525\n",
      "           1      0.226     0.648     0.335       199\n",
      "           2      0.121     0.662     0.205       136\n",
      "           3      0.071     0.433     0.122       134\n",
      "           4      0.122     0.508     0.197       124\n",
      "           5      0.164     0.211     0.185       275\n",
      "           6      0.375     0.577     0.455       724\n",
      "           7      0.704     0.082     0.147      3285\n",
      "\n",
      "    accuracy                          0.237      5402\n",
      "   macro avg      0.250     0.437     0.240      5402\n",
      "weighted avg      0.524     0.237     0.211      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.579     0.482     0.526       525\n",
      "           1      0.298     0.854     0.442       199\n",
      "           2      0.156     0.831     0.263       136\n",
      "           3      0.115     0.716     0.198       134\n",
      "           4      0.176     0.661     0.277       124\n",
      "           5      0.379     0.465     0.418       275\n",
      "           6      0.954     0.742     0.834       724\n",
      "           7      0.973     0.435     0.601      3285\n",
      "\n",
      "    accuracy                          0.520      5402\n",
      "   macro avg      0.454     0.648     0.445      5402\n",
      "weighted avg      0.817     0.520     0.584      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_RF = rf.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_RF,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.37      0.27       525\n",
      "           1       0.23      0.63      0.34       199\n",
      "           2       0.11      0.66      0.19       136\n",
      "           3       0.07      0.44      0.12       134\n",
      "           4       0.12      0.49      0.19       124\n",
      "           5       0.17      0.22      0.20       275\n",
      "           6       0.38      0.59      0.46       724\n",
      "           7       0.74      0.07      0.14      3285\n",
      "\n",
      "    accuracy                           0.23      5402\n",
      "   macro avg       0.26      0.43      0.24      5402\n",
      "weighted avg       0.55      0.23      0.21      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.553     0.459     0.502       525\n",
      "           1      0.313     0.844     0.457       199\n",
      "           2      0.147     0.838     0.251       136\n",
      "           3      0.115     0.731     0.198       134\n",
      "           4      0.180     0.661     0.283       124\n",
      "           5      0.377     0.469     0.418       275\n",
      "           6      0.951     0.731     0.827       724\n",
      "           7      0.982     0.433     0.601      3285\n",
      "\n",
      "    accuracy                          0.515      5402\n",
      "   macro avg      0.452     0.646     0.442      5402\n",
      "weighted avg      0.820     0.515     0.581      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_estimator = RandomForestClassifier(n_estimators=100,  random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_bagging))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_bagging))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
