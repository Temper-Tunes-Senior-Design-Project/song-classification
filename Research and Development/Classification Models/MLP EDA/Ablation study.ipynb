{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from os import chdir\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove worst feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAndNormalize(features):\n",
    "    #clip the features to the range of the training data\n",
    "    features.drop(['key'], axis=1, inplace=True)\n",
    "    #clip outliers to 1st and 99th percentile\n",
    "    features['danceability'] = features['danceability'].clip(lower=features['danceability'].quantile(0.01), upper=features['danceability'].quantile(0.99))\n",
    "    features['energy'] = features['energy'].clip(lower=features['energy'].quantile(0.01), upper=features['energy'].quantile(0.99))\n",
    "    features['loudness'] = features['loudness'].clip(lower=features['loudness'].quantile(0.01), upper=features['loudness'].quantile(0.99))\n",
    "    features['speechiness'] = features['speechiness'].clip(lower=features['speechiness'].quantile(0.01), upper=features['speechiness'].quantile(0.99))\n",
    "    features['acousticness'] = features['acousticness'].clip(lower=features['acousticness'].quantile(0.01), upper=features['acousticness'].quantile(0.99))\n",
    "    features['instrumentalness'] = features['instrumentalness'].clip(lower=features['instrumentalness'].quantile(0.01), upper=features['instrumentalness'].quantile(0.99))\n",
    "    features['liveness'] = features['liveness'].clip(lower=features['liveness'].quantile(0.01), upper=features['liveness'].quantile(0.99))\n",
    "    features['valence'] = features['valence'].clip(lower=features['valence'].quantile(0.01), upper=features['valence'].quantile(0.99))\n",
    "    features['tempo'] = features['tempo'].clip(lower=features['tempo'].quantile(0.01), upper=features['tempo'].quantile(0.99))\n",
    "    features['duration_ms'] = features['duration_ms'].clip(lower=features['duration_ms'].quantile(0.01), upper=features['duration_ms'].quantile(0.99))\n",
    "    features['time_signature'] = features['time_signature'].clip(lower=features['time_signature'].quantile(0.01), upper=features['time_signature'].quantile(0.99))\n",
    "\n",
    "    columns_to_log=['liveness', 'instrumentalness', 'acousticness', 'speechiness','loudness','energy']\n",
    "\n",
    "    for i in columns_to_log:\n",
    "        if i == 'loudness':\n",
    "            features[i] = features[i] + 60\n",
    "        features[i] = np.log(features[i]+1)\n",
    "\n",
    "    \n",
    "    #normalize the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #if id is a column, drop it\n",
    "    if 'id' in features.columns:\n",
    "        #fit on all columns except the track id\n",
    "        rawfeatures = features.drop(['id'], axis=1)\n",
    "    else:\n",
    "        rawfeatures = features\n",
    "    preprocessedFeatures = scaler.fit_transform(rawfeatures)\n",
    "\n",
    "    preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    #apply z-score normalization\n",
    "    for i in columns_to_log:\n",
    "        preprocessedFeaturesDF[i] = stats.zscore(preprocessedFeaturesDF[i])\n",
    "        preprocessedFeaturesDF.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    '''#convert to dictionary, with track id as key\n",
    "    preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "    preprocessedFeatures['id']= features['id']\n",
    "    preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')'''\n",
    "    return preprocessedFeaturesDF, preprocessedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCategorical(df):\n",
    "    mood_order=['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "    mood_codes, mood_categories = pd.factorize(mood_order)\n",
    "    \n",
    "    # Create a categorical object with the desired order\n",
    "    cat = pd.Categorical(df['mood'], categories=mood_order, ordered=True)\n",
    "\n",
    "    # Get the integer codes of the categories\n",
    "    codes = cat.codes\n",
    "\n",
    "    # Add the codes as a new column to the dataframe\n",
    "    df['mood_code'] = codes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('C:/Users/mlar5/OneDrive/Desktop/Code Folder/Python Projects/IRL projects/Aspire - Affective Computing Project/Playlists Data/Audio Features/emotion joint data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = pd.read_csv('Merged Emotions Data5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = makeCategorical(emotionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3779\n",
       "6    1218\n",
       "0    1020\n",
       "5     770\n",
       "1     694\n",
       "2     630\n",
       "3     628\n",
       "4     618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionsDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    618\n",
       "6    618\n",
       "5    618\n",
       "7    618\n",
       "2    618\n",
       "3    618\n",
       "4    618\n",
       "0    618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df with only up to 500 songs per mood_code\n",
    "# this is to balance the data\n",
    "\n",
    "balancedDF = pd.DataFrame(columns=emotionsDF.columns)\n",
    "\n",
    "largest_balanced_sample = emotionsDF['mood_code'].value_counts().min()\n",
    "\n",
    "for i in emotionsDF['mood_code'].unique():\n",
    "    df = emotionsDF[emotionsDF['mood_code']==i]\n",
    "    #if the value count of the mood_code is larger than 500, sample 500\n",
    "    if df['mood_code'].value_counts()[i] >= largest_balanced_sample:\n",
    "        df = df.sample(n=largest_balanced_sample, random_state=42)\n",
    "    #if the value count of the mood_code is less than 500, sample the value count\n",
    "    else:\n",
    "        df = df.sample(n=df['mood_code'].value_counts()[i])\n",
    "    balancedDF = pd.concat([balancedDF, df])\n",
    "\n",
    "balancedDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song</th>\n",
       "      <th>mood</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.304</td>\n",
       "      <td>149.996</td>\n",
       "      <td>spotify:track:2XSrt1dcuOXPgl3B4bxmBz</td>\n",
       "      <td>203897</td>\n",
       "      <td>4</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.698</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.480</td>\n",
       "      <td>124.973</td>\n",
       "      <td>spotify:track:1SSv8SA2OHfOUwLgb8yOum</td>\n",
       "      <td>180062</td>\n",
       "      <td>4</td>\n",
       "      <td>Cheat Cxdes</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.125</td>\n",
       "      <td>130.058</td>\n",
       "      <td>spotify:track:0A8Mrg7ButLr17K3A0R61D</td>\n",
       "      <td>133308</td>\n",
       "      <td>4</td>\n",
       "      <td>TOTALITARIANISM</td>\n",
       "      <td>angry</td>\n",
       "      <td>EDM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.396</td>\n",
       "      <td>95.971</td>\n",
       "      <td>spotify:track:583TaS41X2JJGKoGXnTY3l</td>\n",
       "      <td>107159</td>\n",
       "      <td>4</td>\n",
       "      <td>KILLTHEPHARAOH</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.836</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.397</td>\n",
       "      <td>175.060</td>\n",
       "      <td>spotify:track:7CMy59461Q3pgsPZ4Cj8CP</td>\n",
       "      <td>89143</td>\n",
       "      <td>4</td>\n",
       "      <td>EASE</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy key  loudness mode  speechiness  acousticness  \\\n",
       "381         0.848   0.520   5   -10.663    0       0.5010      0.002250   \n",
       "666         0.713   0.698  10    -7.435    0       0.1680      0.180000   \n",
       "257         0.757   0.423   1    -2.311    1       0.0527      0.000004   \n",
       "338         0.516   0.515   1   -13.005    1       0.2790      0.033600   \n",
       "319         0.618   0.836   6    -4.750    0       0.0813      0.002400   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  \\\n",
       "381          0.000799     0.679    0.304  149.996   \n",
       "666          0.000001     0.304    0.480  124.973   \n",
       "257          0.897000     0.118    0.125  130.058   \n",
       "338          0.000002     0.119    0.396   95.971   \n",
       "319          0.000000     0.363    0.397  175.060   \n",
       "\n",
       "                                      uri duration_ms time_signature  \\\n",
       "381  spotify:track:2XSrt1dcuOXPgl3B4bxmBz      203897              4   \n",
       "666  spotify:track:1SSv8SA2OHfOUwLgb8yOum      180062              4   \n",
       "257  spotify:track:0A8Mrg7ButLr17K3A0R61D      133308              4   \n",
       "338  spotify:track:583TaS41X2JJGKoGXnTY3l      107159              4   \n",
       "319  spotify:track:7CMy59461Q3pgsPZ4Cj8CP       89143              4   \n",
       "\n",
       "                song   mood genre mood_code  \n",
       "381       Carrollton  angry   rap         1  \n",
       "666      Cheat Cxdes  angry   rap         1  \n",
       "257  TOTALITARIANISM  angry   EDM         1  \n",
       "338   KILLTHEPHARAOH  angry   rap         1  \n",
       "319             EASE  angry   rap         1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeatures = balancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeaturesDF, rawfeatures = clipAndNormalize(rawfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482419</td>\n",
       "      <td>-0.322342</td>\n",
       "      <td>-0.665392</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.958541</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.552893</td>\n",
       "      <td>0.940143</td>\n",
       "      <td>0.272427</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545890</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>-0.245604</td>\n",
       "      <td>-0.492971</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>0.071470</td>\n",
       "      <td>-0.199505</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851129</td>\n",
       "      <td>-0.735754</td>\n",
       "      <td>1.136073</td>\n",
       "      <td>0.779283</td>\n",
       "      <td>-0.530916</td>\n",
       "      <td>-0.967633</td>\n",
       "      <td>2.350764</td>\n",
       "      <td>-0.477927</td>\n",
       "      <td>-1.311172</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>-1.125231</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.820748</td>\n",
       "      <td>-0.342998</td>\n",
       "      <td>-1.224490</td>\n",
       "      <td>0.779283</td>\n",
       "      <td>1.695751</td>\n",
       "      <td>-0.824045</td>\n",
       "      <td>-0.492970</td>\n",
       "      <td>-0.469337</td>\n",
       "      <td>-0.163163</td>\n",
       "      <td>-0.935335</td>\n",
       "      <td>-1.642980</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.113148</td>\n",
       "      <td>0.861786</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.957888</td>\n",
       "      <td>-0.492977</td>\n",
       "      <td>1.425940</td>\n",
       "      <td>-0.158927</td>\n",
       "      <td>1.810239</td>\n",
       "      <td>-1.999696</td>\n",
       "      <td>0.173859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy  loudness      mode  speechiness  acousticness  \\\n",
       "0      1.482419 -0.322342 -0.665392 -1.283231     2.700000     -0.958541   \n",
       "1      0.545890  0.371919  0.064003 -1.283231     0.657598     -0.245604   \n",
       "2      0.851129 -0.735754  1.136073  0.779283    -0.530916     -0.967633   \n",
       "3     -0.820748 -0.342998 -1.224490  0.779283     1.695751     -0.824045   \n",
       "4     -0.113148  0.861786  0.637965 -1.283231    -0.224387     -0.957888   \n",
       "\n",
       "   instrumentalness  liveness   valence     tempo  duration_ms  time_signature  \n",
       "0         -0.489430  2.700000 -0.552893  0.940143     0.272427        0.173859  \n",
       "1         -0.492971  1.000754  0.192677  0.071470    -0.199505        0.173859  \n",
       "2          2.350764 -0.477927 -1.311172  0.247995    -1.125231        0.173859  \n",
       "3         -0.492970 -0.469337 -0.163163 -0.935335    -1.642980        0.173859  \n",
       "4         -0.492977  1.425940 -0.158927  1.810239    -1.999696        0.173859  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balancedDF['mood_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it to categorical\n",
    "y = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#make a new dataframe of all the rows in emotionsDF that are not in balancedDF\n",
    "unbalancedDF = emotionsDF[~emotionsDF.index.isin(balancedDF.index)]\n",
    "extra_test_features = unbalancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)\n",
    "extra_test_features_DF, extra_test_features = clipAndNormalize(extra_test_features)\n",
    "extra_test_y = unbalancedDF['mood_code'].astype('category')\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#combine the extra test features to the test set numpy arrays\n",
    "X_test_standard = np.concatenate((X_test_standard, extra_test_features), axis=0)\n",
    "y_test_standard = np.concatenate((y_test_standard, extra_test_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128),random_state=42,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.188     0.310     0.234       525\n",
      "           1      0.292     0.528     0.376       199\n",
      "           2      0.110     0.618     0.187       136\n",
      "           3      0.071     0.507     0.125       134\n",
      "           4      0.103     0.524     0.172       124\n",
      "           5      0.136     0.189     0.158       275\n",
      "           6      0.412     0.535     0.465       724\n",
      "           7      0.747     0.114     0.198      3285\n",
      "\n",
      "    accuracy                          0.240      5402\n",
      "   macro avg      0.257     0.416     0.239      5402\n",
      "weighted avg      0.552     0.240     0.239      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the resampled data\n",
    "mlp.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance of micro-averaged F1 score\n",
    "\n",
    "print(classification_report(y_test_standard, y_pred,digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offByOne(y_test_standard, y_pred,digits=3):\n",
    "    #compare y_test_standard with y_pred_list. If y_pred_list is +-1 from y_test_standard, then it change it to be the same as y_test_standard\n",
    "    y_test_standard_list=list(y_test_standard)\n",
    "    y_pred_list = list(y_pred)\n",
    "    for id in range(len(y_test_standard_list)):\n",
    "        if y_test_standard_list[id] != 0 and y_test_standard_list[id] != 7:\n",
    "            if y_pred_list[id] == y_test_standard_list[id] - 1 or y_pred_list[id] == y_test_standard_list[id] + 1:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 0:\n",
    "            if y_pred_list[id] ==  1 or y_pred_list[id] == 7:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 7:\n",
    "            if y_pred_list[id] ==  0 or y_pred_list[id] == 6:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "    print(classification_report(y_test_standard_list, y_pred_list,digits = digits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.538     0.389     0.451       525\n",
      "           1      0.392     0.739     0.512       199\n",
      "           2      0.145     0.787     0.244       136\n",
      "           3      0.110     0.799     0.194       134\n",
      "           4      0.147     0.677     0.242       124\n",
      "           5      0.360     0.455     0.402       275\n",
      "           6      0.940     0.756     0.838       724\n",
      "           7      0.971     0.425     0.591      3285\n",
      "\n",
      "    accuracy                          0.503      5402\n",
      "   macro avg      0.450     0.628     0.434      5402\n",
      "weighted avg      0.811     0.503     0.571      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm =SVC(kernel='poly', degree=3,class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.200     0.343     0.252       525\n",
      "           1      0.252     0.482     0.331       199\n",
      "           2      0.099     0.596     0.170       136\n",
      "           3      0.076     0.336     0.124       134\n",
      "           4      0.073     0.637     0.132       124\n",
      "           5      0.099     0.185     0.129       275\n",
      "           6      0.436     0.344     0.385       724\n",
      "           7      0.742     0.125     0.213      3285\n",
      "\n",
      "    accuracy                          0.220      5402\n",
      "   macro avg      0.247     0.381     0.217      5402\n",
      "weighted avg      0.550     0.220     0.235      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_SVM = svm.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_SVM,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.533     0.427     0.474       525\n",
      "           1      0.374     0.769     0.503       199\n",
      "           2      0.127     0.728     0.217       136\n",
      "           3      0.159     0.761     0.263       134\n",
      "           4      0.090     0.694     0.159       124\n",
      "           5      0.330     0.535     0.408       275\n",
      "           6      0.961     0.673     0.791       724\n",
      "           7      0.971     0.368     0.534      3285\n",
      "\n",
      "    accuracy                          0.464      5402\n",
      "   macro avg      0.443     0.619     0.419      5402\n",
      "weighted avg      0.811     0.464     0.532      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.24      0.21       525\n",
      "           1       0.18      0.46      0.26       199\n",
      "           2       0.10      0.54      0.17       136\n",
      "           3       0.05      0.28      0.09       134\n",
      "           4       0.05      0.25      0.09       124\n",
      "           5       0.10      0.21      0.13       275\n",
      "           6       0.35      0.37      0.36       724\n",
      "           7       0.68      0.17      0.27      3285\n",
      "\n",
      "    accuracy                           0.23      5402\n",
      "   macro avg       0.21      0.32      0.20      5402\n",
      "weighted avg       0.50      0.23      0.26      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.593     0.451     0.512       525\n",
      "           1      0.278     0.744     0.404       199\n",
      "           2      0.143     0.713     0.238       136\n",
      "           3      0.100     0.537     0.169       134\n",
      "           4      0.109     0.492     0.179       124\n",
      "           5      0.234     0.458     0.310       275\n",
      "           6      0.921     0.673     0.777       724\n",
      "           7      0.944     0.415     0.577      3285\n",
      "\n",
      "    accuracy                          0.480      5402\n",
      "   macro avg      0.415     0.560     0.396      5402\n",
      "weighted avg      0.786     0.480     0.550      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_DT = dt.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_DT))\n",
    "\n",
    "offByOne(y_test_standard, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.217     0.381     0.276       525\n",
      "           1      0.220     0.638     0.327       199\n",
      "           2      0.122     0.647     0.206       136\n",
      "           3      0.070     0.433     0.121       134\n",
      "           4      0.123     0.500     0.197       124\n",
      "           5      0.166     0.215     0.187       275\n",
      "           6      0.370     0.572     0.449       724\n",
      "           7      0.712     0.082     0.147      3285\n",
      "\n",
      "    accuracy                          0.236      5402\n",
      "   macro avg      0.250     0.433     0.239      5402\n",
      "weighted avg      0.528     0.236     0.211      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.581     0.484     0.528       525\n",
      "           1      0.294     0.854     0.437       199\n",
      "           2      0.162     0.831     0.271       136\n",
      "           3      0.112     0.701     0.193       134\n",
      "           4      0.181     0.669     0.285       124\n",
      "           5      0.378     0.465     0.417       275\n",
      "           6      0.950     0.736     0.830       724\n",
      "           7      0.975     0.441     0.608      3285\n",
      "\n",
      "    accuracy                          0.523      5402\n",
      "   macro avg      0.454     0.648     0.446      5402\n",
      "weighted avg      0.818     0.523     0.588      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_RF = rf.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_RF,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.212     0.371     0.270       525\n",
      "           1      0.234     0.623     0.340       199\n",
      "           2      0.114     0.662     0.195       136\n",
      "           3      0.070     0.440     0.121       134\n",
      "           4      0.122     0.484     0.195       124\n",
      "           5      0.173     0.225     0.196       275\n",
      "           6      0.373     0.579     0.454       724\n",
      "           7      0.746     0.080     0.145      3285\n",
      "\n",
      "    accuracy                          0.236      5402\n",
      "   macro avg      0.256     0.433     0.240      5402\n",
      "weighted avg      0.549     0.236     0.210      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.558     0.461     0.505       525\n",
      "           1      0.312     0.839     0.454       199\n",
      "           2      0.149     0.838     0.254       136\n",
      "           3      0.112     0.716     0.194       134\n",
      "           4      0.181     0.645     0.283       124\n",
      "           5      0.382     0.484     0.427       275\n",
      "           6      0.951     0.731     0.827       724\n",
      "           7      0.980     0.437     0.605      3285\n",
      "\n",
      "    accuracy                          0.518      5402\n",
      "   macro avg      0.453     0.644     0.443      5402\n",
      "weighted avg      0.819     0.518     0.584      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_estimator = RandomForestClassifier(n_estimators=100,  random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_bagging,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_bagging))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove worst 2 features **BEST SO FAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAndNormalize(features):\n",
    "    #clip the features to the range of the training data\n",
    "    features.drop(['key','time_signature'], axis=1, inplace=True)\n",
    "    #clip outliers to 1st and 99th percentile\n",
    "    features['danceability'] = features['danceability'].clip(lower=features['danceability'].quantile(0.01), upper=features['danceability'].quantile(0.99))\n",
    "    features['energy'] = features['energy'].clip(lower=features['energy'].quantile(0.01), upper=features['energy'].quantile(0.99))\n",
    "    features['loudness'] = features['loudness'].clip(lower=features['loudness'].quantile(0.01), upper=features['loudness'].quantile(0.99))\n",
    "    features['speechiness'] = features['speechiness'].clip(lower=features['speechiness'].quantile(0.01), upper=features['speechiness'].quantile(0.99))\n",
    "    features['acousticness'] = features['acousticness'].clip(lower=features['acousticness'].quantile(0.01), upper=features['acousticness'].quantile(0.99))\n",
    "    features['instrumentalness'] = features['instrumentalness'].clip(lower=features['instrumentalness'].quantile(0.01), upper=features['instrumentalness'].quantile(0.99))\n",
    "    features['liveness'] = features['liveness'].clip(lower=features['liveness'].quantile(0.01), upper=features['liveness'].quantile(0.99))\n",
    "    features['valence'] = features['valence'].clip(lower=features['valence'].quantile(0.01), upper=features['valence'].quantile(0.99))\n",
    "    features['tempo'] = features['tempo'].clip(lower=features['tempo'].quantile(0.01), upper=features['tempo'].quantile(0.99))\n",
    "    features['duration_ms'] = features['duration_ms'].clip(lower=features['duration_ms'].quantile(0.01), upper=features['duration_ms'].quantile(0.99))\n",
    "    #features['time_signature'] = features['time_signature'].clip(lower=features['time_signature'].quantile(0.01), upper=features['time_signature'].quantile(0.99))\n",
    "\n",
    "    columns_to_log=['liveness', 'instrumentalness', 'acousticness', 'speechiness','loudness','energy']\n",
    "\n",
    "    for i in columns_to_log:\n",
    "        if i == 'loudness':\n",
    "            features[i] = features[i] + 60\n",
    "        features[i] = np.log(features[i]+1)\n",
    "\n",
    "    \n",
    "    #normalize the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #if id is a column, drop it\n",
    "    if 'id' in features.columns:\n",
    "        #fit on all columns except the track id\n",
    "        rawfeatures = features.drop(['id'], axis=1)\n",
    "    else:\n",
    "        rawfeatures = features\n",
    "    preprocessedFeatures = scaler.fit_transform(rawfeatures)\n",
    "\n",
    "    preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    #apply z-score normalization\n",
    "    for i in columns_to_log:\n",
    "        preprocessedFeaturesDF[i] = stats.zscore(preprocessedFeaturesDF[i])\n",
    "        preprocessedFeaturesDF.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    '''#convert to dictionary, with track id as key\n",
    "    preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "    preprocessedFeatures['id']= features['id']\n",
    "    preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')'''\n",
    "    return preprocessedFeaturesDF, preprocessedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCategorical(df):\n",
    "    mood_order=['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "    mood_codes, mood_categories = pd.factorize(mood_order)\n",
    "    \n",
    "    # Create a categorical object with the desired order\n",
    "    cat = pd.Categorical(df['mood'], categories=mood_order, ordered=True)\n",
    "\n",
    "    # Get the integer codes of the categories\n",
    "    codes = cat.codes\n",
    "\n",
    "    # Add the codes as a new column to the dataframe\n",
    "    df['mood_code'] = codes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('C:/Users/mlar5/OneDrive/Desktop/Code Folder/Python Projects/IRL projects/Aspire - Affective Computing Project/Playlists Data/Audio Features/emotion joint data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = pd.read_csv('Merged Emotions Data5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = makeCategorical(emotionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3779\n",
       "6    1218\n",
       "0    1020\n",
       "5     770\n",
       "1     694\n",
       "2     630\n",
       "3     628\n",
       "4     618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionsDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    618\n",
       "6    618\n",
       "5    618\n",
       "7    618\n",
       "2    618\n",
       "3    618\n",
       "4    618\n",
       "0    618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df with only up to 500 songs per mood_code\n",
    "# this is to balance the data\n",
    "\n",
    "balancedDF = pd.DataFrame(columns=emotionsDF.columns)\n",
    "\n",
    "largest_balanced_sample = emotionsDF['mood_code'].value_counts().min()\n",
    "\n",
    "for i in emotionsDF['mood_code'].unique():\n",
    "    df = emotionsDF[emotionsDF['mood_code']==i]\n",
    "    #if the value count of the mood_code is larger than 500, sample 500\n",
    "    if df['mood_code'].value_counts()[i] >= largest_balanced_sample:\n",
    "        df = df.sample(n=largest_balanced_sample, random_state=42)\n",
    "    #if the value count of the mood_code is less than 500, sample the value count\n",
    "    else:\n",
    "        df = df.sample(n=df['mood_code'].value_counts()[i])\n",
    "    balancedDF = pd.concat([balancedDF, df])\n",
    "\n",
    "balancedDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song</th>\n",
       "      <th>mood</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.304</td>\n",
       "      <td>149.996</td>\n",
       "      <td>spotify:track:2XSrt1dcuOXPgl3B4bxmBz</td>\n",
       "      <td>203897</td>\n",
       "      <td>4</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.698</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.480</td>\n",
       "      <td>124.973</td>\n",
       "      <td>spotify:track:1SSv8SA2OHfOUwLgb8yOum</td>\n",
       "      <td>180062</td>\n",
       "      <td>4</td>\n",
       "      <td>Cheat Cxdes</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.125</td>\n",
       "      <td>130.058</td>\n",
       "      <td>spotify:track:0A8Mrg7ButLr17K3A0R61D</td>\n",
       "      <td>133308</td>\n",
       "      <td>4</td>\n",
       "      <td>TOTALITARIANISM</td>\n",
       "      <td>angry</td>\n",
       "      <td>EDM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.396</td>\n",
       "      <td>95.971</td>\n",
       "      <td>spotify:track:583TaS41X2JJGKoGXnTY3l</td>\n",
       "      <td>107159</td>\n",
       "      <td>4</td>\n",
       "      <td>KILLTHEPHARAOH</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.836</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.397</td>\n",
       "      <td>175.060</td>\n",
       "      <td>spotify:track:7CMy59461Q3pgsPZ4Cj8CP</td>\n",
       "      <td>89143</td>\n",
       "      <td>4</td>\n",
       "      <td>EASE</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy key  loudness mode  speechiness  acousticness  \\\n",
       "381         0.848   0.520   5   -10.663    0       0.5010      0.002250   \n",
       "666         0.713   0.698  10    -7.435    0       0.1680      0.180000   \n",
       "257         0.757   0.423   1    -2.311    1       0.0527      0.000004   \n",
       "338         0.516   0.515   1   -13.005    1       0.2790      0.033600   \n",
       "319         0.618   0.836   6    -4.750    0       0.0813      0.002400   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  \\\n",
       "381          0.000799     0.679    0.304  149.996   \n",
       "666          0.000001     0.304    0.480  124.973   \n",
       "257          0.897000     0.118    0.125  130.058   \n",
       "338          0.000002     0.119    0.396   95.971   \n",
       "319          0.000000     0.363    0.397  175.060   \n",
       "\n",
       "                                      uri duration_ms time_signature  \\\n",
       "381  spotify:track:2XSrt1dcuOXPgl3B4bxmBz      203897              4   \n",
       "666  spotify:track:1SSv8SA2OHfOUwLgb8yOum      180062              4   \n",
       "257  spotify:track:0A8Mrg7ButLr17K3A0R61D      133308              4   \n",
       "338  spotify:track:583TaS41X2JJGKoGXnTY3l      107159              4   \n",
       "319  spotify:track:7CMy59461Q3pgsPZ4Cj8CP       89143              4   \n",
       "\n",
       "                song   mood genre mood_code  \n",
       "381       Carrollton  angry   rap         1  \n",
       "666      Cheat Cxdes  angry   rap         1  \n",
       "257  TOTALITARIANISM  angry   EDM         1  \n",
       "338   KILLTHEPHARAOH  angry   rap         1  \n",
       "319             EASE  angry   rap         1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeatures = balancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeaturesDF, rawfeatures = clipAndNormalize(rawfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482419</td>\n",
       "      <td>-0.322342</td>\n",
       "      <td>-0.665392</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.958541</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.552893</td>\n",
       "      <td>0.940143</td>\n",
       "      <td>0.272427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545890</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>-0.245604</td>\n",
       "      <td>-0.492971</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>0.071470</td>\n",
       "      <td>-0.199505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851129</td>\n",
       "      <td>-0.735754</td>\n",
       "      <td>1.136073</td>\n",
       "      <td>0.779283</td>\n",
       "      <td>-0.530916</td>\n",
       "      <td>-0.967633</td>\n",
       "      <td>2.350764</td>\n",
       "      <td>-0.477927</td>\n",
       "      <td>-1.311172</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>-1.125231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.820748</td>\n",
       "      <td>-0.342998</td>\n",
       "      <td>-1.224490</td>\n",
       "      <td>0.779283</td>\n",
       "      <td>1.695751</td>\n",
       "      <td>-0.824045</td>\n",
       "      <td>-0.492970</td>\n",
       "      <td>-0.469337</td>\n",
       "      <td>-0.163163</td>\n",
       "      <td>-0.935335</td>\n",
       "      <td>-1.642980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.113148</td>\n",
       "      <td>0.861786</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>-1.283231</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.957888</td>\n",
       "      <td>-0.492977</td>\n",
       "      <td>1.425940</td>\n",
       "      <td>-0.158927</td>\n",
       "      <td>1.810239</td>\n",
       "      <td>-1.999696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy  loudness      mode  speechiness  acousticness  \\\n",
       "0      1.482419 -0.322342 -0.665392 -1.283231     2.700000     -0.958541   \n",
       "1      0.545890  0.371919  0.064003 -1.283231     0.657598     -0.245604   \n",
       "2      0.851129 -0.735754  1.136073  0.779283    -0.530916     -0.967633   \n",
       "3     -0.820748 -0.342998 -1.224490  0.779283     1.695751     -0.824045   \n",
       "4     -0.113148  0.861786  0.637965 -1.283231    -0.224387     -0.957888   \n",
       "\n",
       "   instrumentalness  liveness   valence     tempo  duration_ms  \n",
       "0         -0.489430  2.700000 -0.552893  0.940143     0.272427  \n",
       "1         -0.492971  1.000754  0.192677  0.071470    -0.199505  \n",
       "2          2.350764 -0.477927 -1.311172  0.247995    -1.125231  \n",
       "3         -0.492970 -0.469337 -0.163163 -0.935335    -1.642980  \n",
       "4         -0.492977  1.425940 -0.158927  1.810239    -1.999696  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balancedDF['mood_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it to categorical\n",
    "y = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#make a new dataframe of all the rows in emotionsDF that are not in balancedDF\n",
    "unbalancedDF = emotionsDF[~emotionsDF.index.isin(balancedDF.index)]\n",
    "extra_test_features = unbalancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)\n",
    "extra_test_features_DF, extra_test_features = clipAndNormalize(extra_test_features)\n",
    "extra_test_y = unbalancedDF['mood_code'].astype('category')\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#combine the extra test features to the test set numpy arrays\n",
    "X_test_standard = np.concatenate((X_test_standard, extra_test_features), axis=0)\n",
    "y_test_standard = np.concatenate((y_test_standard, extra_test_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128),random_state=42,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.210     0.343     0.261       525\n",
      "           1      0.257     0.563     0.353       199\n",
      "           2      0.111     0.596     0.187       136\n",
      "           3      0.076     0.463     0.130       134\n",
      "           4      0.099     0.508     0.165       124\n",
      "           5      0.146     0.265     0.188       275\n",
      "           6      0.419     0.511     0.460       724\n",
      "           7      0.766     0.125     0.216      3285\n",
      "\n",
      "    accuracy                          0.250      5402\n",
      "   macro avg      0.260     0.422     0.245      5402\n",
      "weighted avg      0.566     0.250     0.252      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the resampled data\n",
    "mlp.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance of micro-averaged F1 score\n",
    "\n",
    "print(classification_report(y_test_standard, y_pred,digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offByOne(y_test_standard, y_pred,digits=3):\n",
    "    #compare y_test_standard with y_pred_list. If y_pred_list is +-1 from y_test_standard, then it change it to be the same as y_test_standard\n",
    "    y_test_standard_list=list(y_test_standard)\n",
    "    y_pred_list = list(y_pred)\n",
    "    for id in range(len(y_test_standard_list)):\n",
    "        if y_test_standard_list[id] != 0 and y_test_standard_list[id] != 7:\n",
    "            if y_pred_list[id] == y_test_standard_list[id] - 1 or y_pred_list[id] == y_test_standard_list[id] + 1:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 0:\n",
    "            if y_pred_list[id] ==  1 or y_pred_list[id] == 7:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 7:\n",
    "            if y_pred_list[id] ==  0 or y_pred_list[id] == 6:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "    print(classification_report(y_test_standard_list, y_pred_list,digits = digits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.574     0.429     0.491       525\n",
      "           1      0.349     0.784     0.483       199\n",
      "           2      0.144     0.750     0.242       136\n",
      "           3      0.119     0.746     0.206       134\n",
      "           4      0.144     0.669     0.237       124\n",
      "           5      0.323     0.513     0.397       275\n",
      "           6      0.961     0.757     0.847       724\n",
      "           7      0.969     0.423     0.589      3285\n",
      "\n",
      "    accuracy                          0.508      5402\n",
      "   macro avg      0.448     0.634     0.436      5402\n",
      "weighted avg      0.813     0.508     0.574      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm =SVC(kernel='poly', degree=3,class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.205     0.387     0.268       525\n",
      "           1      0.258     0.487     0.337       199\n",
      "           2      0.103     0.625     0.177       136\n",
      "           3      0.080     0.366     0.131       134\n",
      "           4      0.076     0.605     0.136       124\n",
      "           5      0.098     0.193     0.130       275\n",
      "           6      0.432     0.372     0.400       724\n",
      "           7      0.741     0.102     0.179      3285\n",
      "\n",
      "    accuracy                          0.216      5402\n",
      "   macro avg      0.249     0.392     0.220      5402\n",
      "weighted avg      0.549     0.216     0.218      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_SVM = svm.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_SVM,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.537     0.453     0.492       525\n",
      "           1      0.379     0.769     0.507       199\n",
      "           2      0.131     0.757     0.224       136\n",
      "           3      0.154     0.754     0.255       134\n",
      "           4      0.096     0.677     0.168       124\n",
      "           5      0.307     0.516     0.385       275\n",
      "           6      0.964     0.675     0.794       724\n",
      "           7      0.970     0.374     0.540      3285\n",
      "\n",
      "    accuracy                          0.470      5402\n",
      "   macro avg      0.442     0.622     0.421      5402\n",
      "weighted avg      0.810     0.470     0.537      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.23      0.20       525\n",
      "           1       0.19      0.51      0.28       199\n",
      "           2       0.10      0.52      0.17       136\n",
      "           3       0.06      0.29      0.09       134\n",
      "           4       0.05      0.24      0.09       124\n",
      "           5       0.10      0.23      0.13       275\n",
      "           6       0.36      0.37      0.37       724\n",
      "           7       0.68      0.17      0.27      3285\n",
      "\n",
      "    accuracy                           0.23      5402\n",
      "   macro avg       0.21      0.32      0.20      5402\n",
      "weighted avg       0.50      0.23      0.26      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.591     0.444     0.507       525\n",
      "           1      0.288     0.764     0.419       199\n",
      "           2      0.148     0.750     0.248       136\n",
      "           3      0.105     0.545     0.176       134\n",
      "           4      0.114     0.492     0.185       124\n",
      "           5      0.231     0.498     0.315       275\n",
      "           6      0.929     0.684     0.788       724\n",
      "           7      0.946     0.414     0.576      3285\n",
      "\n",
      "    accuracy                          0.484      5402\n",
      "   macro avg      0.419     0.574     0.402      5402\n",
      "weighted avg      0.789     0.484     0.552      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_DT = dt.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_DT))\n",
    "\n",
    "offByOne(y_test_standard, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.218     0.387     0.279       525\n",
      "           1      0.219     0.613     0.322       199\n",
      "           2      0.122     0.654     0.206       136\n",
      "           3      0.071     0.440     0.122       134\n",
      "           4      0.129     0.516     0.207       124\n",
      "           5      0.160     0.200     0.178       275\n",
      "           6      0.371     0.575     0.451       724\n",
      "           7      0.704     0.084     0.150      3285\n",
      "\n",
      "    accuracy                          0.238      5402\n",
      "   macro avg      0.249     0.434     0.239      5402\n",
      "weighted avg      0.523     0.238     0.213      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.591     0.493     0.538       525\n",
      "           1      0.294     0.824     0.433       199\n",
      "           2      0.162     0.838     0.271       136\n",
      "           3      0.112     0.709     0.193       134\n",
      "           4      0.188     0.685     0.296       124\n",
      "           5      0.385     0.469     0.423       275\n",
      "           6      0.955     0.739     0.833       724\n",
      "           7      0.973     0.446     0.612      3285\n",
      "\n",
      "    accuracy                          0.527      5402\n",
      "   macro avg      0.458     0.651     0.450      5402\n",
      "weighted avg      0.819     0.527     0.592      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_RF = rf.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_RF,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.213     0.371     0.271       525\n",
      "           1      0.233     0.623     0.339       199\n",
      "           2      0.118     0.669     0.200       136\n",
      "           3      0.071     0.448     0.122       134\n",
      "           4      0.123     0.492     0.197       124\n",
      "           5      0.169     0.215     0.189       275\n",
      "           6      0.376     0.586     0.458       724\n",
      "           7      0.721     0.079     0.142      3285\n",
      "\n",
      "    accuracy                          0.236      5402\n",
      "   macro avg      0.253     0.435     0.240      5402\n",
      "weighted avg      0.534     0.236     0.209      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.568     0.463     0.510       525\n",
      "           1      0.310     0.839     0.453       199\n",
      "           2      0.154     0.846     0.260       136\n",
      "           3      0.113     0.731     0.196       134\n",
      "           4      0.188     0.677     0.294       124\n",
      "           5      0.386     0.484     0.429       275\n",
      "           6      0.957     0.733     0.830       724\n",
      "           7      0.977     0.438     0.605      3285\n",
      "\n",
      "    accuracy                          0.520      5402\n",
      "   macro avg      0.456     0.651     0.447      5402\n",
      "weighted avg      0.820     0.520     0.586      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_estimator = RandomForestClassifier(n_estimators=100,  random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_bagging,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_bagging))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove worst 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAndNormalize(features):\n",
    "    #clip the features to the range of the training data\n",
    "    features.drop(['key','time_signature','mode'], axis=1, inplace=True)\n",
    "    #clip outliers to 1st and 99th percentile\n",
    "    features['danceability'] = features['danceability'].clip(lower=features['danceability'].quantile(0.01), upper=features['danceability'].quantile(0.99))\n",
    "    features['energy'] = features['energy'].clip(lower=features['energy'].quantile(0.01), upper=features['energy'].quantile(0.99))\n",
    "    features['loudness'] = features['loudness'].clip(lower=features['loudness'].quantile(0.01), upper=features['loudness'].quantile(0.99))\n",
    "    features['speechiness'] = features['speechiness'].clip(lower=features['speechiness'].quantile(0.01), upper=features['speechiness'].quantile(0.99))\n",
    "    features['acousticness'] = features['acousticness'].clip(lower=features['acousticness'].quantile(0.01), upper=features['acousticness'].quantile(0.99))\n",
    "    features['instrumentalness'] = features['instrumentalness'].clip(lower=features['instrumentalness'].quantile(0.01), upper=features['instrumentalness'].quantile(0.99))\n",
    "    features['liveness'] = features['liveness'].clip(lower=features['liveness'].quantile(0.01), upper=features['liveness'].quantile(0.99))\n",
    "    features['valence'] = features['valence'].clip(lower=features['valence'].quantile(0.01), upper=features['valence'].quantile(0.99))\n",
    "    features['tempo'] = features['tempo'].clip(lower=features['tempo'].quantile(0.01), upper=features['tempo'].quantile(0.99))\n",
    "    features['duration_ms'] = features['duration_ms'].clip(lower=features['duration_ms'].quantile(0.01), upper=features['duration_ms'].quantile(0.99))\n",
    "    #features['time_signature'] = features['time_signature'].clip(lower=features['time_signature'].quantile(0.01), upper=features['time_signature'].quantile(0.99))\n",
    "\n",
    "    columns_to_log=['liveness', 'instrumentalness', 'acousticness', 'speechiness','loudness','energy']\n",
    "\n",
    "    for i in columns_to_log:\n",
    "        if i == 'loudness':\n",
    "            features[i] = features[i] + 60\n",
    "        features[i] = np.log(features[i]+1)\n",
    "\n",
    "    \n",
    "    #normalize the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #if id is a column, drop it\n",
    "    if 'id' in features.columns:\n",
    "        #fit on all columns except the track id\n",
    "        rawfeatures = features.drop(['id'], axis=1)\n",
    "    else:\n",
    "        rawfeatures = features\n",
    "    preprocessedFeatures = scaler.fit_transform(rawfeatures)\n",
    "\n",
    "    preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    #apply z-score normalization\n",
    "    for i in columns_to_log:\n",
    "        preprocessedFeaturesDF[i] = stats.zscore(preprocessedFeaturesDF[i])\n",
    "        preprocessedFeaturesDF.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    '''#convert to dictionary, with track id as key\n",
    "    preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "    preprocessedFeatures['id']= features['id']\n",
    "    preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')'''\n",
    "    return preprocessedFeaturesDF, preprocessedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCategorical(df):\n",
    "    mood_order=['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "    mood_codes, mood_categories = pd.factorize(mood_order)\n",
    "    \n",
    "    # Create a categorical object with the desired order\n",
    "    cat = pd.Categorical(df['mood'], categories=mood_order, ordered=True)\n",
    "\n",
    "    # Get the integer codes of the categories\n",
    "    codes = cat.codes\n",
    "\n",
    "    # Add the codes as a new column to the dataframe\n",
    "    df['mood_code'] = codes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('C:/Users/mlar5/OneDrive/Desktop/Code Folder/Python Projects/IRL projects/Aspire - Affective Computing Project/Playlists Data/Audio Features/emotion joint data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = pd.read_csv('Merged Emotions Data5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = makeCategorical(emotionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3779\n",
       "6    1218\n",
       "0    1020\n",
       "5     770\n",
       "1     694\n",
       "2     630\n",
       "3     628\n",
       "4     618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionsDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    618\n",
       "6    618\n",
       "5    618\n",
       "7    618\n",
       "2    618\n",
       "3    618\n",
       "4    618\n",
       "0    618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df with only up to 500 songs per mood_code\n",
    "# this is to balance the data\n",
    "\n",
    "balancedDF = pd.DataFrame(columns=emotionsDF.columns)\n",
    "\n",
    "largest_balanced_sample = emotionsDF['mood_code'].value_counts().min()\n",
    "\n",
    "for i in emotionsDF['mood_code'].unique():\n",
    "    df = emotionsDF[emotionsDF['mood_code']==i]\n",
    "    #if the value count of the mood_code is larger than 500, sample 500\n",
    "    if df['mood_code'].value_counts()[i] >= largest_balanced_sample:\n",
    "        df = df.sample(n=largest_balanced_sample, random_state=42)\n",
    "    #if the value count of the mood_code is less than 500, sample the value count\n",
    "    else:\n",
    "        df = df.sample(n=df['mood_code'].value_counts()[i])\n",
    "    balancedDF = pd.concat([balancedDF, df])\n",
    "\n",
    "balancedDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song</th>\n",
       "      <th>mood</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.304</td>\n",
       "      <td>149.996</td>\n",
       "      <td>spotify:track:2XSrt1dcuOXPgl3B4bxmBz</td>\n",
       "      <td>203897</td>\n",
       "      <td>4</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.698</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.480</td>\n",
       "      <td>124.973</td>\n",
       "      <td>spotify:track:1SSv8SA2OHfOUwLgb8yOum</td>\n",
       "      <td>180062</td>\n",
       "      <td>4</td>\n",
       "      <td>Cheat Cxdes</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.125</td>\n",
       "      <td>130.058</td>\n",
       "      <td>spotify:track:0A8Mrg7ButLr17K3A0R61D</td>\n",
       "      <td>133308</td>\n",
       "      <td>4</td>\n",
       "      <td>TOTALITARIANISM</td>\n",
       "      <td>angry</td>\n",
       "      <td>EDM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.396</td>\n",
       "      <td>95.971</td>\n",
       "      <td>spotify:track:583TaS41X2JJGKoGXnTY3l</td>\n",
       "      <td>107159</td>\n",
       "      <td>4</td>\n",
       "      <td>KILLTHEPHARAOH</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.836</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.397</td>\n",
       "      <td>175.060</td>\n",
       "      <td>spotify:track:7CMy59461Q3pgsPZ4Cj8CP</td>\n",
       "      <td>89143</td>\n",
       "      <td>4</td>\n",
       "      <td>EASE</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy key  loudness mode  speechiness  acousticness  \\\n",
       "381         0.848   0.520   5   -10.663    0       0.5010      0.002250   \n",
       "666         0.713   0.698  10    -7.435    0       0.1680      0.180000   \n",
       "257         0.757   0.423   1    -2.311    1       0.0527      0.000004   \n",
       "338         0.516   0.515   1   -13.005    1       0.2790      0.033600   \n",
       "319         0.618   0.836   6    -4.750    0       0.0813      0.002400   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  \\\n",
       "381          0.000799     0.679    0.304  149.996   \n",
       "666          0.000001     0.304    0.480  124.973   \n",
       "257          0.897000     0.118    0.125  130.058   \n",
       "338          0.000002     0.119    0.396   95.971   \n",
       "319          0.000000     0.363    0.397  175.060   \n",
       "\n",
       "                                      uri duration_ms time_signature  \\\n",
       "381  spotify:track:2XSrt1dcuOXPgl3B4bxmBz      203897              4   \n",
       "666  spotify:track:1SSv8SA2OHfOUwLgb8yOum      180062              4   \n",
       "257  spotify:track:0A8Mrg7ButLr17K3A0R61D      133308              4   \n",
       "338  spotify:track:583TaS41X2JJGKoGXnTY3l      107159              4   \n",
       "319  spotify:track:7CMy59461Q3pgsPZ4Cj8CP       89143              4   \n",
       "\n",
       "                song   mood genre mood_code  \n",
       "381       Carrollton  angry   rap         1  \n",
       "666      Cheat Cxdes  angry   rap         1  \n",
       "257  TOTALITARIANISM  angry   EDM         1  \n",
       "338   KILLTHEPHARAOH  angry   rap         1  \n",
       "319             EASE  angry   rap         1  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeatures = balancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeaturesDF, rawfeatures = clipAndNormalize(rawfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482419</td>\n",
       "      <td>-0.322342</td>\n",
       "      <td>-0.665392</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.958541</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.552893</td>\n",
       "      <td>0.940143</td>\n",
       "      <td>0.272427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545890</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>-0.245604</td>\n",
       "      <td>-0.492971</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>0.071470</td>\n",
       "      <td>-0.199505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851129</td>\n",
       "      <td>-0.735754</td>\n",
       "      <td>1.136073</td>\n",
       "      <td>-0.530916</td>\n",
       "      <td>-0.967633</td>\n",
       "      <td>2.350764</td>\n",
       "      <td>-0.477927</td>\n",
       "      <td>-1.311172</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>-1.125231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.820748</td>\n",
       "      <td>-0.342998</td>\n",
       "      <td>-1.224490</td>\n",
       "      <td>1.695751</td>\n",
       "      <td>-0.824045</td>\n",
       "      <td>-0.492970</td>\n",
       "      <td>-0.469337</td>\n",
       "      <td>-0.163163</td>\n",
       "      <td>-0.935335</td>\n",
       "      <td>-1.642980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.113148</td>\n",
       "      <td>0.861786</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.957888</td>\n",
       "      <td>-0.492977</td>\n",
       "      <td>1.425940</td>\n",
       "      <td>-0.158927</td>\n",
       "      <td>1.810239</td>\n",
       "      <td>-1.999696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy  loudness  speechiness  acousticness  \\\n",
       "0      1.482419 -0.322342 -0.665392     2.700000     -0.958541   \n",
       "1      0.545890  0.371919  0.064003     0.657598     -0.245604   \n",
       "2      0.851129 -0.735754  1.136073    -0.530916     -0.967633   \n",
       "3     -0.820748 -0.342998 -1.224490     1.695751     -0.824045   \n",
       "4     -0.113148  0.861786  0.637965    -0.224387     -0.957888   \n",
       "\n",
       "   instrumentalness  liveness   valence     tempo  duration_ms  \n",
       "0         -0.489430  2.700000 -0.552893  0.940143     0.272427  \n",
       "1         -0.492971  1.000754  0.192677  0.071470    -0.199505  \n",
       "2          2.350764 -0.477927 -1.311172  0.247995    -1.125231  \n",
       "3         -0.492970 -0.469337 -0.163163 -0.935335    -1.642980  \n",
       "4         -0.492977  1.425940 -0.158927  1.810239    -1.999696  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balancedDF['mood_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it to categorical\n",
    "y = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#make a new dataframe of all the rows in emotionsDF that are not in balancedDF\n",
    "unbalancedDF = emotionsDF[~emotionsDF.index.isin(balancedDF.index)]\n",
    "extra_test_features = unbalancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)\n",
    "extra_test_features_DF, extra_test_features = clipAndNormalize(extra_test_features)\n",
    "extra_test_y = unbalancedDF['mood_code'].astype('category')\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#combine the extra test features to the test set numpy arrays\n",
    "X_test_standard = np.concatenate((X_test_standard, extra_test_features), axis=0)\n",
    "y_test_standard = np.concatenate((y_test_standard, extra_test_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128),random_state=42,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.193     0.354     0.249       525\n",
      "           1      0.223     0.633     0.330       199\n",
      "           2      0.111     0.654     0.190       136\n",
      "           3      0.071     0.418     0.121       134\n",
      "           4      0.102     0.395     0.162       124\n",
      "           5      0.180     0.193     0.186       275\n",
      "           6      0.400     0.557     0.465       724\n",
      "           7      0.741     0.112     0.194      3285\n",
      "\n",
      "    accuracy                          0.246      5402\n",
      "   macro avg      0.253     0.415     0.237      5402\n",
      "weighted avg      0.547     0.246     0.238      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the resampled data\n",
    "mlp.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance of micro-averaged F1 score\n",
    "\n",
    "print(classification_report(y_test_standard, y_pred,digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offByOne(y_test_standard, y_pred,digits=3):\n",
    "    #compare y_test_standard with y_pred_list. If y_pred_list is +-1 from y_test_standard, then it change it to be the same as y_test_standard\n",
    "    y_test_standard_list=list(y_test_standard)\n",
    "    y_pred_list = list(y_pred)\n",
    "    for id in range(len(y_test_standard_list)):\n",
    "        if y_test_standard_list[id] != 0 and y_test_standard_list[id] != 7:\n",
    "            if y_pred_list[id] == y_test_standard_list[id] - 1 or y_pred_list[id] == y_test_standard_list[id] + 1:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 0:\n",
    "            if y_pred_list[id] ==  1 or y_pred_list[id] == 7:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 7:\n",
    "            if y_pred_list[id] ==  0 or y_pred_list[id] == 6:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "    print(classification_report(y_test_standard_list, y_pred_list,digits = digits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.535     0.453     0.491       525\n",
      "           1      0.297     0.839     0.438       199\n",
      "           2      0.147     0.846     0.251       136\n",
      "           3      0.115     0.694     0.197       134\n",
      "           4      0.156     0.548     0.243       124\n",
      "           5      0.406     0.400     0.403       275\n",
      "           6      0.940     0.736     0.826       724\n",
      "           7      0.970     0.452     0.617      3285\n",
      "\n",
      "    accuracy                          0.520      5402\n",
      "   macro avg      0.446     0.621     0.433      5402\n",
      "weighted avg      0.810     0.520     0.587      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm =SVC(kernel='poly', degree=3,class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.210     0.370     0.267       525\n",
      "           1      0.266     0.452     0.335       199\n",
      "           2      0.099     0.588     0.169       136\n",
      "           3      0.082     0.403     0.136       134\n",
      "           4      0.072     0.653     0.130       124\n",
      "           5      0.100     0.196     0.132       275\n",
      "           6      0.453     0.314     0.371       724\n",
      "           7      0.767     0.118     0.205      3285\n",
      "\n",
      "    accuracy                          0.216      5402\n",
      "   macro avg      0.256     0.387     0.218      5402\n",
      "weighted avg      0.569     0.216     0.230      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_SVM = svm.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_SVM,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.528     0.427     0.472       525\n",
      "           1      0.411     0.764     0.534       199\n",
      "           2      0.128     0.721     0.218       136\n",
      "           3      0.152     0.791     0.255       134\n",
      "           4      0.093     0.750     0.165       124\n",
      "           5      0.319     0.542     0.402       275\n",
      "           6      0.967     0.655     0.781       724\n",
      "           7      0.980     0.353     0.519      3285\n",
      "\n",
      "    accuracy                          0.455      5402\n",
      "   macro avg      0.447     0.625     0.418      5402\n",
      "weighted avg      0.817     0.455     0.522      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.24      0.21       525\n",
      "           1       0.18      0.47      0.26       199\n",
      "           2       0.10      0.54      0.17       136\n",
      "           3       0.05      0.25      0.08       134\n",
      "           4       0.06      0.27      0.10       124\n",
      "           5       0.09      0.21      0.13       275\n",
      "           6       0.35      0.36      0.36       724\n",
      "           7       0.67      0.17      0.27      3285\n",
      "\n",
      "    accuracy                           0.23      5402\n",
      "   macro avg       0.21      0.31      0.20      5402\n",
      "weighted avg       0.49      0.23      0.26      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.593     0.448     0.510       525\n",
      "           1      0.278     0.719     0.401       199\n",
      "           2      0.146     0.757     0.244       136\n",
      "           3      0.100     0.522     0.168       134\n",
      "           4      0.120     0.524     0.195       124\n",
      "           5      0.226     0.469     0.305       275\n",
      "           6      0.917     0.688     0.786       724\n",
      "           7      0.949     0.412     0.575      3285\n",
      "\n",
      "    accuracy                          0.481      5402\n",
      "   macro avg      0.416     0.567     0.398      5402\n",
      "weighted avg      0.788     0.481     0.550      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_DT = dt.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_DT))\n",
    "\n",
    "offByOne(y_test_standard, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.213     0.375     0.272       525\n",
      "           1      0.220     0.638     0.327       199\n",
      "           2      0.121     0.640     0.204       136\n",
      "           3      0.070     0.425     0.120       134\n",
      "           4      0.122     0.500     0.196       124\n",
      "           5      0.155     0.193     0.172       275\n",
      "           6      0.373     0.580     0.454       724\n",
      "           7      0.721     0.086     0.153      3285\n",
      "\n",
      "    accuracy                          0.238      5402\n",
      "   macro avg      0.249     0.430     0.237      5402\n",
      "weighted avg      0.532     0.238     0.214      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.571     0.482     0.523       525\n",
      "           1      0.294     0.849     0.437       199\n",
      "           2      0.161     0.824     0.269       136\n",
      "           3      0.112     0.694     0.193       134\n",
      "           4      0.178     0.669     0.281       124\n",
      "           5      0.375     0.451     0.409       275\n",
      "           6      0.955     0.738     0.832       724\n",
      "           7      0.973     0.444     0.610      3285\n",
      "\n",
      "    accuracy                          0.524      5402\n",
      "   macro avg      0.452     0.644     0.444      5402\n",
      "weighted avg      0.816     0.524     0.588      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_RF = rf.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_RF,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.215     0.377     0.274       525\n",
      "           1      0.229     0.628     0.336       199\n",
      "           2      0.116     0.654     0.197       136\n",
      "           3      0.073     0.455     0.125       134\n",
      "           4      0.127     0.492     0.202       124\n",
      "           5      0.166     0.207     0.184       275\n",
      "           6      0.377     0.586     0.458       724\n",
      "           7      0.726     0.084     0.150      3285\n",
      "\n",
      "    accuracy                          0.239      5402\n",
      "   macro avg      0.253     0.435     0.241      5402\n",
      "weighted avg      0.537     0.239     0.214      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.570     0.472     0.517       525\n",
      "           1      0.304     0.844     0.447       199\n",
      "           2      0.151     0.824     0.255       136\n",
      "           3      0.112     0.709     0.193       134\n",
      "           4      0.188     0.669     0.293       124\n",
      "           5      0.368     0.447     0.404       275\n",
      "           6      0.957     0.733     0.830       724\n",
      "           7      0.976     0.442     0.609      3285\n",
      "\n",
      "    accuracy                          0.521      5402\n",
      "   macro avg      0.453     0.643     0.443      5402\n",
      "weighted avg      0.818     0.521     0.587      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_estimator = RandomForestClassifier(n_estimators=100,  random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_bagging,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_bagging))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove worst 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAndNormalize(features):\n",
    "    #clip the features to the range of the training data\n",
    "    features.drop(['key','time_signature','mode', 'tempo'], axis=1, inplace=True)\n",
    "    #clip outliers to 1st and 99th percentile\n",
    "    features['danceability'] = features['danceability'].clip(lower=features['danceability'].quantile(0.01), upper=features['danceability'].quantile(0.99))\n",
    "    features['energy'] = features['energy'].clip(lower=features['energy'].quantile(0.01), upper=features['energy'].quantile(0.99))\n",
    "    features['loudness'] = features['loudness'].clip(lower=features['loudness'].quantile(0.01), upper=features['loudness'].quantile(0.99))\n",
    "    features['speechiness'] = features['speechiness'].clip(lower=features['speechiness'].quantile(0.01), upper=features['speechiness'].quantile(0.99))\n",
    "    features['acousticness'] = features['acousticness'].clip(lower=features['acousticness'].quantile(0.01), upper=features['acousticness'].quantile(0.99))\n",
    "    features['instrumentalness'] = features['instrumentalness'].clip(lower=features['instrumentalness'].quantile(0.01), upper=features['instrumentalness'].quantile(0.99))\n",
    "    features['liveness'] = features['liveness'].clip(lower=features['liveness'].quantile(0.01), upper=features['liveness'].quantile(0.99))\n",
    "    features['valence'] = features['valence'].clip(lower=features['valence'].quantile(0.01), upper=features['valence'].quantile(0.99))\n",
    "    #features['tempo'] = features['tempo'].clip(lower=features['tempo'].quantile(0.01), upper=features['tempo'].quantile(0.99))\n",
    "    features['duration_ms'] = features['duration_ms'].clip(lower=features['duration_ms'].quantile(0.01), upper=features['duration_ms'].quantile(0.99))\n",
    "    #features['time_signature'] = features['time_signature'].clip(lower=features['time_signature'].quantile(0.01), upper=features['time_signature'].quantile(0.99))\n",
    "\n",
    "    columns_to_log=['liveness', 'instrumentalness', 'acousticness', 'speechiness','loudness','energy']\n",
    "\n",
    "    for i in columns_to_log:\n",
    "        if i == 'loudness':\n",
    "            features[i] = features[i] + 60\n",
    "        features[i] = np.log(features[i]+1)\n",
    "\n",
    "    \n",
    "    #normalize the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #if id is a column, drop it\n",
    "    if 'id' in features.columns:\n",
    "        #fit on all columns except the track id\n",
    "        rawfeatures = features.drop(['id'], axis=1)\n",
    "    else:\n",
    "        rawfeatures = features\n",
    "    preprocessedFeatures = scaler.fit_transform(rawfeatures)\n",
    "\n",
    "    preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    #apply z-score normalization\n",
    "    for i in columns_to_log:\n",
    "        preprocessedFeaturesDF[i] = stats.zscore(preprocessedFeaturesDF[i])\n",
    "        preprocessedFeaturesDF.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    '''#convert to dictionary, with track id as key\n",
    "    preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "    preprocessedFeatures['id']= features['id']\n",
    "    preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')'''\n",
    "    return preprocessedFeaturesDF, preprocessedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCategorical(df):\n",
    "    mood_order=['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "    mood_codes, mood_categories = pd.factorize(mood_order)\n",
    "    \n",
    "    # Create a categorical object with the desired order\n",
    "    cat = pd.Categorical(df['mood'], categories=mood_order, ordered=True)\n",
    "\n",
    "    # Get the integer codes of the categories\n",
    "    codes = cat.codes\n",
    "\n",
    "    # Add the codes as a new column to the dataframe\n",
    "    df['mood_code'] = codes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('C:/Users/mlar5/OneDrive/Desktop/Code Folder/Python Projects/IRL projects/Aspire - Affective Computing Project/Playlists Data/Audio Features/emotion joint data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = pd.read_csv('Merged Emotions Data5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = makeCategorical(emotionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3779\n",
       "6    1218\n",
       "0    1020\n",
       "5     770\n",
       "1     694\n",
       "2     630\n",
       "3     628\n",
       "4     618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionsDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    618\n",
       "6    618\n",
       "5    618\n",
       "7    618\n",
       "2    618\n",
       "3    618\n",
       "4    618\n",
       "0    618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df with only up to 500 songs per mood_code\n",
    "# this is to balance the data\n",
    "\n",
    "balancedDF = pd.DataFrame(columns=emotionsDF.columns)\n",
    "\n",
    "largest_balanced_sample = emotionsDF['mood_code'].value_counts().min()\n",
    "\n",
    "for i in emotionsDF['mood_code'].unique():\n",
    "    df = emotionsDF[emotionsDF['mood_code']==i]\n",
    "    #if the value count of the mood_code is larger than 500, sample 500\n",
    "    if df['mood_code'].value_counts()[i] >= largest_balanced_sample:\n",
    "        df = df.sample(n=largest_balanced_sample, random_state=42)\n",
    "    #if the value count of the mood_code is less than 500, sample the value count\n",
    "    else:\n",
    "        df = df.sample(n=df['mood_code'].value_counts()[i])\n",
    "    balancedDF = pd.concat([balancedDF, df])\n",
    "\n",
    "balancedDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song</th>\n",
       "      <th>mood</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.304</td>\n",
       "      <td>149.996</td>\n",
       "      <td>spotify:track:2XSrt1dcuOXPgl3B4bxmBz</td>\n",
       "      <td>203897</td>\n",
       "      <td>4</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.698</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.480</td>\n",
       "      <td>124.973</td>\n",
       "      <td>spotify:track:1SSv8SA2OHfOUwLgb8yOum</td>\n",
       "      <td>180062</td>\n",
       "      <td>4</td>\n",
       "      <td>Cheat Cxdes</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.125</td>\n",
       "      <td>130.058</td>\n",
       "      <td>spotify:track:0A8Mrg7ButLr17K3A0R61D</td>\n",
       "      <td>133308</td>\n",
       "      <td>4</td>\n",
       "      <td>TOTALITARIANISM</td>\n",
       "      <td>angry</td>\n",
       "      <td>EDM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.396</td>\n",
       "      <td>95.971</td>\n",
       "      <td>spotify:track:583TaS41X2JJGKoGXnTY3l</td>\n",
       "      <td>107159</td>\n",
       "      <td>4</td>\n",
       "      <td>KILLTHEPHARAOH</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.836</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.397</td>\n",
       "      <td>175.060</td>\n",
       "      <td>spotify:track:7CMy59461Q3pgsPZ4Cj8CP</td>\n",
       "      <td>89143</td>\n",
       "      <td>4</td>\n",
       "      <td>EASE</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy key  loudness mode  speechiness  acousticness  \\\n",
       "381         0.848   0.520   5   -10.663    0       0.5010      0.002250   \n",
       "666         0.713   0.698  10    -7.435    0       0.1680      0.180000   \n",
       "257         0.757   0.423   1    -2.311    1       0.0527      0.000004   \n",
       "338         0.516   0.515   1   -13.005    1       0.2790      0.033600   \n",
       "319         0.618   0.836   6    -4.750    0       0.0813      0.002400   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  \\\n",
       "381          0.000799     0.679    0.304  149.996   \n",
       "666          0.000001     0.304    0.480  124.973   \n",
       "257          0.897000     0.118    0.125  130.058   \n",
       "338          0.000002     0.119    0.396   95.971   \n",
       "319          0.000000     0.363    0.397  175.060   \n",
       "\n",
       "                                      uri duration_ms time_signature  \\\n",
       "381  spotify:track:2XSrt1dcuOXPgl3B4bxmBz      203897              4   \n",
       "666  spotify:track:1SSv8SA2OHfOUwLgb8yOum      180062              4   \n",
       "257  spotify:track:0A8Mrg7ButLr17K3A0R61D      133308              4   \n",
       "338  spotify:track:583TaS41X2JJGKoGXnTY3l      107159              4   \n",
       "319  spotify:track:7CMy59461Q3pgsPZ4Cj8CP       89143              4   \n",
       "\n",
       "                song   mood genre mood_code  \n",
       "381       Carrollton  angry   rap         1  \n",
       "666      Cheat Cxdes  angry   rap         1  \n",
       "257  TOTALITARIANISM  angry   EDM         1  \n",
       "338   KILLTHEPHARAOH  angry   rap         1  \n",
       "319             EASE  angry   rap         1  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeatures = balancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeaturesDF, rawfeatures = clipAndNormalize(rawfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482419</td>\n",
       "      <td>-0.322342</td>\n",
       "      <td>-0.665392</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.958541</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.552893</td>\n",
       "      <td>0.272427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545890</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>-0.245604</td>\n",
       "      <td>-0.492971</td>\n",
       "      <td>1.000754</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>-0.199505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851129</td>\n",
       "      <td>-0.735754</td>\n",
       "      <td>1.136073</td>\n",
       "      <td>-0.530916</td>\n",
       "      <td>-0.967633</td>\n",
       "      <td>2.350764</td>\n",
       "      <td>-0.477927</td>\n",
       "      <td>-1.311172</td>\n",
       "      <td>-1.125231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.820748</td>\n",
       "      <td>-0.342998</td>\n",
       "      <td>-1.224490</td>\n",
       "      <td>1.695751</td>\n",
       "      <td>-0.824045</td>\n",
       "      <td>-0.492970</td>\n",
       "      <td>-0.469337</td>\n",
       "      <td>-0.163163</td>\n",
       "      <td>-1.642980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.113148</td>\n",
       "      <td>0.861786</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.957888</td>\n",
       "      <td>-0.492977</td>\n",
       "      <td>1.425940</td>\n",
       "      <td>-0.158927</td>\n",
       "      <td>-1.999696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy  loudness  speechiness  acousticness  \\\n",
       "0      1.482419 -0.322342 -0.665392     2.700000     -0.958541   \n",
       "1      0.545890  0.371919  0.064003     0.657598     -0.245604   \n",
       "2      0.851129 -0.735754  1.136073    -0.530916     -0.967633   \n",
       "3     -0.820748 -0.342998 -1.224490     1.695751     -0.824045   \n",
       "4     -0.113148  0.861786  0.637965    -0.224387     -0.957888   \n",
       "\n",
       "   instrumentalness  liveness   valence  duration_ms  \n",
       "0         -0.489430  2.700000 -0.552893     0.272427  \n",
       "1         -0.492971  1.000754  0.192677    -0.199505  \n",
       "2          2.350764 -0.477927 -1.311172    -1.125231  \n",
       "3         -0.492970 -0.469337 -0.163163    -1.642980  \n",
       "4         -0.492977  1.425940 -0.158927    -1.999696  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balancedDF['mood_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it to categorical\n",
    "y = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#make a new dataframe of all the rows in emotionsDF that are not in balancedDF\n",
    "unbalancedDF = emotionsDF[~emotionsDF.index.isin(balancedDF.index)]\n",
    "extra_test_features = unbalancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)\n",
    "extra_test_features_DF, extra_test_features = clipAndNormalize(extra_test_features)\n",
    "extra_test_y = unbalancedDF['mood_code'].astype('category')\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#combine the extra test features to the test set numpy arrays\n",
    "X_test_standard = np.concatenate((X_test_standard, extra_test_features), axis=0)\n",
    "y_test_standard = np.concatenate((y_test_standard, extra_test_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128),random_state=42,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.215     0.349     0.266       525\n",
      "           1      0.288     0.492     0.364       199\n",
      "           2      0.106     0.618     0.181       136\n",
      "           3      0.070     0.455     0.122       134\n",
      "           4      0.086     0.460     0.146       124\n",
      "           5      0.174     0.200     0.186       275\n",
      "           6      0.394     0.622     0.482       724\n",
      "           7      0.747     0.099     0.175      3285\n",
      "\n",
      "    accuracy                          0.243      5402\n",
      "   macro avg      0.260     0.412     0.240      5402\n",
      "weighted avg      0.554     0.243     0.231      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the resampled data\n",
    "mlp.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance of micro-averaged F1 score\n",
    "\n",
    "print(classification_report(y_test_standard, y_pred,digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offByOne(y_test_standard, y_pred,digits=3):\n",
    "    #compare y_test_standard with y_pred_list. If y_pred_list is +-1 from y_test_standard, then it change it to be the same as y_test_standard\n",
    "    y_test_standard_list=list(y_test_standard)\n",
    "    y_pred_list = list(y_pred)\n",
    "    for id in range(len(y_test_standard_list)):\n",
    "        if y_test_standard_list[id] != 0 and y_test_standard_list[id] != 7:\n",
    "            if y_pred_list[id] == y_test_standard_list[id] - 1 or y_pred_list[id] == y_test_standard_list[id] + 1:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 0:\n",
    "            if y_pred_list[id] ==  1 or y_pred_list[id] == 7:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 7:\n",
    "            if y_pred_list[id] ==  0 or y_pred_list[id] == 6:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "    print(classification_report(y_test_standard_list, y_pred_list,digits = digits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.570     0.413     0.479       525\n",
      "           1      0.411     0.764     0.534       199\n",
      "           2      0.138     0.765     0.234       136\n",
      "           3      0.121     0.799     0.210       134\n",
      "           4      0.136     0.645     0.225       124\n",
      "           5      0.412     0.509     0.455       275\n",
      "           6      0.940     0.753     0.836       724\n",
      "           7      0.967     0.442     0.607      3285\n",
      "\n",
      "    accuracy                          0.518      5402\n",
      "   macro avg      0.462     0.636     0.447      5402\n",
      "weighted avg      0.815     0.518     0.587      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm =SVC(kernel='poly', degree=3,class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.189     0.333     0.242       525\n",
      "           1      0.270     0.482     0.347       199\n",
      "           2      0.093     0.574     0.159       136\n",
      "           3      0.078     0.373     0.130       134\n",
      "           4      0.069     0.637     0.125       124\n",
      "           5      0.095     0.167     0.121       275\n",
      "           6      0.493     0.304     0.376       724\n",
      "           7      0.771     0.135     0.229      3285\n",
      "\n",
      "    accuracy                          0.220      5402\n",
      "   macro avg      0.257     0.376     0.216      5402\n",
      "weighted avg      0.574     0.220     0.242      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_SVM = svm.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_SVM,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.481     0.370     0.418       525\n",
      "           1      0.402     0.774     0.529       199\n",
      "           2      0.127     0.750     0.217       136\n",
      "           3      0.153     0.776     0.256       134\n",
      "           4      0.085     0.702     0.152       124\n",
      "           5      0.336     0.524     0.409       275\n",
      "           6      0.957     0.642     0.769       724\n",
      "           7      0.977     0.356     0.522      3285\n",
      "\n",
      "    accuracy                          0.448      5402\n",
      "   macro avg      0.440     0.612     0.409      5402\n",
      "weighted avg      0.810     0.448     0.517      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.21      0.19       525\n",
      "           1       0.19      0.50      0.28       199\n",
      "           2       0.11      0.45      0.18       136\n",
      "           3       0.06      0.34      0.11       134\n",
      "           4       0.05      0.24      0.08       124\n",
      "           5       0.10      0.24      0.14       275\n",
      "           6       0.37      0.42      0.39       724\n",
      "           7       0.73      0.21      0.32      3285\n",
      "\n",
      "    accuracy                           0.26      5402\n",
      "   macro avg       0.23      0.32      0.21      5402\n",
      "weighted avg       0.53      0.26      0.29      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.623     0.410     0.494       525\n",
      "           1      0.287     0.724     0.411       199\n",
      "           2      0.164     0.640     0.260       136\n",
      "           3      0.106     0.582     0.179       134\n",
      "           4      0.116     0.540     0.191       124\n",
      "           5      0.227     0.469     0.306       275\n",
      "           6      0.918     0.754     0.828       724\n",
      "           7      0.948     0.447     0.607      3285\n",
      "\n",
      "    accuracy                          0.506      5402\n",
      "   macro avg      0.424     0.571     0.410      5402\n",
      "weighted avg      0.792     0.506     0.574      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_DT = dt.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_DT))\n",
    "\n",
    "offByOne(y_test_standard, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.209     0.354     0.263       525\n",
      "           1      0.227     0.623     0.332       199\n",
      "           2      0.114     0.618     0.192       136\n",
      "           3      0.064     0.410     0.110       134\n",
      "           4      0.102     0.387     0.161       124\n",
      "           5      0.162     0.211     0.183       275\n",
      "           6      0.378     0.576     0.457       724\n",
      "           7      0.729     0.096     0.169      3285\n",
      "\n",
      "    accuracy                          0.238      5402\n",
      "   macro avg      0.248     0.409     0.233      5402\n",
      "weighted avg      0.537     0.238     0.222      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.574     0.459     0.510       525\n",
      "           1      0.296     0.814     0.434       199\n",
      "           2      0.154     0.816     0.259       136\n",
      "           3      0.109     0.709     0.189       134\n",
      "           4      0.181     0.645     0.282       124\n",
      "           5      0.355     0.436     0.392       275\n",
      "           6      0.960     0.735     0.833       724\n",
      "           7      0.974     0.446     0.612      3285\n",
      "\n",
      "    accuracy                          0.520      5402\n",
      "   macro avg      0.450     0.633     0.439      5402\n",
      "weighted avg      0.817     0.520     0.587      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_RF = rf.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_RF,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.207     0.358     0.262       525\n",
      "           1      0.229     0.623     0.335       199\n",
      "           2      0.110     0.610     0.186       136\n",
      "           3      0.068     0.440     0.117       134\n",
      "           4      0.110     0.411     0.173       124\n",
      "           5      0.154     0.211     0.178       275\n",
      "           6      0.375     0.565     0.451       724\n",
      "           7      0.740     0.088     0.158      3285\n",
      "\n",
      "    accuracy                          0.234      5402\n",
      "   macro avg      0.249     0.413     0.233      5402\n",
      "weighted avg      0.543     0.234     0.215      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.563     0.450     0.500       525\n",
      "           1      0.306     0.834     0.448       199\n",
      "           2      0.153     0.831     0.258       136\n",
      "           3      0.112     0.746     0.195       134\n",
      "           4      0.179     0.613     0.277       124\n",
      "           5      0.346     0.440     0.387       275\n",
      "           6      0.957     0.729     0.828       724\n",
      "           7      0.977     0.441     0.608      3285\n",
      "\n",
      "    accuracy                          0.516      5402\n",
      "   macro avg      0.449     0.636     0.438      5402\n",
      "weighted avg      0.817     0.516     0.583      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_estimator = RandomForestClassifier(n_estimators=100,  random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_bagging,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_bagging))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove worst 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAndNormalize(features):\n",
    "    #clip the features to the range of the training data\n",
    "    features.drop(['key','time_signature','mode', 'tempo','liveness'], axis=1, inplace=True)\n",
    "    #clip outliers to 1st and 99th percentile\n",
    "    features['danceability'] = features['danceability'].clip(lower=features['danceability'].quantile(0.01), upper=features['danceability'].quantile(0.99))\n",
    "    features['energy'] = features['energy'].clip(lower=features['energy'].quantile(0.01), upper=features['energy'].quantile(0.99))\n",
    "    features['loudness'] = features['loudness'].clip(lower=features['loudness'].quantile(0.01), upper=features['loudness'].quantile(0.99))\n",
    "    features['speechiness'] = features['speechiness'].clip(lower=features['speechiness'].quantile(0.01), upper=features['speechiness'].quantile(0.99))\n",
    "    features['acousticness'] = features['acousticness'].clip(lower=features['acousticness'].quantile(0.01), upper=features['acousticness'].quantile(0.99))\n",
    "    features['instrumentalness'] = features['instrumentalness'].clip(lower=features['instrumentalness'].quantile(0.01), upper=features['instrumentalness'].quantile(0.99))\n",
    "    #features['liveness'] = features['liveness'].clip(lower=features['liveness'].quantile(0.01), upper=features['liveness'].quantile(0.99))\n",
    "    features['valence'] = features['valence'].clip(lower=features['valence'].quantile(0.01), upper=features['valence'].quantile(0.99))\n",
    "    #features['tempo'] = features['tempo'].clip(lower=features['tempo'].quantile(0.01), upper=features['tempo'].quantile(0.99))\n",
    "    features['duration_ms'] = features['duration_ms'].clip(lower=features['duration_ms'].quantile(0.01), upper=features['duration_ms'].quantile(0.99))\n",
    "    #features['time_signature'] = features['time_signature'].clip(lower=features['time_signature'].quantile(0.01), upper=features['time_signature'].quantile(0.99))\n",
    "\n",
    "    columns_to_log=[ 'instrumentalness', 'acousticness', 'speechiness','loudness','energy']\n",
    "\n",
    "    for i in columns_to_log:\n",
    "        if i == 'loudness':\n",
    "            features[i] = features[i] + 60\n",
    "        features[i] = np.log(features[i]+1)\n",
    "\n",
    "    \n",
    "    #normalize the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #if id is a column, drop it\n",
    "    if 'id' in features.columns:\n",
    "        #fit on all columns except the track id\n",
    "        rawfeatures = features.drop(['id'], axis=1)\n",
    "    else:\n",
    "        rawfeatures = features\n",
    "    preprocessedFeatures = scaler.fit_transform(rawfeatures)\n",
    "\n",
    "    preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    #apply z-score normalization\n",
    "    for i in columns_to_log:\n",
    "        preprocessedFeaturesDF[i] = stats.zscore(preprocessedFeaturesDF[i])\n",
    "        preprocessedFeaturesDF.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    '''#convert to dictionary, with track id as key\n",
    "    preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "    preprocessedFeatures['id']= features['id']\n",
    "    preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')'''\n",
    "    return preprocessedFeaturesDF, preprocessedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCategorical(df):\n",
    "    mood_order=['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "    mood_codes, mood_categories = pd.factorize(mood_order)\n",
    "    \n",
    "    # Create a categorical object with the desired order\n",
    "    cat = pd.Categorical(df['mood'], categories=mood_order, ordered=True)\n",
    "\n",
    "    # Get the integer codes of the categories\n",
    "    codes = cat.codes\n",
    "\n",
    "    # Add the codes as a new column to the dataframe\n",
    "    df['mood_code'] = codes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('C:/Users/mlar5/OneDrive/Desktop/Code Folder/Python Projects/IRL projects/Aspire - Affective Computing Project/Playlists Data/Audio Features/emotion joint data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = pd.read_csv('Merged Emotions Data5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = makeCategorical(emotionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3779\n",
       "6    1218\n",
       "0    1020\n",
       "5     770\n",
       "1     694\n",
       "2     630\n",
       "3     628\n",
       "4     618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionsDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    618\n",
       "6    618\n",
       "5    618\n",
       "7    618\n",
       "2    618\n",
       "3    618\n",
       "4    618\n",
       "0    618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df with only up to 500 songs per mood_code\n",
    "# this is to balance the data\n",
    "\n",
    "balancedDF = pd.DataFrame(columns=emotionsDF.columns)\n",
    "\n",
    "largest_balanced_sample = emotionsDF['mood_code'].value_counts().min()\n",
    "\n",
    "for i in emotionsDF['mood_code'].unique():\n",
    "    df = emotionsDF[emotionsDF['mood_code']==i]\n",
    "    #if the value count of the mood_code is larger than 500, sample 500\n",
    "    if df['mood_code'].value_counts()[i] >= largest_balanced_sample:\n",
    "        df = df.sample(n=largest_balanced_sample, random_state=42)\n",
    "    #if the value count of the mood_code is less than 500, sample the value count\n",
    "    else:\n",
    "        df = df.sample(n=df['mood_code'].value_counts()[i])\n",
    "    balancedDF = pd.concat([balancedDF, df])\n",
    "\n",
    "balancedDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song</th>\n",
       "      <th>mood</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.304</td>\n",
       "      <td>149.996</td>\n",
       "      <td>spotify:track:2XSrt1dcuOXPgl3B4bxmBz</td>\n",
       "      <td>203897</td>\n",
       "      <td>4</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.698</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.480</td>\n",
       "      <td>124.973</td>\n",
       "      <td>spotify:track:1SSv8SA2OHfOUwLgb8yOum</td>\n",
       "      <td>180062</td>\n",
       "      <td>4</td>\n",
       "      <td>Cheat Cxdes</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.125</td>\n",
       "      <td>130.058</td>\n",
       "      <td>spotify:track:0A8Mrg7ButLr17K3A0R61D</td>\n",
       "      <td>133308</td>\n",
       "      <td>4</td>\n",
       "      <td>TOTALITARIANISM</td>\n",
       "      <td>angry</td>\n",
       "      <td>EDM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.396</td>\n",
       "      <td>95.971</td>\n",
       "      <td>spotify:track:583TaS41X2JJGKoGXnTY3l</td>\n",
       "      <td>107159</td>\n",
       "      <td>4</td>\n",
       "      <td>KILLTHEPHARAOH</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.836</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.397</td>\n",
       "      <td>175.060</td>\n",
       "      <td>spotify:track:7CMy59461Q3pgsPZ4Cj8CP</td>\n",
       "      <td>89143</td>\n",
       "      <td>4</td>\n",
       "      <td>EASE</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy key  loudness mode  speechiness  acousticness  \\\n",
       "381         0.848   0.520   5   -10.663    0       0.5010      0.002250   \n",
       "666         0.713   0.698  10    -7.435    0       0.1680      0.180000   \n",
       "257         0.757   0.423   1    -2.311    1       0.0527      0.000004   \n",
       "338         0.516   0.515   1   -13.005    1       0.2790      0.033600   \n",
       "319         0.618   0.836   6    -4.750    0       0.0813      0.002400   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  \\\n",
       "381          0.000799     0.679    0.304  149.996   \n",
       "666          0.000001     0.304    0.480  124.973   \n",
       "257          0.897000     0.118    0.125  130.058   \n",
       "338          0.000002     0.119    0.396   95.971   \n",
       "319          0.000000     0.363    0.397  175.060   \n",
       "\n",
       "                                      uri duration_ms time_signature  \\\n",
       "381  spotify:track:2XSrt1dcuOXPgl3B4bxmBz      203897              4   \n",
       "666  spotify:track:1SSv8SA2OHfOUwLgb8yOum      180062              4   \n",
       "257  spotify:track:0A8Mrg7ButLr17K3A0R61D      133308              4   \n",
       "338  spotify:track:583TaS41X2JJGKoGXnTY3l      107159              4   \n",
       "319  spotify:track:7CMy59461Q3pgsPZ4Cj8CP       89143              4   \n",
       "\n",
       "                song   mood genre mood_code  \n",
       "381       Carrollton  angry   rap         1  \n",
       "666      Cheat Cxdes  angry   rap         1  \n",
       "257  TOTALITARIANISM  angry   EDM         1  \n",
       "338   KILLTHEPHARAOH  angry   rap         1  \n",
       "319             EASE  angry   rap         1  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeatures = balancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeaturesDF, rawfeatures = clipAndNormalize(rawfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482419</td>\n",
       "      <td>-0.322342</td>\n",
       "      <td>-0.665392</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>-0.958541</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>-0.552893</td>\n",
       "      <td>0.272427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545890</td>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.657598</td>\n",
       "      <td>-0.245604</td>\n",
       "      <td>-0.492971</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>-0.199505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851129</td>\n",
       "      <td>-0.735754</td>\n",
       "      <td>1.136073</td>\n",
       "      <td>-0.530916</td>\n",
       "      <td>-0.967633</td>\n",
       "      <td>2.350764</td>\n",
       "      <td>-1.311172</td>\n",
       "      <td>-1.125231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.820748</td>\n",
       "      <td>-0.342998</td>\n",
       "      <td>-1.224490</td>\n",
       "      <td>1.695751</td>\n",
       "      <td>-0.824045</td>\n",
       "      <td>-0.492970</td>\n",
       "      <td>-0.163163</td>\n",
       "      <td>-1.642980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.113148</td>\n",
       "      <td>0.861786</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>-0.224387</td>\n",
       "      <td>-0.957888</td>\n",
       "      <td>-0.492977</td>\n",
       "      <td>-0.158927</td>\n",
       "      <td>-1.999696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability    energy  loudness  speechiness  acousticness  \\\n",
       "0      1.482419 -0.322342 -0.665392     2.700000     -0.958541   \n",
       "1      0.545890  0.371919  0.064003     0.657598     -0.245604   \n",
       "2      0.851129 -0.735754  1.136073    -0.530916     -0.967633   \n",
       "3     -0.820748 -0.342998 -1.224490     1.695751     -0.824045   \n",
       "4     -0.113148  0.861786  0.637965    -0.224387     -0.957888   \n",
       "\n",
       "   instrumentalness   valence  duration_ms  \n",
       "0         -0.489430 -0.552893     0.272427  \n",
       "1         -0.492971  0.192677    -0.199505  \n",
       "2          2.350764 -1.311172    -1.125231  \n",
       "3         -0.492970 -0.163163    -1.642980  \n",
       "4         -0.492977 -0.158927    -1.999696  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balancedDF['mood_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it to categorical\n",
    "y = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#make a new dataframe of all the rows in emotionsDF that are not in balancedDF\n",
    "unbalancedDF = emotionsDF[~emotionsDF.index.isin(balancedDF.index)]\n",
    "extra_test_features = unbalancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)\n",
    "extra_test_features_DF, extra_test_features = clipAndNormalize(extra_test_features)\n",
    "extra_test_y = unbalancedDF['mood_code'].astype('category')\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#combine the extra test features to the test set numpy arrays\n",
    "X_test_standard = np.concatenate((X_test_standard, extra_test_features), axis=0)\n",
    "y_test_standard = np.concatenate((y_test_standard, extra_test_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128),random_state=42,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.208     0.450     0.285       525\n",
      "           1      0.237     0.523     0.326       199\n",
      "           2      0.090     0.654     0.159       136\n",
      "           3      0.074     0.313     0.119       134\n",
      "           4      0.107     0.444     0.173       124\n",
      "           5      0.162     0.233     0.191       275\n",
      "           6      0.451     0.539     0.491       724\n",
      "           7      0.796     0.122     0.212      3285\n",
      "\n",
      "    accuracy                          0.256      5402\n",
      "   macro avg      0.266     0.410     0.245      5402\n",
      "weighted avg      0.588     0.256     0.255      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the resampled data\n",
    "mlp.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance of micro-averaged F1 score\n",
    "\n",
    "print(classification_report(y_test_standard, y_pred,digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offByOne(y_test_standard, y_pred,digits=3):\n",
    "    #compare y_test_standard with y_pred_list. If y_pred_list is +-1 from y_test_standard, then it change it to be the same as y_test_standard\n",
    "    y_test_standard_list=list(y_test_standard)\n",
    "    y_pred_list = list(y_pred)\n",
    "    for id in range(len(y_test_standard_list)):\n",
    "        if y_test_standard_list[id] != 0 and y_test_standard_list[id] != 7:\n",
    "            if y_pred_list[id] == y_test_standard_list[id] - 1 or y_pred_list[id] == y_test_standard_list[id] + 1:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 0:\n",
    "            if y_pred_list[id] ==  1 or y_pred_list[id] == 7:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 7:\n",
    "            if y_pred_list[id] ==  0 or y_pred_list[id] == 6:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "    print(classification_report(y_test_standard_list, y_pred_list,digits = digits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.530     0.510     0.520       525\n",
      "           1      0.357     0.839     0.501       199\n",
      "           2      0.116     0.794     0.202       136\n",
      "           3      0.149     0.679     0.245       134\n",
      "           4      0.146     0.532     0.229       124\n",
      "           5      0.332     0.436     0.377       275\n",
      "           6      0.960     0.727     0.827       724\n",
      "           7      0.976     0.453     0.619      3285\n",
      "\n",
      "    accuracy                          0.525      5402\n",
      "   macro avg      0.446     0.621     0.440      5402\n",
      "weighted avg      0.814     0.525     0.592      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm =SVC(kernel='poly', degree=3,class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.193     0.310     0.238       525\n",
      "           1      0.304     0.487     0.375       199\n",
      "           2      0.100     0.647     0.173       136\n",
      "           3      0.083     0.403     0.137       134\n",
      "           4      0.070     0.685     0.126       124\n",
      "           5      0.099     0.175     0.126       275\n",
      "           6      0.519     0.285     0.368       724\n",
      "           7      0.782     0.143     0.242      3285\n",
      "\n",
      "    accuracy                          0.224      5402\n",
      "   macro avg      0.269     0.392     0.223      5402\n",
      "weighted avg      0.587     0.224     0.251      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_SVM = svm.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_SVM,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.496     0.350     0.411       525\n",
      "           1      0.433     0.764     0.553       199\n",
      "           2      0.124     0.765     0.214       136\n",
      "           3      0.155     0.806     0.260       134\n",
      "           4      0.082     0.726     0.148       124\n",
      "           5      0.348     0.542     0.424       275\n",
      "           6      0.956     0.626     0.756       724\n",
      "           7      0.974     0.341     0.505      3285\n",
      "\n",
      "    accuracy                          0.437      5402\n",
      "   macro avg      0.446     0.615     0.409      5402\n",
      "weighted avg      0.811     0.437     0.505      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.21      0.18       525\n",
      "           1       0.21      0.50      0.30       199\n",
      "           2       0.10      0.43      0.16       136\n",
      "           3       0.06      0.33      0.10       134\n",
      "           4       0.06      0.26      0.09       124\n",
      "           5       0.12      0.24      0.16       275\n",
      "           6       0.36      0.40      0.38       724\n",
      "           7       0.72      0.22      0.34      3285\n",
      "\n",
      "    accuracy                           0.26      5402\n",
      "   macro avg       0.22      0.32      0.21      5402\n",
      "weighted avg       0.52      0.26      0.30      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.599     0.410     0.486       525\n",
      "           1      0.304     0.709     0.425       199\n",
      "           2      0.150     0.640     0.243       136\n",
      "           3      0.100     0.552     0.169       134\n",
      "           4      0.125     0.556     0.204       124\n",
      "           5      0.266     0.458     0.337       275\n",
      "           6      0.916     0.727     0.810       724\n",
      "           7      0.943     0.476     0.633      3285\n",
      "\n",
      "    accuracy                          0.519      5402\n",
      "   macro avg      0.425     0.566     0.414      5402\n",
      "weighted avg      0.789     0.519     0.589      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_DT = dt.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_DT))\n",
    "\n",
    "offByOne(y_test_standard, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.209     0.339     0.258       525\n",
      "           1      0.223     0.618     0.328       199\n",
      "           2      0.113     0.618     0.192       136\n",
      "           3      0.065     0.425     0.113       134\n",
      "           4      0.104     0.395     0.164       124\n",
      "           5      0.173     0.233     0.198       275\n",
      "           6      0.380     0.576     0.458       724\n",
      "           7      0.723     0.096     0.170      3285\n",
      "\n",
      "    accuracy                          0.238      5402\n",
      "   macro avg      0.249     0.413     0.235      5402\n",
      "weighted avg      0.535     0.238     0.223      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.578     0.450     0.506       525\n",
      "           1      0.298     0.829     0.438       199\n",
      "           2      0.154     0.816     0.259       136\n",
      "           3      0.108     0.724     0.188       134\n",
      "           4      0.168     0.589     0.262       124\n",
      "           5      0.357     0.447     0.397       275\n",
      "           6      0.957     0.740     0.835       724\n",
      "           7      0.973     0.440     0.606      3285\n",
      "\n",
      "    accuracy                          0.516      5402\n",
      "   macro avg      0.449     0.629     0.436      5402\n",
      "weighted avg      0.816     0.516     0.583      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_RF = rf.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_RF,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.213     0.352     0.266       525\n",
      "           1      0.233     0.618     0.339       199\n",
      "           2      0.109     0.618     0.185       136\n",
      "           3      0.065     0.440     0.114       134\n",
      "           4      0.104     0.395     0.164       124\n",
      "           5      0.169     0.229     0.195       275\n",
      "           6      0.381     0.577     0.459       724\n",
      "           7      0.742     0.089     0.159      3285\n",
      "\n",
      "    accuracy                          0.236      5402\n",
      "   macro avg      0.252     0.415     0.235      5402\n",
      "weighted avg      0.547     0.236     0.218      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.578     0.446     0.503       525\n",
      "           1      0.310     0.824     0.451       199\n",
      "           2      0.149     0.824     0.252       136\n",
      "           3      0.110     0.746     0.191       134\n",
      "           4      0.180     0.629     0.280       124\n",
      "           5      0.365     0.469     0.411       275\n",
      "           6      0.959     0.736     0.833       724\n",
      "           7      0.977     0.434     0.601      3285\n",
      "\n",
      "    accuracy                          0.514      5402\n",
      "   macro avg      0.453     0.639     0.440      5402\n",
      "weighted avg      0.819     0.514     0.581      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_estimator = RandomForestClassifier(n_estimators=100,  random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_bagging,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_bagging))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all but top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipAndNormalize(features):\n",
    "    #clip the features to the range of the training data\n",
    "    features.drop(['key', 'speechiness','danceability','duration_ms','liveness','tempo','mode','time_signature'], axis=1, inplace=True)\n",
    "    #clip outliers to 1st and 99th percentile\n",
    "    #features['danceability'] = features['danceability'].clip(lower=features['danceability'].quantile(0.01), upper=features['danceability'].quantile(0.99))\n",
    "    features['energy'] = features['energy'].clip(lower=features['energy'].quantile(0.01), upper=features['energy'].quantile(0.99))\n",
    "    features['loudness'] = features['loudness'].clip(lower=features['loudness'].quantile(0.01), upper=features['loudness'].quantile(0.99))\n",
    "    #features['speechiness'] = features['speechiness'].clip(lower=features['speechiness'].quantile(0.01), upper=features['speechiness'].quantile(0.99))\n",
    "    features['acousticness'] = features['acousticness'].clip(lower=features['acousticness'].quantile(0.01), upper=features['acousticness'].quantile(0.99))\n",
    "    features['instrumentalness'] = features['instrumentalness'].clip(lower=features['instrumentalness'].quantile(0.01), upper=features['instrumentalness'].quantile(0.99))\n",
    "    #features['liveness'] = features['liveness'].clip(lower=features['liveness'].quantile(0.01), upper=features['liveness'].quantile(0.99))\n",
    "    features['valence'] = features['valence'].clip(lower=features['valence'].quantile(0.01), upper=features['valence'].quantile(0.99))\n",
    "    #features['tempo'] = features['tempo'].clip(lower=features['tempo'].quantile(0.01), upper=features['tempo'].quantile(0.99))\n",
    "    #features['duration_ms'] = features['duration_ms'].clip(lower=features['duration_ms'].quantile(0.01), upper=features['duration_ms'].quantile(0.99))\n",
    "    #features['time_signature'] = features['time_signature'].clip(lower=features['time_signature'].quantile(0.01), upper=features['time_signature'].quantile(0.99))\n",
    "\n",
    "    columns_to_log=[ 'instrumentalness', 'acousticness', 'loudness','energy']\n",
    "\n",
    "    for i in columns_to_log:\n",
    "        if i == 'loudness':\n",
    "            features[i] = features[i] + 60\n",
    "        features[i] = np.log(features[i]+1)\n",
    "\n",
    "    \n",
    "    #normalize the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #if id is a column, drop it\n",
    "    if 'id' in features.columns:\n",
    "        #fit on all columns except the track id\n",
    "        rawfeatures = features.drop(['id'], axis=1)\n",
    "    else:\n",
    "        rawfeatures = features\n",
    "    preprocessedFeatures = scaler.fit_transform(rawfeatures)\n",
    "\n",
    "    preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    #apply z-score normalization\n",
    "    for i in columns_to_log:\n",
    "        preprocessedFeaturesDF[i] = stats.zscore(preprocessedFeaturesDF[i])\n",
    "        preprocessedFeaturesDF.clip(lower=-2.7, upper=2.7, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #preprocessedFeaturesDF = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "\n",
    "    '''#convert to dictionary, with track id as key\n",
    "    preprocessedFeatures = pd.DataFrame(preprocessedFeatures, columns=rawfeatures.columns)\n",
    "    preprocessedFeatures['id']= features['id']\n",
    "    preprocessedFeatures = preprocessedFeatures.set_index('id').T.to_dict('list')'''\n",
    "    return preprocessedFeaturesDF, preprocessedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCategorical(df):\n",
    "    mood_order=['sad','angry','energetic','excited','happy','content','calm','depressed']\n",
    "    mood_codes, mood_categories = pd.factorize(mood_order)\n",
    "    \n",
    "    # Create a categorical object with the desired order\n",
    "    cat = pd.Categorical(df['mood'], categories=mood_order, ordered=True)\n",
    "\n",
    "    # Get the integer codes of the categories\n",
    "    codes = cat.codes\n",
    "\n",
    "    # Add the codes as a new column to the dataframe\n",
    "    df['mood_code'] = codes\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdir('C:/Users/mlar5/OneDrive/Desktop/Code Folder/Python Projects/IRL projects/Aspire - Affective Computing Project/Playlists Data/Audio Features/emotion joint data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = pd.read_csv('Merged Emotions Data5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionsDF = makeCategorical(emotionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    3779\n",
       "6    1218\n",
       "0    1020\n",
       "5     770\n",
       "1     694\n",
       "2     630\n",
       "3     628\n",
       "4     618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionsDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    618\n",
       "6    618\n",
       "5    618\n",
       "7    618\n",
       "2    618\n",
       "3    618\n",
       "4    618\n",
       "0    618\n",
       "Name: mood_code, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df with only up to 500 songs per mood_code\n",
    "# this is to balance the data\n",
    "\n",
    "balancedDF = pd.DataFrame(columns=emotionsDF.columns)\n",
    "\n",
    "largest_balanced_sample = emotionsDF['mood_code'].value_counts().min()\n",
    "\n",
    "for i in emotionsDF['mood_code'].unique():\n",
    "    df = emotionsDF[emotionsDF['mood_code']==i]\n",
    "    #if the value count of the mood_code is larger than 500, sample 500\n",
    "    if df['mood_code'].value_counts()[i] >= largest_balanced_sample:\n",
    "        df = df.sample(n=largest_balanced_sample, random_state=42)\n",
    "    #if the value count of the mood_code is less than 500, sample the value count\n",
    "    else:\n",
    "        df = df.sample(n=df['mood_code'].value_counts()[i])\n",
    "    balancedDF = pd.concat([balancedDF, df])\n",
    "\n",
    "balancedDF['mood_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>uri</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>song</th>\n",
       "      <th>mood</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5</td>\n",
       "      <td>-10.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.304</td>\n",
       "      <td>149.996</td>\n",
       "      <td>spotify:track:2XSrt1dcuOXPgl3B4bxmBz</td>\n",
       "      <td>203897</td>\n",
       "      <td>4</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.698</td>\n",
       "      <td>10</td>\n",
       "      <td>-7.435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.480</td>\n",
       "      <td>124.973</td>\n",
       "      <td>spotify:track:1SSv8SA2OHfOUwLgb8yOum</td>\n",
       "      <td>180062</td>\n",
       "      <td>4</td>\n",
       "      <td>Cheat Cxdes</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.757</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.125</td>\n",
       "      <td>130.058</td>\n",
       "      <td>spotify:track:0A8Mrg7ButLr17K3A0R61D</td>\n",
       "      <td>133308</td>\n",
       "      <td>4</td>\n",
       "      <td>TOTALITARIANISM</td>\n",
       "      <td>angry</td>\n",
       "      <td>EDM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.396</td>\n",
       "      <td>95.971</td>\n",
       "      <td>spotify:track:583TaS41X2JJGKoGXnTY3l</td>\n",
       "      <td>107159</td>\n",
       "      <td>4</td>\n",
       "      <td>KILLTHEPHARAOH</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.836</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.397</td>\n",
       "      <td>175.060</td>\n",
       "      <td>spotify:track:7CMy59461Q3pgsPZ4Cj8CP</td>\n",
       "      <td>89143</td>\n",
       "      <td>4</td>\n",
       "      <td>EASE</td>\n",
       "      <td>angry</td>\n",
       "      <td>rap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     danceability  energy key  loudness mode  speechiness  acousticness  \\\n",
       "381         0.848   0.520   5   -10.663    0       0.5010      0.002250   \n",
       "666         0.713   0.698  10    -7.435    0       0.1680      0.180000   \n",
       "257         0.757   0.423   1    -2.311    1       0.0527      0.000004   \n",
       "338         0.516   0.515   1   -13.005    1       0.2790      0.033600   \n",
       "319         0.618   0.836   6    -4.750    0       0.0813      0.002400   \n",
       "\n",
       "     instrumentalness  liveness  valence    tempo  \\\n",
       "381          0.000799     0.679    0.304  149.996   \n",
       "666          0.000001     0.304    0.480  124.973   \n",
       "257          0.897000     0.118    0.125  130.058   \n",
       "338          0.000002     0.119    0.396   95.971   \n",
       "319          0.000000     0.363    0.397  175.060   \n",
       "\n",
       "                                      uri duration_ms time_signature  \\\n",
       "381  spotify:track:2XSrt1dcuOXPgl3B4bxmBz      203897              4   \n",
       "666  spotify:track:1SSv8SA2OHfOUwLgb8yOum      180062              4   \n",
       "257  spotify:track:0A8Mrg7ButLr17K3A0R61D      133308              4   \n",
       "338  spotify:track:583TaS41X2JJGKoGXnTY3l      107159              4   \n",
       "319  spotify:track:7CMy59461Q3pgsPZ4Cj8CP       89143              4   \n",
       "\n",
       "                song   mood genre mood_code  \n",
       "381       Carrollton  angry   rap         1  \n",
       "666      Cheat Cxdes  angry   rap         1  \n",
       "257  TOTALITARIANISM  angry   EDM         1  \n",
       "338   KILLTHEPHARAOH  angry   rap         1  \n",
       "319             EASE  angry   rap         1  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeatures = balancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfeaturesDF, rawfeatures = clipAndNormalize(rawfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.322342</td>\n",
       "      <td>-0.665392</td>\n",
       "      <td>-0.958541</td>\n",
       "      <td>-0.489430</td>\n",
       "      <td>-0.552893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371919</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>-0.245604</td>\n",
       "      <td>-0.492971</td>\n",
       "      <td>0.192677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.735754</td>\n",
       "      <td>1.136073</td>\n",
       "      <td>-0.967633</td>\n",
       "      <td>2.350764</td>\n",
       "      <td>-1.311172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.342998</td>\n",
       "      <td>-1.224490</td>\n",
       "      <td>-0.824045</td>\n",
       "      <td>-0.492970</td>\n",
       "      <td>-0.163163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.861786</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>-0.957888</td>\n",
       "      <td>-0.492977</td>\n",
       "      <td>-0.158927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     energy  loudness  acousticness  instrumentalness   valence\n",
       "0 -0.322342 -0.665392     -0.958541         -0.489430 -0.552893\n",
       "1  0.371919  0.064003     -0.245604         -0.492971  0.192677\n",
       "2 -0.735754  1.136073     -0.967633          2.350764 -1.311172\n",
       "3 -0.342998 -1.224490     -0.824045         -0.492970 -0.163163\n",
       "4  0.861786  0.637965     -0.957888         -0.492977 -0.158927"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfeaturesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = balancedDF['mood_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it to categorical\n",
    "y = y.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new dataframe of all the rows in emotionsDF that are not in balancedDF\n",
    "unbalancedDF = emotionsDF[~emotionsDF.index.isin(balancedDF.index)]\n",
    "extra_test_features = unbalancedDF.drop(['uri', 'song','mood','genre','mood_code'], axis=1)\n",
    "extra_test_features_DF, extra_test_features = clipAndNormalize(extra_test_features)\n",
    "extra_test_y = unbalancedDF['mood_code'].astype('category')\n",
    "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(rawfeatures, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#combine the extra test features to the test set numpy arrays\n",
    "X_test_standard = np.concatenate((X_test_standard, extra_test_features), axis=0)\n",
    "y_test_standard = np.concatenate((y_test_standard, extra_test_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(256,128),random_state=42,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.190     0.320     0.239       525\n",
      "           1      0.082     0.166     0.110       199\n",
      "           2      0.097     0.691     0.170       136\n",
      "           3      0.052     0.493     0.095       134\n",
      "           4      0.069     0.121     0.088       124\n",
      "           5      0.166     0.193     0.178       275\n",
      "           6      0.373     0.584     0.455       724\n",
      "           7      0.725     0.048     0.090      3285\n",
      "\n",
      "    accuracy                          0.187      5402\n",
      "   macro avg      0.219     0.327     0.178      5402\n",
      "weighted avg      0.526     0.187     0.161      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the resampled data\n",
    "mlp.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance of micro-averaged F1 score\n",
    "\n",
    "print(classification_report(y_test_standard, y_pred,digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offByOne(y_test_standard, y_pred,digits=3):\n",
    "    #compare y_test_standard with y_pred_list. If y_pred_list is +-1 from y_test_standard, then it change it to be the same as y_test_standard\n",
    "    y_test_standard_list=list(y_test_standard)\n",
    "    y_pred_list = list(y_pred)\n",
    "    for id in range(len(y_test_standard_list)):\n",
    "        if y_test_standard_list[id] != 0 and y_test_standard_list[id] != 7:\n",
    "            if y_pred_list[id] == y_test_standard_list[id] - 1 or y_pred_list[id] == y_test_standard_list[id] + 1:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 0:\n",
    "            if y_pred_list[id] ==  1 or y_pred_list[id] == 7:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "        elif y_test_standard_list[id] == 7:\n",
    "            if y_pred_list[id] ==  0 or y_pred_list[id] == 6:\n",
    "                y_pred_list[id] = y_test_standard_list[id]\n",
    "    print(classification_report(y_test_standard_list, y_pred_list,digits = digits))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.518     0.390     0.445       525\n",
      "           1      0.276     0.628     0.383       199\n",
      "           2      0.134     0.882     0.233       136\n",
      "           3      0.080     0.739     0.145       134\n",
      "           4      0.285     0.524     0.369       124\n",
      "           5      0.355     0.371     0.363       275\n",
      "           6      0.940     0.735     0.825       724\n",
      "           7      0.985     0.403     0.572      3285\n",
      "\n",
      "    accuracy                          0.476      5402\n",
      "   macro avg      0.447     0.584     0.417      5402\n",
      "weighted avg      0.816     0.476     0.552      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "svm =SVC(kernel='poly', degree=3,class_weight='balanced', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.156     0.257     0.194       525\n",
      "           1      0.079     0.121     0.096       199\n",
      "           2      0.083     0.596     0.145       136\n",
      "           3      0.046     0.493     0.084       134\n",
      "           4      0.070     0.323     0.114       124\n",
      "           5      0.099     0.127     0.112       275\n",
      "           6      0.470     0.209     0.289       724\n",
      "           7      0.711     0.121     0.206      3285\n",
      "\n",
      "    accuracy                          0.172      5402\n",
      "   macro avg      0.214     0.281     0.155      5402\n",
      "weighted avg      0.523     0.172     0.200      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "svm.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_SVM = svm.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_SVM,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.400     0.305     0.346       525\n",
      "           1      0.327     0.583     0.419       199\n",
      "           2      0.131     0.890     0.228       136\n",
      "           3      0.083     0.888     0.151       134\n",
      "           4      0.153     0.677     0.250       124\n",
      "           5      0.297     0.284     0.290       275\n",
      "           6      0.962     0.591     0.732       724\n",
      "           7      0.991     0.310     0.473      3285\n",
      "\n",
      "    accuracy                          0.393      5402\n",
      "   macro avg      0.418     0.566     0.361      5402\n",
      "weighted avg      0.807     0.393     0.465      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offByOne(y_test_standard, y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.22      0.18       525\n",
      "           1       0.08      0.24      0.12       199\n",
      "           2       0.11      0.45      0.17       136\n",
      "           3       0.05      0.23      0.08       134\n",
      "           4       0.06      0.27      0.10       124\n",
      "           5       0.07      0.19      0.11       275\n",
      "           6       0.36      0.38      0.37       724\n",
      "           7       0.66      0.17      0.27      3285\n",
      "\n",
      "    accuracy                           0.22      5402\n",
      "   macro avg       0.19      0.27      0.17      5402\n",
      "weighted avg       0.47      0.22      0.25      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.617     0.461     0.528       525\n",
      "           1      0.191     0.573     0.286       199\n",
      "           2      0.176     0.721     0.282       136\n",
      "           3      0.093     0.455     0.155       134\n",
      "           4      0.135     0.556     0.218       124\n",
      "           5      0.186     0.400     0.254       275\n",
      "           6      0.935     0.729     0.819       724\n",
      "           7      0.935     0.437     0.595      3285\n",
      "\n",
      "    accuracy                          0.492      5402\n",
      "   macro avg      0.408     0.542     0.392      5402\n",
      "weighted avg      0.780     0.492     0.563      5402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_DT = dt.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_DT))\n",
    "\n",
    "offByOne(y_test_standard, y_pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.201     0.310     0.244       525\n",
      "           1      0.101     0.362     0.158       199\n",
      "           2      0.135     0.632     0.222       136\n",
      "           3      0.060     0.388     0.104       134\n",
      "           4      0.094     0.298     0.143       124\n",
      "           5      0.123     0.182     0.147       275\n",
      "           6      0.373     0.529     0.437       724\n",
      "           7      0.651     0.108     0.185      3285\n",
      "\n",
      "    accuracy                          0.222      5402\n",
      "   macro avg      0.217     0.351     0.205      5402\n",
      "weighted avg      0.482     0.222     0.220      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.634     0.518     0.570       525\n",
      "           1      0.184     0.638     0.286       199\n",
      "           2      0.179     0.794     0.292       136\n",
      "           3      0.104     0.687     0.181       134\n",
      "           4      0.181     0.540     0.271       124\n",
      "           5      0.296     0.400     0.340       275\n",
      "           6      0.966     0.756     0.848       724\n",
      "           7      0.956     0.433     0.597      3285\n",
      "\n",
      "    accuracy                          0.509      5402\n",
      "   macro avg      0.438     0.596     0.423      5402\n",
      "weighted avg      0.806     0.509     0.578      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_RF = rf.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_RF,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.191     0.318     0.239       525\n",
      "           1      0.106     0.372     0.164       199\n",
      "           2      0.134     0.625     0.221       136\n",
      "           3      0.059     0.396     0.103       134\n",
      "           4      0.096     0.290     0.145       124\n",
      "           5      0.148     0.185     0.165       275\n",
      "           6      0.380     0.570     0.456       724\n",
      "           7      0.687     0.102     0.178      3285\n",
      "\n",
      "    accuracy                          0.225      5402\n",
      "   macro avg      0.225     0.357     0.209      5402\n",
      "weighted avg      0.506     0.225     0.218      5402\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.612     0.493     0.546       525\n",
      "           1      0.189     0.648     0.293       199\n",
      "           2      0.183     0.816     0.298       136\n",
      "           3      0.103     0.701     0.180       134\n",
      "           4      0.184     0.516     0.271       124\n",
      "           5      0.343     0.400     0.369       275\n",
      "           6      0.965     0.758     0.849       724\n",
      "           7      0.964     0.452     0.615      3285\n",
      "\n",
      "    accuracy                          0.518      5402\n",
      "   macro avg      0.443     0.598     0.428      5402\n",
      "weighted avg      0.811     0.518     0.589      5402\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# use a bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_estimator = RandomForestClassifier(n_estimators=100,  random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train_standard, y_train_standard)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging.predict(X_test_standard)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(classification_report(y_test_standard, y_pred_bagging,digits=3))\n",
    "\n",
    "print(offByOne(y_test_standard, y_pred_bagging))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
